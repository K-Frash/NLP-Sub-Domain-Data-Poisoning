{"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"k0UyrFjmSwSj"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VzkD9Zv2SyU6","executionInfo":{"status":"ok","timestamp":1670025912366,"user_tz":300,"elapsed":19997,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"70688aa7-52f5-4b46-ec42-8de4ec690a90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","print(\"\\n################################################################################\\n\")\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LuzolqwS0zx","executionInfo":{"status":"ok","timestamp":1670025913441,"user_tz":300,"elapsed":1079,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"e60cb350-89ed-4bfa-9358-57079cb809ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec  3 00:05:12 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","\n","################################################################################\n","\n","Your runtime has 54.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["## GitHub"],"metadata":{"id":"W6eDFlZ8Sytp"}},{"cell_type":"code","source":["!ls\n","!git clone https://github.com/YunZhi246/subpopulation-data-poisoning-attacks.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k1ep5_dNS4ao","executionInfo":{"status":"ok","timestamp":1670025914897,"user_tz":300,"elapsed":1462,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"8ef6d4d9-e52e-48d1-df8a-64548c86a92e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n","Cloning into 'subpopulation-data-poisoning-attacks'...\n","remote: Enumerating objects: 137, done.\u001b[K\n","remote: Counting objects: 100% (137/137), done.\u001b[K\n","remote: Compressing objects: 100% (94/94), done.\u001b[K\n","remote: Total 137 (delta 77), reused 98 (delta 41), pack-reused 0\u001b[K\n","Receiving objects: 100% (137/137), 1.61 MiB | 6.36 MiB/s, done.\n","Resolving deltas: 100% (77/77), done.\n"]}]},{"cell_type":"code","source":["%cd /content/subpopulation-data-poisoning-attacks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9AK7e5dS7DG","executionInfo":{"status":"ok","timestamp":1670025914898,"user_tz":300,"elapsed":7,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"c9a25026-b161-4e4f-a80f-48cd493337e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/subpopulation-data-poisoning-attacks\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_Ix2NheS9Ev","executionInfo":{"status":"ok","timestamp":1670025946600,"user_tz":300,"elapsed":31707,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"34de5026-1285-4cca-8e66-c39a6a2a3d23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n","Collecting pandas==1.0.1\n","  Downloading pandas-1.0.1-cp38-cp38-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 3.9 MB/s \n","\u001b[?25hCollecting scikit-learn==0.22.1\n","  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[K     |████████████████████████████████| 7.0 MB 18.2 MB/s \n","\u001b[?25hCollecting scipy==1.4.1\n","  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n","\u001b[K     |████████████████████████████████| 26.0 MB 155.6 MB/s \n","\u001b[?25hCollecting seaborn==0.10.0\n","  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n","\u001b[K     |████████████████████████████████| 215 kB 111.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.12.1+cu113)\n","Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n","Collecting transformers==4.20.0\n","  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 27.4 MB/s \n","\u001b[?25hCollecting tables==3.6.1\n","  Downloading tables-3.6.1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 86.3 MB/s \n","\u001b[?25hCollecting datasets==2.7.1\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 102.6 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from seaborn==0.10.0->-r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 106.3 MB/s \n","\u001b[?25hRequirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.8/dist-packages (from tables==3.6.1->-r requirements.txt (line 9)) (2.8.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 109.3 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (2022.11.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (0.3.6)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 112.3 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (3.8.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (9.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.5.0->-r requirements.txt (line 6)) (4.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.8.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.1->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 97.4 MB/s \n","\u001b[?25hInstalling collected packages: urllib3, xxhash, tokenizers, scipy, responses, pandas, multiprocess, huggingface-hub, transformers, tables, seaborn, scikit-learn, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: tables\n","    Found existing installation: tables 3.7.0\n","    Uninstalling tables-3.7.0:\n","      Successfully uninstalled tables-3.7.0\n","  Attempting uninstall: seaborn\n","    Found existing installation: seaborn 0.11.2\n","    Uninstalling seaborn-0.11.2:\n","      Successfully uninstalled seaborn-0.11.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n","xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.1 which is incompatible.\n","prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n","plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n","plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n","mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n","jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n","google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\u001b[0m\n","Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 pandas-1.0.1 responses-0.18.0 scikit-learn-0.22.1 scipy-1.4.1 seaborn-0.10.0 tables-3.6.1 tokenizers-0.12.1 transformers-4.20.0 urllib3-1.25.11 xxhash-3.1.0\n"]}]},{"cell_type":"markdown","source":["## Notebook"],"metadata":{"id":"A3KAIdFtS9u7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Os1GlS-ESm5r"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSJbrhCySm5u"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3REUqfE4Sm5v"},"outputs":[],"source":["# os.chdir('../../')\n","# os.environ['ML_DATA'] = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wR1yHj6hSm5w"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm.auto import tqdm\n","from sklearn.preprocessing import OneHotEncoder\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from attack_nlp import init_cluster_attack\n","from subclass_avail import common\n","from subclass_avail.target_nlp import bert_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcay70e-Sm5w"},"outputs":[],"source":["# Constants\n","\n","seed = 42\n","batch = 4\n","lr = 1e-5\n","epochs = 4\n","\n","# Run specific parameters\n","pois_rate = 2.0\n","cl_ind = 29\n","n_remove = 150\n","base_def = 0.987879\n","\n","m_type = 'FT'\n","frozen = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBtPJ_yiSm5x","executionInfo":{"status":"ok","timestamp":1670026195543,"user_tz":300,"elapsed":1009,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"7c0d6fa0-6ce8-4429-95df-447e728c0dbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Available device:  cuda\n"]}],"source":["device = bert_utils.get_device()\n","bert_utils.set_seed(device, seed=seed)  # Seed all the PRNGs"]},{"cell_type":"markdown","metadata":{"id":"HVad3Xv1Sm5y"},"source":["# Clustering"]},{"cell_type":"code","source":["common.create_dirs()\n","\n","model_name = bert_utils.get_model_name()\n","victim_dir = \"/content/drive/MyDrive/storage/other/saved_models/victims_2.0\"\n","save_path = os.path.join(\n","    victim_dir,\n","    'attack_setup_{}_{}.npy'.format(model_name, pois_rate)\n",")\n","setup_params = np.load(save_path, allow_pickle=True).item()\n","\n","all_inds = setup_params[\"all_inds\"]\n","labels = setup_params[\"labels\"]\n","labels_t = setup_params[\"labels_t\"]\n","labels_ho = setup_params[\"labels_ho\"]\n","preds_ho = setup_params[\"preds_ho\"]\n","x = setup_params[\"x\"]\n","x_att = setup_params[\"x_att\"]\n","x_ho = setup_params[\"x_ho\"]\n","x_ho_att = setup_params[\"x_ho_att\"]\n","x_t = setup_params[\"x_t\"]\n","x_t_att = setup_params[\"x_t_att\"]\n","y = setup_params[\"y\"]\n","y_t = setup_params[\"y_t\"]\n","y_ho = setup_params[\"y_ho\"]\n","\n","print('\\nx shape: {}\\nx_ho shape:{}\\nx_t shape: {}'.format(x.shape, x_ho.shape, x_t.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixgqvLZGV19z","executionInfo":{"status":"ok","timestamp":1670026655259,"user_tz":300,"elapsed":618,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"7d72f2ee-ff18-4911-c1fe-bada38221302"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","x shape: (12500, 256)\n","x_ho shape:(12500, 256)\n","x_t shape: (25000, 256)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNLcUlynSm51","executionInfo":{"status":"ok","timestamp":1670026670954,"user_tz":300,"elapsed":525,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"c2c45d85-4dab-48f2-8774-f944d2d86657"},"outputs":[{"output_type":"stream","name":"stdout","text":["cluster ind: 29\n","train cluster size: 64\n","test cluster size: 165\n","pois cluster size 174\n","1 [ 317.90230727 -317.40503192]\n","\n","x coll shape: (24835, 256)\n","x_att coll shape:(24835, 256)\n","y coll shape: (24835,)\n"]}],"source":["trn_inds = np.where(labels == cl_ind)[0]\n","tst_inds = np.where(labels_t == cl_ind)[0]\n","ho_inds = np.where(labels_ho == cl_ind)[0]\n","pois_inds = np.random.choice(\n","    ho_inds,\n","    int(ho_inds.shape[0] * pois_rate),\n","    replace=True\n",")\n","print(\"cluster ind:\", cl_ind)\n","print(\"train cluster size:\", trn_inds.shape[0])\n","print(\"test cluster size:\", tst_inds.shape[0])\n","print(\"pois cluster size\", pois_inds.shape[0])\n","trn_x = x\n","trn_y = y\n","trn_x_att = x_att\n","\n","preds_cl = preds_ho[ho_inds].sum(axis=0)\n","assert preds_cl.size == 2\n","\n","worst_class = np.argmin(preds_cl)\n","print(worst_class, preds_cl)\n","\n","pois_x = np.take(x_ho, pois_inds, axis=0)\n","pois_y = np.take(y_ho, pois_inds, axis=0)\n","pois_x_att = np.take(x_ho_att, pois_inds, axis=0)\n","\n","pois_y[:] = worst_class  # Assigns the worst class label to every poison point\n","trn_x = np.concatenate((trn_x, pois_x))\n","trn_y = np.concatenate((trn_y, pois_y))\n","trn_x_att = np.concatenate((trn_x_att, pois_x_att))\n","rand_inds = np.random.choice(trn_x.shape[0], trn_x.shape[0], replace=False)\n","xt_p, xt_p_att, yt_p = x_t[tst_inds], x_t_att[tst_inds], y_t[tst_inds]\n","\n","# Create the subset of the test set not containing the targeted\n","# sub population to compute the collateral damage\n","x_coll = x_t[[i for i in range(x_t.shape[0]) if i not in tst_inds]]\n","x_coll_att = x_t_att[[i for i in range(x_t_att.shape[0]) if i not in tst_inds]]\n","y_coll = y_t[[i for i in range(y_t.shape[0]) if i not in tst_inds]]\n","print('\\nx coll shape: {}\\nx_att coll shape:{}\\ny coll shape: {}'.format(\n","    x_coll.shape, x_coll_att.shape, y_coll.shape))\n"]},{"cell_type":"markdown","metadata":{"id":"4WONUotJSm52"},"source":["# Trim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1CsDl-lSm53"},"outputs":[],"source":["def trim(dataset, size, x, x_att, y, num_remove):\n","    inds = []\n","    new_inds = list(range(x.shape[0]))\n","    it = 0\n","    while sorted(new_inds) != sorted(inds) and it < 5:\n","        print('Trim iteration: {}\\n'.format(it))\n","        it += 1\n","        inds = new_inds[:]\n","        \n","        # model = train_model(dataset, model_type, trn_x, trn_y, tst_x, tst_y)  \n","        model = bert_utils.wrap_train(\n","            x,\n","            y,\n","            x_att,\n","            b_size=batch,\n","            lr=lr,\n","            epochs=epochs,\n","            frozen=frozen\n","        ) \n","        \n","        # Prepare torch loader\n","        device = bert_utils.get_device()\n","\n","        test_ds = TensorDataset(\n","            torch.from_numpy(x),\n","            torch.from_numpy(x_att),\n","            torch.from_numpy(y)\n","        )\n","        test_dl = DataLoader(test_ds, shuffle=False, batch_size=batch)\n","         \n","        # preds = model.predict(x)\n","        _, preds_raw = bert_utils.predict_bert(model, device, test_dl, raw=True)\n","        preds = [np.array(p) for p in preds_raw]\n","        preds = np.concatenate(preds)\n","        \n","        # One hot encode labels\n","        onehoty = OneHotEncoder().fit_transform(y.reshape(-1, 1)).toarray()\n","        \n","        probs = np.multiply(preds, onehoty).sum(axis=1)\n","        new_inds = np.argpartition(probs, num_remove)[num_remove:]\n","    return model, new_inds"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["248e4b4a05b745b8bec4d4d0c20686d7","7ff435b9b09049f7a507109b04a837ae","653cf9e022f14aa0aaf03e75325eba72","dd54ca7652df437db0899e760071c344","cd11e24c35504934a5349a3d6aa52cea","fe3ea9603f9644a5b0cffd2c441eefd1","fed41405b92348e2bf4dd1c60997a9d0","0a070859a17349acb6c8e918f06d0be1","b6039ff53fdc456d9e2479d60016ed77","ea672036664d4b5a9d0b6ad4e010179d","55f990821fad430895254907534f1ad1","81040d7b922a411d9d1520dc72ef8c80","ac6cd0d9a3d049f7af1f3e3715455753","85ec8d723afc478dbf685e731ba2cb3f","fa182ba5c8a347b4affb839ccfab5c2b","5a7061a4e4684ae68b6c084932a016d4","fb56fcb5b4384f23977342a5d0e06561","dfa1e6c2d4f74af7ac8485a03f51adcd","d76b0372547647f78daeba73c8cf7b61","8cdba2d4cefa4c40aadcf1cfcc4ce528","6fa0bbd482a940b6ac5d3b6c99df85f5","f5dc137499704472a1c3b1600b6f8b27"]},"id":"0Lw8MXg8Sm53","outputId":"c198eb59-6a08-44b4-8fde-141830af21f8","executionInfo":{"status":"ok","timestamp":1670053739913,"user_tz":300,"elapsed":8408261,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trim iteration: 0\n","\n","Available device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248e4b4a05b745b8bec4d4d0c20686d7","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81040d7b922a411d9d1520dc72ef8c80","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:13<00:00,  3.47it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 0: 0.2918813239516201\n","Training accuracy - epoch 0: 0.9420164089618176\n","Epoch 1 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 1: 0.17572674501784857\n","Training accuracy - epoch 1: 0.9675765225623225\n","Epoch 2 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 2: 0.09208489120167904\n","Training accuracy - epoch 2: 0.9904544020195646\n","Epoch 3 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:17<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 3: 0.04437827785324826\n","Training accuracy - epoch 3: 0.995582202587567\n","Saving to bert_tuned\n","Available device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [05:42<00:00,  9.25it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trim iteration: 1\n","\n","Available device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:17<00:00,  3.45it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 0: 0.2798008643475421\n","Training accuracy - epoch 0: 0.9451719785421269\n","Epoch 1 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:15<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 1: 0.17136082900037097\n","Training accuracy - epoch 1: 0.9747554433575261\n","Epoch 2 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:17<00:00,  3.45it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 2: 0.09565143099605876\n","Training accuracy - epoch 2: 0.9898232881035027\n","Epoch 3 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 3: 0.0487357131660103\n","Training accuracy - epoch 3: 0.9944777532344589\n","Saving to bert_tuned\n","Available device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [05:39<00:00,  9.34it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trim iteration: 2\n","\n","Available device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 0: 0.28463609679580043\n","Training accuracy - epoch 0: 0.939255285579047\n","Epoch 1 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 1: 0.17092266601397052\n","Training accuracy - epoch 1: 0.9694698643105081\n","Epoch 2 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 2: 0.09294113519781308\n","Training accuracy - epoch 2: 0.9788576838119281\n","Epoch 3 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:15<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 3: 0.04711960811241721\n","Training accuracy - epoch 3: 0.992663300725781\n","Saving to bert_tuned\n","Available device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [05:38<00:00,  9.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trim iteration: 3\n","\n","Available device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:15<00:00,  3.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss at epoch 0: 0.28726212770738935\n","Training accuracy - epoch 0: 0.9418586304828022\n","Epoch 1 of 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3169/3169 [15:15<00:00,  3.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 1: 0.17944065833190365\n","Training accuracy - epoch 1: 0.9704165351846008\n","Epoch 2 of 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [15:17<00:00,  3.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 2: 0.10304525948977307\n","Training accuracy - epoch 2: 0.9884821710318713\n","Epoch 3 of 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 3: 0.05409115363065163\n","Training accuracy - epoch 3: 0.9932155254023352\n","Saving to bert_tuned\n","Available device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [05:39<00:00,  9.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trim iteration: 4\n","\n","Available device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 of 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [15:14<00:00,  3.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 0: 0.27980659451158163\n","Training accuracy - epoch 0: 0.9362574944777532\n","Epoch 1 of 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 1: 0.161798417035907\n","Training accuracy - epoch 1: 0.9822499211107605\n","Epoch 2 of 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 2: 0.08410414163297356\n","Training accuracy - epoch 2: 0.9930577469233196\n","Epoch 3 of 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [15:16<00:00,  3.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss at epoch 3: 0.041680796308409596\n","Training accuracy - epoch 3: 0.9962133165036289\n","Saving to bert_tuned\n","Available device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3169/3169 [05:39<00:00,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 8h 7min 43s, sys: 1h 21min 2s, total: 9h 28min 45s\n","Wall time: 7h 26min 22s\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["%%time\n","trim_model, trim_inds = trim(\n","    dataset='imdb',\n","    size=256,\n","    x=trn_x[rand_inds],\n","    x_att=trn_x_att[rand_inds],\n","    y=trn_y[rand_inds],\n","    num_remove=n_remove\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCmlKQPTSm54","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670053741043,"user_tz":300,"elapsed":1135,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"4c2c8806-de21-489c-eba9-2b15a498e6a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/storage/other/saved_models/victims_2.0/imdb_bert_FT_TRM_pois2.0_ind29.ckpt\n"]}],"source":["# Save trim model\n","save_pth = os.path.join(\n","    victim_dir,\n","    'imdb_bert_{}_TRM_pois{}_ind{}.ckpt'.format(m_type, pois_rate, cl_ind)\n",")\n","print(save_pth)\n","\n","torch.save(trim_model.state_dict(), save_pth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLN2RUyaSm54"},"outputs":[],"source":["# Evaluation\n","\n","pois_ds = TensorDataset(\n","    torch.from_numpy(xt_p),\n","    torch.from_numpy(xt_p_att),\n","    torch.from_numpy(yt_p)\n",")\n","\n","pois_dl = DataLoader(pois_ds, shuffle=False, batch_size=batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUEH046vSm55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670053745347,"user_tz":300,"elapsed":4303,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"5df5c93c-97bf-44a4-eb6f-15f463d8151d"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:04<00:00,  9.56it/s]\n"]}],"source":["trim_acc = bert_utils.predict_bert(trim_model, device, pois_dl, acc=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmYEXCZRSm55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670053745642,"user_tz":300,"elapsed":296,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"b7ae2e6b-4248-4718-87b3-a2df5bfa153c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of Trim model on the poisoned data: 0.9030303030303031\n"]}],"source":["print('Accuracy of Trim model on the poisoned data: {}'.format(trim_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTrCNXlFSm55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670053745643,"user_tz":300,"elapsed":6,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"76721c2d-6310-4919-8efe-8adbbdb97a11"},"outputs":[{"output_type":"stream","name":"stdout","text":["New targeted damage: 0.08484869696969688\n"]}],"source":["print('New targeted damage: {}'.format(base_def - trim_acc))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"248e4b4a05b745b8bec4d4d0c20686d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ff435b9b09049f7a507109b04a837ae","IPY_MODEL_653cf9e022f14aa0aaf03e75325eba72","IPY_MODEL_dd54ca7652df437db0899e760071c344"],"layout":"IPY_MODEL_cd11e24c35504934a5349a3d6aa52cea"}},"7ff435b9b09049f7a507109b04a837ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe3ea9603f9644a5b0cffd2c441eefd1","placeholder":"​","style":"IPY_MODEL_fed41405b92348e2bf4dd1c60997a9d0","value":"Downloading: 100%"}},"653cf9e022f14aa0aaf03e75325eba72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a070859a17349acb6c8e918f06d0be1","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6039ff53fdc456d9e2479d60016ed77","value":760}},"dd54ca7652df437db0899e760071c344":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea672036664d4b5a9d0b6ad4e010179d","placeholder":"​","style":"IPY_MODEL_55f990821fad430895254907534f1ad1","value":" 760/760 [00:00&lt;00:00, 30.7kB/s]"}},"cd11e24c35504934a5349a3d6aa52cea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe3ea9603f9644a5b0cffd2c441eefd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fed41405b92348e2bf4dd1c60997a9d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a070859a17349acb6c8e918f06d0be1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6039ff53fdc456d9e2479d60016ed77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea672036664d4b5a9d0b6ad4e010179d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f990821fad430895254907534f1ad1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81040d7b922a411d9d1520dc72ef8c80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac6cd0d9a3d049f7af1f3e3715455753","IPY_MODEL_85ec8d723afc478dbf685e731ba2cb3f","IPY_MODEL_fa182ba5c8a347b4affb839ccfab5c2b"],"layout":"IPY_MODEL_5a7061a4e4684ae68b6c084932a016d4"}},"ac6cd0d9a3d049f7af1f3e3715455753":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb56fcb5b4384f23977342a5d0e06561","placeholder":"​","style":"IPY_MODEL_dfa1e6c2d4f74af7ac8485a03f51adcd","value":"Downloading: 100%"}},"85ec8d723afc478dbf685e731ba2cb3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d76b0372547647f78daeba73c8cf7b61","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cdba2d4cefa4c40aadcf1cfcc4ce528","value":467042463}},"fa182ba5c8a347b4affb839ccfab5c2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa0bbd482a940b6ac5d3b6c99df85f5","placeholder":"​","style":"IPY_MODEL_f5dc137499704472a1c3b1600b6f8b27","value":" 445M/445M [00:21&lt;00:00, 22.5MB/s]"}},"5a7061a4e4684ae68b6c084932a016d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb56fcb5b4384f23977342a5d0e06561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa1e6c2d4f74af7ac8485a03f51adcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d76b0372547647f78daeba73c8cf7b61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cdba2d4cefa4c40aadcf1cfcc4ce528":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fa0bbd482a940b6ac5d3b6c99df85f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5dc137499704472a1c3b1600b6f8b27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}