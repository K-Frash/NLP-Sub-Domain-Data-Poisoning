{"cells":[{"cell_type":"markdown","metadata":{"id":"59Vmb2AtkNzp"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"sulD-2sJkQJC"},"source":["## System"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16951,"status":"ok","timestamp":1669965820272,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"jfQXSZebkLds","outputId":"f1b1139a-683e-4737-ace1-4f3a42e819a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1669965820468,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"kCQT9cPlkI5a","outputId":"7c1bda98-832f-4cb1-dcb8-885042f4fb4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Not connected to a GPU\n","\n","################################################################################\n","\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","print(\"\\n################################################################################\\n\")\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"kwdXdVkLX00V"},"source":["## GitHub"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1454,"status":"ok","timestamp":1669965821918,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"pKgq3FWyblhi","outputId":"a547a877-80af-4e4c-de90-279c9e8f8996"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n","Cloning into 'subpopulation-data-poisoning-attacks'...\n","remote: Enumerating objects: 137, done.\u001b[K\n","remote: Counting objects: 100% (137/137), done.\u001b[K\n","remote: Compressing objects: 100% (94/94), done.\u001b[K\n","remote: Total 137 (delta 77), reused 98 (delta 41), pack-reused 0\u001b[K\n","Receiving objects: 100% (137/137), 1.61 MiB | 4.17 MiB/s, done.\n","Resolving deltas: 100% (77/77), done.\n"]}],"source":["!ls\n","!git clone https://github.com/YunZhi246/subpopulation-data-poisoning-attacks.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1669965821919,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"a-Jc6ZbZj8QG","outputId":"4663e513-eacd-4e1f-b573-11e4f27e5cc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/subpopulation-data-poisoning-attacks\n"]}],"source":["%cd /content/subpopulation-data-poisoning-attacks"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38228,"status":"ok","timestamp":1669965860142,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"T3rXkcpLcP8o","outputId":"4e6f225e-65b6-43b1-dfda-108ebd4fdbe6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n","Collecting pandas==1.0.1\n","  Downloading pandas-1.0.1-cp38-cp38-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 7.9 MB/s \n","\u001b[?25hCollecting scikit-learn==0.22.1\n","  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[K     |████████████████████████████████| 7.0 MB 21.9 MB/s \n","\u001b[?25hCollecting scipy==1.4.1\n","  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n","\u001b[K     |████████████████████████████████| 26.0 MB 1.4 MB/s \n","\u001b[?25hCollecting seaborn==0.10.0\n","  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n","\u001b[K     |████████████████████████████████| 215 kB 57.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.12.1+cu113)\n","Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n","Collecting transformers==4.20.0\n","  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 42.7 MB/s \n","\u001b[?25hCollecting tables==3.6.1\n","  Downloading tables-3.6.1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 37.0 MB/s \n","\u001b[?25hCollecting datasets==2.7.1\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 47.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2022.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from seaborn==0.10.0->-r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 50.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2022.6.2)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.8/dist-packages (from tables==3.6.1->-r requirements.txt (line 9)) (2.8.4)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (9.0.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 74.0 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (3.8.3)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (0.3.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (2022.11.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.5.0->-r requirements.txt (line 6)) (4.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (2.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.1->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2022.9.24)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 61.1 MB/s \n","\u001b[?25hInstalling collected packages: urllib3, xxhash, tokenizers, scipy, responses, pandas, multiprocess, huggingface-hub, transformers, tables, seaborn, scikit-learn, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: tables\n","    Found existing installation: tables 3.7.0\n","    Uninstalling tables-3.7.0:\n","      Successfully uninstalled tables-3.7.0\n","  Attempting uninstall: seaborn\n","    Found existing installation: seaborn 0.11.2\n","    Uninstalling seaborn-0.11.2:\n","      Successfully uninstalled seaborn-0.11.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n","xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.1 which is incompatible.\n","prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n","plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n","plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n","mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n","jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n","google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\u001b[0m\n","Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 pandas-1.0.1 responses-0.18.0 scikit-learn-0.22.1 scipy-1.4.1 seaborn-0.10.0 tables-3.6.1 tokenizers-0.12.1 transformers-4.20.0 urllib3-1.25.11 xxhash-3.1.0\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"-V6Mh6DSkgrf"},"source":["# Train models"]},{"cell_type":"markdown","metadata":{"id":"Wfu_3QhzX7Eh"},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaZmOK79kfJK"},"outputs":[],"source":["# !python train_imdb_bert.py"]},{"cell_type":"markdown","metadata":{"id":"2oqQ4vVRX9-v"},"source":["# Attack"]},{"cell_type":"markdown","metadata":{"id":"i8eGZHMVWsl3"},"source":["## Perform Attack"]},{"cell_type":"markdown","metadata":{"id":"p9MC0ivQfUpC"},"source":["### 0.5 Poison Rate"]},{"cell_type":"markdown","metadata":{"id":"lj_1cb-LPiC7"},"source":["#### Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626897,"status":"ok","timestamp":1669444995324,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"kQwZ0mUn2gDJ","outputId":"b02573a2-34d7-4201-f73c-cd9566ef9a5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Performing sub-population poisoning attack, received arguments:\n","{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 0.5, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1}\n","\n","Creating directory: /content/drive/MyDrive/storage/other/saved_models/victims\n","Available device:  cuda\n","Available device:  cuda\n","Loading model: imdb_xlnet_FT_ADV.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n","100% 3/3 [00:00<00:00, 587.55it/s]\n","WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f700cd6f222bd13f.arrow\n","WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b23cfeb68a931a8d.arrow\n","100% 13/13 [00:05<00:00,  2.35ba/s]\n","100% 13/13 [00:05<00:00,  2.34ba/s]\n","100% 25/25 [00:10<00:00,  2.32ba/s]\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","\n","Getting def train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting adv train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting test representations\n","Available device:  cuda\n","Representation size:(25000, 256, 768)\n","\n","Computing predictions on the training sets\n","100% 3125/3125 [05:38<00:00,  9.22it/s]\n","100% 3125/3125 [05:37<00:00,  9.26it/s]\n","\n","Shapes\n","\tll: (12500, 196608)\n","\tll_ho: (12500, 196608)\n","\tll_t: (25000, 196608)\n","\n","Clustering ll_ho\n","tcmalloc: large alloc 9830400000 bytes == 0x7f450e100000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8615726 0x7f51c8608475 0x7f51c86b86ec 0x58f62c 0x510bf2 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c\n","tcmalloc: large alloc 9830400000 bytes == 0x7f42c2200000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8611cf5 0x7f51c8611e08 0x7f51c86d10f4 0x7f51c86d430c 0x7f51c885b3ac 0x7f51c885be10 0x5917ee 0x591ac9 0x7f51c86db2a6 0x4e50c9 0x50d124 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x4bad0a 0x7f51c85fc944 0x58f67f 0x50ff13 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37\n","\n","Clustering ll_t\n","tcmalloc: large alloc 19660800000 bytes == 0x7f3e2e400000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8611cf5 0x7f51c8611e08 0x7f51c86d10f4 0x7f51c86d430c 0x7f51c885b3ac 0x7f51c885be10 0x5917ee 0x591ac9 0x7f51c86db2a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","\n","Clustering ll\n","tcmalloc: large alloc 9830400000 bytes == 0x7f450e100000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8611cf5 0x7f51c8611e08 0x7f51c86d10f4 0x7f51c86d430c 0x7f51c885b3ac 0x7f51c885be10 0x5917ee 0x591ac9 0x7f51c86db2a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 43, 142, 106, 142,  47, 259, 188,  75, 217, 137,  99, 174, 118,\n","       145, 151,  97,  80,  61, 107, 144, 123, 212, 177, 177, 106, 104,\n","       152, 172,  27,  68, 211, 187,  34,  13, 227,  77, 169, 201,  92,\n","       169, 149,  91,  88, 172, 134,  77,  68,  75,  50, 105,  82, 235,\n","       149,  86, 181, 131, 121, 169,  43, 138, 151, 104, 142,  65, 134,\n","        94, 156,  77, 124, 193,  41, 190,  86, 121, 130, 103,  93, 118,\n","       178, 140, 162, 101, 138,  73,  89, 103, 191, 148, 117,  88, 162,\n","        76, 106, 105, 150,  74, 158, 137, 152, 156]))\n","ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 31, 172, 134, 181,  56, 252, 194, 104, 199, 130,  96, 159, 130,\n","       124, 127,  94,  92,  79, 118, 151, 153, 154, 153, 159, 128, 120,\n","       143, 200,  30,  85, 202, 181,  51,  12, 246,  95, 162, 205,  65,\n","       152, 121, 122,  95, 207, 112,  61,  69,  52,  28, 101,  79, 168,\n","       109,  79, 202, 124, 129, 170,  55, 146, 160,  93, 120,  65, 168,\n","        99, 160,  87, 134, 194,  32, 193,  99, 108, 126, 115,  70, 139,\n","       158, 137, 142,  82, 138,  78,  90, 114, 198, 128, 116, 101, 158,\n","       101,  84, 122, 143,  81, 165, 141, 156, 157]))\n","test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 86, 285, 230, 295, 101, 495, 328, 191, 360, 233, 244, 307, 244,\n","       327, 248, 194, 187, 105, 244, 324, 279, 455, 350, 340, 241, 194,\n","       311, 355,  78, 157, 376, 332, 112,  24, 464, 194, 398, 380, 169,\n","       323, 270, 203, 151, 384, 241, 163, 166, 155,  62, 200, 179, 437,\n","       272, 154, 358, 265, 265, 293, 143, 267, 326, 202, 324, 135, 307,\n","       177, 352, 193, 280, 353,  76, 351, 160, 248, 238, 227, 168, 237,\n","       324, 264, 265, 165, 284, 138, 171, 227, 318, 303, 235, 176, 315,\n","       207, 221, 206, 277, 166, 277, 295, 315, 309]))\n","\n","x shape: (12500, 256)\n","x_ho shape:(12500, 256)\n","x_t shape: (25000, 256)\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --setup"]},{"cell_type":"markdown","metadata":{"id":"X3mvaXFEPlAE"},"source":["#### Attack"]},{"cell_type":"markdown","metadata":{"id":"NXB3x-qKP3Y8"},"source":["Done: 30  \n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n","\n","\n","Pending: 0  \n","[]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oo_VIWH8HgH7"},"outputs":[],"source":["import time\n","\n","start = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6276624,"status":"ok","timestamp":1669737940870,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"nY_DadrDunU7","outputId":"3724f6bd-6c32-42af-a7ee-1e4c952e2185"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-11-29 14:21:07.843037: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n","Available device:  cuda\n","cluster ind: 25\n","train cluster size: 104\n","test cluster size: 194\n","pois cluster size 60\n","1 [ 447.65972805 -437.96363306]\n","\n","x coll shape: (24806, 256)\n","x_att coll shape:(24806, 256)\n","y coll shape: (24806,)\n","Training new model\n","Available device:  cuda\n","Downloading: 100% 760/760 [00:00<00:00, 750kB/s]\n","Downloading: 100% 445M/445M [00:07<00:00, 63.1MB/s]\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch 0 of 4\n","100% 1570/1570 [03:23<00:00,  7.72it/s]\n","Train loss at epoch 0: 0.26118005954179985\n","Training accuracy - epoch 0: 0.9480095541401274\n","Epoch 1 of 4\n","100% 1570/1570 [03:20<00:00,  7.83it/s]\n","Train loss at epoch 1: 0.16946462480392852\n","Training accuracy - epoch 1: 0.9707802547770701\n","Epoch 2 of 4\n","100% 1570/1570 [03:20<00:00,  7.83it/s]\n","Train loss at epoch 2: 0.1094163073609423\n","Training accuracy - epoch 2: 0.9852707006369427\n","Epoch 3 of 4\n","100% 1570/1570 [03:20<00:00,  7.84it/s]\n","Train loss at epoch 3: 0.0688366223999394\n","Training accuracy - epoch 3: 0.9894108280254778\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_25\n","Available device:  cuda\n","100% 1570/1570 [01:07<00:00, 23.13it/s]\n","100% 3125/3125 [02:15<00:00, 23.14it/s]\n","100% 25/25 [00:01<00:00, 23.77it/s]\n","Available device:  cuda\n","100% 3101/3101 [02:14<00:00, 23.11it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 25/25 [00:01<00:00, 23.14it/s]\n","Available device:  cuda\n","100% 3101/3101 [02:13<00:00, 23.25it/s]\n","Eval stats: {'train': 0.9894108280254778, 'test': 0.93444, 'pois': 0.9948453608247423, 'train_clus_size': (104,), 'test_clus_size': (194,), 'pois_clus_size': (60,), 'base_def': 1.0, 'collateral_dmg': 0.0005240667580423963}\n","\n","\n","Available device:  cuda\n","cluster ind: 56\n","train cluster size: 121\n","test cluster size: 265\n","pois cluster size 64\n","1 [ 475.87042975 -463.41330957]\n","\n","x coll shape: (24735, 256)\n","x_att coll shape:(24735, 256)\n","y coll shape: (24735,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1571/1571 [03:20<00:00,  7.83it/s]\n","Train loss at epoch 0: 0.262635453759481\n","Training accuracy - epoch 0: 0.9488383195416932\n","Epoch 1 of 4\n","100% 1571/1571 [03:20<00:00,  7.82it/s]\n","Train loss at epoch 1: 0.16671315707010825\n","Training accuracy - epoch 1: 0.9746180776575429\n","Epoch 2 of 4\n","100% 1571/1571 [03:21<00:00,  7.81it/s]\n","Train loss at epoch 2: 0.10130858789193654\n","Training accuracy - epoch 2: 0.98520050922979\n","Epoch 3 of 4\n","100% 1571/1571 [03:20<00:00,  7.82it/s]\n","Train loss at epoch 3: 0.06362500239017951\n","Training accuracy - epoch 3: 0.9894971355824316\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_56\n","Available device:  cuda\n","100% 1571/1571 [01:08<00:00, 23.05it/s]\n","100% 3125/3125 [02:15<00:00, 23.13it/s]\n","100% 34/34 [00:01<00:00, 22.73it/s]\n","Available device:  cuda\n","100% 3092/3092 [02:13<00:00, 23.14it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 34/34 [00:01<00:00, 22.89it/s]\n","Available device:  cuda\n","100% 3092/3092 [02:13<00:00, 23.15it/s]\n","Eval stats: {'train': 0.9894937917860553, 'test': 0.932, 'pois': 0.9962264150943396, 'train_clus_size': (121,), 'test_clus_size': (265,), 'pois_clus_size': (64,), 'base_def': 0.9962264150943396, 'collateral_dmg': 0.003032140691328067}\n","\n","\n","Available device:  cuda\n","cluster ind: 65\n","train cluster size: 94\n","test cluster size: 177\n","pois cluster size 49\n","1 [ 366.32870436 -363.60538483]\n","\n","x coll shape: (24823, 256)\n","x_att coll shape:(24823, 256)\n","y coll shape: (24823,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1569/1569 [03:20<00:00,  7.81it/s]\n","Train loss at epoch 0: 0.26668579499916883\n","Training accuracy - epoch 0: 0.954270235818993\n","Epoch 1 of 4\n","100% 1569/1569 [03:20<00:00,  7.82it/s]\n","Train loss at epoch 1: 0.16959784176928355\n","Training accuracy - epoch 1: 0.9731835564053537\n","Epoch 2 of 4\n","100% 1569/1569 [03:21<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.10712447521200201\n","Training accuracy - epoch 2: 0.9822339069471001\n","Epoch 3 of 4\n","100% 1569/1569 [03:21<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.06692998829105402\n","Training accuracy - epoch 3: 0.990152963671128\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_65\n","Available device:  cuda\n","100% 1569/1569 [01:08<00:00, 22.92it/s]\n","100% 3125/3125 [02:16<00:00, 22.92it/s]\n","100% 23/23 [00:00<00:00, 23.53it/s]\n","Available device:  cuda\n","100% 3103/3103 [02:15<00:00, 22.94it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 23/23 [00:01<00:00, 22.80it/s]\n","Available device:  cuda\n","100% 3103/3103 [02:15<00:00, 22.96it/s]\n","Eval stats: {'train': 0.9901984221850346, 'test': 0.93428, 'pois': 1.0, 'train_clus_size': (94,), 'test_clus_size': (177,), 'pois_clus_size': (49,), 'base_def': 1.0, 'collateral_dmg': 0.0007251339483543839}\n","\n","\n","Available device:  cuda\n","cluster ind: 78\n","train cluster size: 178\n","test cluster size: 324\n","pois cluster size 79\n","1 [ 597.61912298 -593.47862554]\n","\n","x coll shape: (24676, 256)\n","x_att coll shape:(24676, 256)\n","y coll shape: (24676,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1573/1573 [03:21<00:00,  7.82it/s]\n","Train loss at epoch 0: 0.2857542728379994\n","Training accuracy - epoch 0: 0.9485060394151303\n","Epoch 1 of 4\n","100% 1573/1573 [03:21<00:00,  7.82it/s]\n","Train loss at epoch 1: 0.17291226522116024\n","Training accuracy - epoch 1: 0.9663858868404323\n","Epoch 2 of 4\n","100% 1573/1573 [03:21<00:00,  7.79it/s]\n","Train loss at epoch 2: 0.11697166748253128\n","Training accuracy - epoch 2: 0.9827558804831532\n","Epoch 3 of 4\n","100% 1573/1573 [03:21<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.07460570467870745\n","Training accuracy - epoch 3: 0.9865702479338843\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_78\n","Available device:  cuda\n","100% 1573/1573 [01:08<00:00, 22.92it/s]\n","100% 3125/3125 [02:15<00:00, 22.98it/s]\n","100% 41/41 [00:01<00:00, 23.24it/s]\n","Available device:  cuda\n","100% 3085/3085 [02:14<00:00, 22.95it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 41/41 [00:01<00:00, 23.17it/s]\n","Available device:  cuda\n","100% 3085/3085 [02:13<00:00, 23.03it/s]\n","Eval stats: {'train': 0.986564909770252, 'test': 0.93308, 'pois': 0.9938271604938271, 'train_clus_size': (178,), 'test_clus_size': (324,), 'pois_clus_size': (79,), 'base_def': 0.9938271604938271, 'collateral_dmg': 0.0019452099205705675}\n","\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 26 --n_attack 4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1669737940871,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"hoj6dy8MusO5","outputId":"ae99792f-2f53-449f-856f-e46db2c5f9be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time taken: 104.608\n"]}],"source":["print(\"Time taken: {}\".format(round((time.time() - start)/60, 3)))"]},{"cell_type":"markdown","metadata":{"id":"NFZmEeNPe_C7"},"source":["#### Eval Only"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506183,"status":"ok","timestamp":1669738447021,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"4BuhucjCfA46","outputId":"b4625d95-2469-4680-8875-8440da1966f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-11-29 16:05:42.731279: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n","Available device:  cuda\n","cluster ind: 13\n","train cluster size: 145\n","test cluster size: 327\n","pois cluster size 62\n","0 [-31.59220918  -0.76336302]\n","\n","x coll shape: (24673, 256)\n","x_att coll shape:(24673, 256)\n","y coll shape: (24673,)\n","Loading model\n","Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_13.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Available device:  cuda\n","100% 1571/1571 [01:11<00:00, 21.95it/s]\n","100% 3125/3125 [02:19<00:00, 22.35it/s]\n","100% 41/41 [00:01<00:00, 22.41it/s]\n","Available device:  cuda\n","100% 3085/3085 [02:13<00:00, 23.03it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 41/41 [00:01<00:00, 22.63it/s]\n","Available device:  cuda\n","100% 3085/3085 [02:14<00:00, 22.88it/s]\n","Eval stats: {'train': 0.9926763254258876, 'test': 0.9328, 'pois': 0.691131498470948, 'train_clus_size': (145,), 'test_clus_size': (327,), 'pois_clus_size': (62,), 'base_def': 0.7033639143730887, 'collateral_dmg': 0.0020670368418919116}\n","\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 1 --n_attack 1 --eval_only"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1484574,"status":"ok","timestamp":1669739931858,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"UJM7hEmgJeSG","outputId":"32c9f336-e5e8-4f32-abe2-906d11e389db"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-11-29 16:14:09.315996: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n","Available device:  cuda\n","cluster ind: 38\n","train cluster size: 92\n","test cluster size: 169\n","pois cluster size 32\n","1 [ 99.92571146 -99.75787343]\n","\n","x coll shape: (24831, 256)\n","x_att coll shape:(24831, 256)\n","y coll shape: (24831,)\n","Loading model\n","Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_38.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Available device:  cuda\n","100% 1567/1567 [01:11<00:00, 21.93it/s]\n","100% 3125/3125 [02:19<00:00, 22.34it/s]\n","100% 22/22 [00:00<00:00, 23.14it/s]\n","Available device:  cuda\n","100% 3104/3104 [02:14<00:00, 23.02it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 22/22 [00:00<00:00, 22.73it/s]\n","Available device:  cuda\n","100% 3104/3104 [02:15<00:00, 22.84it/s]\n","Eval stats: {'train': 0.9947334822853495, 'test': 0.93336, 'pois': 0.8402366863905325, 'train_clus_size': (92,), 'test_clus_size': (169,), 'pois_clus_size': (32,), 'base_def': 0.8165680473372781, 'collateral_dmg': 0.0018122508155128392}\n","\n","\n","Available device:  cuda\n","cluster ind: 51\n","train cluster size: 235\n","test cluster size: 437\n","pois cluster size 84\n","1 [ 231.16976844 -222.08490889]\n","\n","x coll shape: (24563, 256)\n","x_att coll shape:(24563, 256)\n","y coll shape: (24563,)\n","Loading model\n","Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_51.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Available device:  cuda\n","100% 1573/1573 [01:08<00:00, 22.90it/s]\n","100% 3125/3125 [02:16<00:00, 22.91it/s]\n","100% 55/55 [00:02<00:00, 22.87it/s]\n","Available device:  cuda\n","100% 3071/3071 [02:13<00:00, 22.93it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 55/55 [00:02<00:00, 23.04it/s]\n","Available device:  cuda\n","100% 3071/3071 [02:14<00:00, 22.91it/s]\n","Eval stats: {'train': 0.9924507310870947, 'test': 0.93292, 'pois': 0.6910755148741419, 'train_clus_size': (235,), 'test_clus_size': (437,), 'pois_clus_size': (84,), 'base_def': 0.7254004576659039, 'collateral_dmg': 0.0015063306599356618}\n","\n","\n","Available device:  cuda\n","cluster ind: 61\n","train cluster size: 104\n","test cluster size: 202\n","pois cluster size 46\n","1 [ 151.78303122 -144.84906949]\n","\n","x coll shape: (24798, 256)\n","x_att coll shape:(24798, 256)\n","y coll shape: (24798,)\n","Loading model\n","Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_61.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Available device:  cuda\n","100% 1569/1569 [01:08<00:00, 23.01it/s]\n","100% 3125/3125 [02:15<00:00, 23.12it/s]\n","100% 26/26 [00:01<00:00, 23.51it/s]\n","Available device:  cuda\n","100% 3100/3100 [02:14<00:00, 23.12it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 26/26 [00:01<00:00, 22.73it/s]\n","Available device:  cuda\n","100% 3100/3100 [02:14<00:00, 23.12it/s]\n","Eval stats: {'train': 0.9936234656464211, 'test': 0.93448, 'pois': 0.7871287128712872, 'train_clus_size': (104,), 'test_clus_size': (202,), 'pois_clus_size': (46,), 'base_def': 0.8118811881188119, 'collateral_dmg': 0.00032260666182748476}\n","\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 2 --n_attack 3 --eval_only"]},{"cell_type":"markdown","metadata":{"id":"Z5lDQ4P5fXhD"},"source":["### 1.0 Poison Rate"]},{"cell_type":"markdown","metadata":{"id":"pMSyXClgUw7x"},"source":["#### Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":601473,"status":"ok","timestamp":1669741997515,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"KJ5mteAAuizB","outputId":"7df3c6d8-de28-41b4-c83b-86f9d2dada6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-11-29 17:03:19.733479: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Performing sub-population poisoning attack, received arguments:\n","{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 1.0, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1, 'eval_only': False}\n","\n","Creating directory: /content/drive/MyDrive/storage/other/saved_models/victims\n","Creating directory: /content/drive/MyDrive/storage/results/xlnet\n","Available device:  cuda\n","Available device:  cuda\n","Loading model: imdb_xlnet_FT_ADV.ckpt\n","Downloading: 100% 760/760 [00:00<00:00, 1.10MB/s]\n","Downloading: 100% 445M/445M [00:06<00:00, 72.4MB/s]\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading builder script: 100% 4.31k/4.31k [00:00<00:00, 4.77MB/s]\n","Downloading metadata: 100% 2.17k/2.17k [00:00<00:00, 2.63MB/s]\n","Downloading readme: 100% 7.59k/7.59k [00:00<00:00, 8.81MB/s]\n","Downloading and preparing dataset imdb/plain_text to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","Downloading data: 100% 84.1M/84.1M [00:01<00:00, 54.5MB/s]\n","Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","100% 3/3 [00:00<00:00, 340.11it/s]\n","Downloading: 100% 779k/779k [00:00<00:00, 2.61MB/s]\n","Downloading: 100% 1.32M/1.32M [00:00<00:00, 3.75MB/s]\n","100% 13/13 [00:03<00:00,  4.04ba/s]\n","100% 13/13 [00:03<00:00,  3.86ba/s]\n","100% 25/25 [00:06<00:00,  3.91ba/s]\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","\n","Getting def train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting adv train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting test representations\n","Available device:  cuda\n","Representation size:(25000, 256, 768)\n","\n","Computing predictions on the training sets\n","100% 3125/3125 [01:14<00:00, 42.16it/s]\n","100% 3125/3125 [01:11<00:00, 43.48it/s]\n","\n","Shapes\n","\tll: (12500, 196608)\n","\tll_ho: (12500, 196608)\n","\tll_t: (25000, 196608)\n","\n","Clustering ll_ho\n","tcmalloc: large alloc 9830400000 bytes == 0x7faf0e100000 @  0x7fbc83d8d1e7 0x7fbc136040ce 0x7fbc1365e726 0x7fbc13651475 0x7fbc137016ec 0x58f62c 0x510bf2 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c\n","tcmalloc: large alloc 9830400000 bytes == 0x7facbf300000 @  0x7fbc83d8d1e7 0x7fbc136040ce 0x7fbc1365acf5 0x7fbc1365ae08 0x7fbc1371a0f4 0x7fbc1371d30c 0x7fbc138a43ac 0x7fbc138a4e10 0x5917ee 0x591ac9 0x7fbc137242a6 0x4e50c9 0x50d124 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x4bad0a 0x7fbc13645944 0x58f67f 0x50ff13 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37\n","\n","Clustering ll_t\n","tcmalloc: large alloc 19660800000 bytes == 0x7fa82b500000 @  0x7fbc83d8d1e7 0x7fbc136040ce 0x7fbc1365acf5 0x7fbc1365ae08 0x7fbc1371a0f4 0x7fbc1371d30c 0x7fbc138a43ac 0x7fbc138a4e10 0x5917ee 0x591ac9 0x7fbc137242a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","\n","Clustering ll\n","tcmalloc: large alloc 9830400000 bytes == 0x7faf0e100000 @  0x7fbc83d8d1e7 0x7fbc136040ce 0x7fbc1365acf5 0x7fbc1365ae08 0x7fbc1371a0f4 0x7fbc1371d30c 0x7fbc138a43ac 0x7fbc138a4e10 0x5917ee 0x591ac9 0x7fbc137242a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 42, 145, 111, 144,  47, 261, 188,  76, 218, 139, 104, 171, 117,\n","       145, 150,  96,  80,  64, 107, 143, 140, 210, 171, 181, 106, 106,\n","       155, 170,  27,  64, 211, 199,  32,  13, 227,  86, 169, 203,  92,\n","       169, 155,  92,  92, 170, 134,  79,  59,  75,  50, 103,  72, 229,\n","       150,  86, 180, 121, 111, 169,  42, 138, 152, 105, 133,  73, 131,\n","        91, 159,  81, 124, 193,  40, 187,  87, 121, 131, 100,  94, 120,\n","       179, 144, 152, 100, 133,  74,  92, 112, 191, 163, 116,  79, 164,\n","        76, 105, 111, 149,  74, 157, 122, 147, 152]))\n","ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 31, 167, 138, 182,  56, 257, 194, 104, 198, 135, 102, 153, 131,\n","       126, 124,  93,  92,  79, 118, 151, 165, 149, 147, 160, 128, 121,\n","       138, 199,  30,  87, 197, 193,  51,  12, 246, 104, 168, 206,  65,\n","       149, 125, 124,  95, 208, 112,  63,  61,  52,  28, 104,  71, 150,\n","       110,  79, 194, 119, 123, 170,  53, 143, 160,  92, 121,  68, 167,\n","        94, 163,  88, 135, 199,  30, 190,  94, 108, 126, 118,  71, 139,\n","       161, 149, 131,  83, 134,  78,  90, 124, 200, 138, 117, 101, 164,\n","       101,  84, 125, 144,  81, 166, 125, 157, 154]))\n","test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 82, 275, 229, 297, 103, 509, 324, 191, 364, 237, 254, 299, 249,\n","       328, 244, 194, 187, 106, 244, 330, 308, 440, 333, 338, 241, 199,\n","       308, 352,  77, 165, 366, 362, 110,  24, 462, 207, 413, 383, 163,\n","       313, 267, 200, 157, 387, 241, 159, 151, 158,  62, 202, 174, 407,\n","       286, 152, 358, 251, 247, 297, 141, 260, 326, 200, 311, 141, 305,\n","       178, 355, 187, 278, 355,  80, 347, 163, 248, 236, 223, 169, 240,\n","       319, 278, 238, 170, 284, 143, 173, 234, 321, 322, 233, 178, 313,\n","       207, 222, 206, 290, 172, 279, 278, 321, 310]))\n","\n","x shape: (12500, 256)\n","x_ho shape:(12500, 256)\n","x_t shape: (25000, 256)\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78]\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 1 --n_clusters 100 --setup"]},{"cell_type":"markdown","metadata":{"id":"xzcVytT8Uy1C"},"source":["#### Attack"]},{"cell_type":"markdown","metadata":{"id":"4we2wLM8WWeY"},"source":["Done: 30  \n","[21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78]\n","\n","Pending: 0  \n","[]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvuThJ76VCJw"},"outputs":[],"source":["import time\n","start = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzw3ouH1JPpV","executionInfo":{"status":"ok","timestamp":1669794973196,"user_tz":300,"elapsed":9302406,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"07b16d24-5459-4ac4-b515-5d397cef3803"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-30 05:21:12.862002: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78]\n","\n","Available device:  cuda\n","cluster ind: 84\n","train cluster size: 92\n","test cluster size: 173\n","pois cluster size 90\n","1 [ 324.66239619 -313.6750102 ]\n","\n","x coll shape: (24827, 256)\n","x_att coll shape:(24827, 256)\n","y coll shape: (24827,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch 0 of 4\n","100% 1574/1574 [03:21<00:00,  7.83it/s]\n","Train loss at epoch 0: 0.2677999824229888\n","Training accuracy - epoch 0: 0.9522183396865735\n","Epoch 1 of 4\n","100% 1574/1574 [03:19<00:00,  7.87it/s]\n","Train loss at epoch 1: 0.16012285888938202\n","Training accuracy - epoch 1: 0.975195891571368\n","Epoch 2 of 4\n","100% 1574/1574 [03:20<00:00,  7.86it/s]\n","Train loss at epoch 2: 0.09273049847337948\n","Training accuracy - epoch 2: 0.9898348157560356\n","Epoch 3 of 4\n","100% 1574/1574 [03:20<00:00,  7.86it/s]\n","Train loss at epoch 3: 0.051677640541280614\n","Training accuracy - epoch 3: 0.9928526048284625\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_84\n","Available device:  cuda\n","100% 1574/1574 [01:08<00:00, 23.14it/s]\n","100% 3125/3125 [02:14<00:00, 23.17it/s]\n","100% 22/22 [00:00<00:00, 23.63it/s]\n","Available device:  cuda\n","100% 3104/3104 [02:13<00:00, 23.19it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 22/22 [00:00<00:00, 22.95it/s]\n","Available device:  cuda\n","100% 3104/3104 [02:13<00:00, 23.20it/s]\n","Eval stats: {'train': 0.9928514694201748, 'test': 0.93204, 'pois': 0.9884393063583815, 'train_clus_size': (92,), 'test_clus_size': (173,), 'pois_clus_size': (90,), 'base_def': 0.9942196531791907, 'collateral_dmg': 0.002940347202642246}\n","\n","\n","Available device:  cuda\n","cluster ind: 55\n","train cluster size: 121\n","test cluster size: 251\n","pois cluster size 119\n","1 [ 435.21694279 -439.22415352]\n","\n","x coll shape: (24749, 256)\n","x_att coll shape:(24749, 256)\n","y coll shape: (24749,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1578/1578 [03:20<00:00,  7.87it/s]\n","Train loss at epoch 0: 0.2891596460411578\n","Training accuracy - epoch 0: 0.9475602027883396\n","Epoch 1 of 4\n","100% 1578/1578 [03:20<00:00,  7.87it/s]\n","Train loss at epoch 1: 0.18414351798084072\n","Training accuracy - epoch 1: 0.9554816223067174\n","Epoch 2 of 4\n","100% 1578/1578 [03:20<00:00,  7.86it/s]\n","Train loss at epoch 2: 0.12068208687037527\n","Training accuracy - epoch 2: 0.979404309252218\n","Epoch 3 of 4\n","100% 1578/1578 [03:20<00:00,  7.86it/s]\n","Train loss at epoch 3: 0.07534151655150853\n","Training accuracy - epoch 3: 0.985424588086185\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_55\n","Available device:  cuda\n","100% 1578/1578 [01:08<00:00, 23.19it/s]\n","100% 3125/3125 [02:14<00:00, 23.22it/s]\n","100% 32/32 [00:01<00:00, 23.62it/s]\n","Available device:  cuda\n","100% 3094/3094 [02:13<00:00, 23.22it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 32/32 [00:01<00:00, 23.21it/s]\n","Available device:  cuda\n","100% 3094/3094 [02:13<00:00, 23.25it/s]\n","Eval stats: {'train': 0.9854188129011807, 'test': 0.9348, 'pois': 0.9880478087649402, 'train_clus_size': (121,), 'test_clus_size': (251,), 'pois_clus_size': (119,), 'base_def': 1.0, 'collateral_dmg': 8.08113459129789e-05}\n","\n","\n","Available device:  cuda\n","cluster ind: 56\n","train cluster size: 111\n","test cluster size: 247\n","pois cluster size 123\n","1 [ 453.21462083 -441.23036361]\n","\n","x coll shape: (24753, 256)\n","x_att coll shape:(24753, 256)\n","y coll shape: (24753,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1578/1578 [03:20<00:00,  7.86it/s]\n","Train loss at epoch 0: 0.2674533460113363\n","Training accuracy - epoch 0: 0.9485786710121311\n","Epoch 1 of 4\n","100% 1578/1578 [03:20<00:00,  7.88it/s]\n","Train loss at epoch 1: 0.1702279024822366\n","Training accuracy - epoch 1: 0.9711660329531052\n","Epoch 2 of 4\n","100% 1578/1578 [03:20<00:00,  7.87it/s]\n","Train loss at epoch 2: 0.10463005168459653\n","Training accuracy - epoch 2: 0.9843948035487959\n","Epoch 3 of 4\n","100% 1578/1578 [03:20<00:00,  7.87it/s]\n","Train loss at epoch 3: 0.06743021273956881\n","Training accuracy - epoch 3: 0.9895437262357415\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_56\n","Available device:  cuda\n","100% 1578/1578 [01:07<00:00, 23.30it/s]\n","100% 3125/3125 [02:14<00:00, 23.25it/s]\n","100% 31/31 [00:01<00:00, 23.34it/s]\n","Available device:  cuda\n","100% 3095/3095 [02:13<00:00, 23.24it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 31/31 [00:01<00:00, 22.93it/s]\n","Available device:  cuda\n","100% 3095/3095 [02:13<00:00, 23.24it/s]\n","Eval stats: {'train': 0.9895428978848134, 'test': 0.93416, 'pois': 0.9959514170040485, 'train_clus_size': (111,), 'test_clus_size': (247,), 'pois_clus_size': (123,), 'base_def': 0.9959514170040485, 'collateral_dmg': 0.0008483820143012633}\n","\n","\n","Available device:  cuda\n","cluster ind: 65\n","train cluster size: 91\n","test cluster size: 178\n","pois cluster size 94\n","1 [ 347.54711843 -345.27639055]\n","\n","x coll shape: (24822, 256)\n","x_att coll shape:(24822, 256)\n","y coll shape: (24822,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1575/1575 [03:20<00:00,  7.86it/s]\n","Train loss at epoch 0: 0.2701042461661356\n","Training accuracy - epoch 0: 0.9518253968253968\n","Epoch 1 of 4\n","100% 1575/1575 [03:20<00:00,  7.87it/s]\n","Train loss at epoch 1: 0.17194998890102384\n","Training accuracy - epoch 1: 0.9725396825396826\n","Epoch 2 of 4\n","100% 1575/1575 [03:19<00:00,  7.88it/s]\n","Train loss at epoch 2: 0.11091258918186502\n","Training accuracy - epoch 2: 0.9823015873015873\n","Epoch 3 of 4\n","100% 1575/1575 [03:19<00:00,  7.89it/s]\n","Train loss at epoch 3: 0.07120113851358405\n","Training accuracy - epoch 3: 0.9875396825396825\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_65\n","Available device:  cuda\n","100% 1575/1575 [01:07<00:00, 23.38it/s]\n","100% 3125/3125 [02:13<00:00, 23.39it/s]\n","100% 23/23 [00:00<00:00, 23.99it/s]\n","Available device:  cuda\n","100% 3103/3103 [02:12<00:00, 23.43it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 23/23 [00:00<00:00, 23.57it/s]\n","Available device:  cuda\n","100% 3103/3103 [02:12<00:00, 23.39it/s]\n","Eval stats: {'train': 0.9875337462283628, 'test': 0.9356, 'pois': 1.0, 'train_clus_size': (91,), 'test_clus_size': (178,), 'pois_clus_size': (94,), 'base_def': 1.0, 'collateral_dmg': -0.0006043026347595237}\n","\n","\n","Available device:  cuda\n","cluster ind: 11\n","train cluster size: 171\n","test cluster size: 299\n","pois cluster size 153\n","1 [ 569.35814595 -568.01781583]\n","\n","x coll shape: (24701, 256)\n","x_att coll shape:(24701, 256)\n","y coll shape: (24701,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1582/1582 [03:20<00:00,  7.89it/s]\n","Train loss at epoch 0: 0.295561981625271\n","Training accuracy - epoch 0: 0.9405341340075853\n","Epoch 1 of 4\n","100% 1582/1582 [03:20<00:00,  7.89it/s]\n","Train loss at epoch 1: 0.20060372408349939\n","Training accuracy - epoch 1: 0.9617572692793932\n","Epoch 2 of 4\n","100% 1582/1582 [03:20<00:00,  7.89it/s]\n","Train loss at epoch 2: 0.14716263271264224\n","Training accuracy - epoch 2: 0.9750316055625791\n","Epoch 3 of 4\n","100% 1582/1582 [03:20<00:00,  7.89it/s]\n","Train loss at epoch 3: 0.10840044802469208\n","Training accuracy - epoch 3: 0.9785872313527181\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_11\n","Available device:  cuda\n","100% 1582/1582 [01:07<00:00, 23.35it/s]\n","100% 3125/3125 [02:13<00:00, 23.39it/s]\n","100% 38/38 [00:01<00:00, 23.74it/s]\n","Available device:  cuda\n","100% 3088/3088 [02:11<00:00, 23.42it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 38/38 [00:01<00:00, 23.46it/s]\n","Available device:  cuda\n","100% 3088/3088 [02:11<00:00, 23.44it/s]\n","Eval stats: {'train': 0.9785821544297795, 'test': 0.93384, 'pois': 1.0, 'train_clus_size': (171,), 'test_clus_size': (299,), 'pois_clus_size': (153,), 'base_def': 1.0, 'collateral_dmg': 0.0011740415367798018}\n","\n","\n","Available device:  cuda\n","cluster ind: 78\n","train cluster size: 179\n","test cluster size: 319\n","pois cluster size 161\n","1 [ 608.39685512 -604.01255846]\n","\n","x coll shape: (24681, 256)\n","x_att coll shape:(24681, 256)\n","y coll shape: (24681,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1583/1583 [03:20<00:00,  7.89it/s]\n","Train loss at epoch 0: 0.2826648709444836\n","Training accuracy - epoch 0: 0.9445672773215413\n","Epoch 1 of 4\n","100% 1583/1583 [03:21<00:00,  7.86it/s]\n","Train loss at epoch 1: 0.18634844625448727\n","Training accuracy - epoch 1: 0.9658875552747946\n","Epoch 2 of 4\n","100% 1583/1583 [03:21<00:00,  7.86it/s]\n","Train loss at epoch 2: 0.12079245613361941\n","Training accuracy - epoch 2: 0.980811749842072\n","Epoch 3 of 4\n","100% 1583/1583 [03:21<00:00,  7.87it/s]\n","Train loss at epoch 3: 0.07692114264736351\n","Training accuracy - epoch 3: 0.9872867972204674\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_78\n","Available device:  cuda\n","100% 1583/1583 [01:08<00:00, 23.22it/s]\n","100% 3125/3125 [02:14<00:00, 23.23it/s]\n","100% 40/40 [00:01<00:00, 23.36it/s]\n","Available device:  cuda\n","100% 3086/3086 [02:12<00:00, 23.22it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 40/40 [00:01<00:00, 22.99it/s]\n","Available device:  cuda\n","100% 3086/3086 [02:12<00:00, 23.25it/s]\n","Eval stats: {'train': 0.9872837848511176, 'test': 0.93012, 'pois': 0.9216300940438872, 'train_clus_size': (179,), 'test_clus_size': (319,), 'pois_clus_size': (161,), 'base_def': 0.9937304075235109, 'collateral_dmg': 0.004011182691138981}\n","\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 1 --n_clusters 100 --no_setup --n_start 24 --n_attack 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4LLnHrfVH7M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669794973196,"user_tz":300,"elapsed":12,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"179d1f0e-09b4-4555-c74d-1aafd69e5bec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Time taken: 155.042\n"]}],"source":["print(\"Time taken: {}\".format(round((time.time() - start)/60, 3)))"]},{"cell_type":"markdown","metadata":{"id":"pbshFYkhfZg5"},"source":["### 2.0 Poison Rate"]},{"cell_type":"markdown","source":["#### Setup"],"metadata":{"id":"-pBFNyjSoKPq"}},{"cell_type":"code","source":["# !python attack_nlp.py --poison_rate 2 --n_clusters 100 --setup"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAIfQsokoL55","executionInfo":{"status":"ok","timestamp":1669797243947,"user_tz":300,"elapsed":566649,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"e07fd135-2ff5-46f5-e044-ad9e2d639bf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-30 08:24:41.134749: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Performing sub-population poisoning attack, received arguments:\n","{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 2.0, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1, 'eval_only': False}\n","\n","Creating directory: /content/drive/MyDrive/storage/other/saved_models/victims\n","Creating directory: /content/drive/MyDrive/storage/results/xlnet\n","Available device:  cuda\n","Available device:  cuda\n","Loading model: imdb_xlnet_FT_ADV.ckpt\n","Downloading: 100% 760/760 [00:00<00:00, 743kB/s]\n","Downloading: 100% 445M/445M [00:06<00:00, 70.8MB/s]\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading builder script: 100% 4.31k/4.31k [00:00<00:00, 3.27MB/s]\n","Downloading metadata: 100% 2.17k/2.17k [00:00<00:00, 1.49MB/s]\n","Downloading readme: 100% 7.59k/7.59k [00:00<00:00, 5.89MB/s]\n","Downloading and preparing dataset imdb/plain_text to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","Downloading data: 100% 84.1M/84.1M [00:02<00:00, 31.7MB/s]\n","Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","100% 3/3 [00:00<00:00, 326.37it/s]\n","Downloading: 100% 779k/779k [00:00<00:00, 4.68MB/s]\n","Downloading: 100% 1.32M/1.32M [00:00<00:00, 7.54MB/s]\n","100% 13/13 [00:03<00:00,  3.79ba/s]\n","100% 13/13 [00:03<00:00,  3.64ba/s]\n","100% 25/25 [00:06<00:00,  3.65ba/s]\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","\n","Getting def train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting adv train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting test representations\n","Available device:  cuda\n","Representation size:(25000, 256, 768)\n","\n","Computing predictions on the training sets\n","100% 3125/3125 [01:16<00:00, 40.98it/s]\n","100% 3125/3125 [01:14<00:00, 42.21it/s]\n","\n","Shapes\n","\tll: (12500, 196608)\n","\tll_ho: (12500, 196608)\n","\tll_t: (25000, 196608)\n","\n","Clustering ll_ho\n","tcmalloc: large alloc 9830400000 bytes == 0x7fe4f8100000 @  0x7ff26db7a1e7 0x7ff1fd3f10ce 0x7ff1fd44b726 0x7ff1fd43e475 0x7ff1fd4ee6ec 0x58f62c 0x510bf2 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c\n","tcmalloc: large alloc 9830400000 bytes == 0x7fe2a9300000 @  0x7ff26db7a1e7 0x7ff1fd3f10ce 0x7ff1fd447cf5 0x7ff1fd447e08 0x7ff1fd5070f4 0x7ff1fd50a30c 0x7ff1fd6913ac 0x7ff1fd691e10 0x5917ee 0x591ac9 0x7ff1fd5112a6 0x4e50c9 0x50d124 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x4bad0a 0x7ff1fd432944 0x58f67f 0x50ff13 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37\n","\n","Clustering ll_t\n","tcmalloc: large alloc 19660800000 bytes == 0x7fde15500000 @  0x7ff26db7a1e7 0x7ff1fd3f10ce 0x7ff1fd447cf5 0x7ff1fd447e08 0x7ff1fd5070f4 0x7ff1fd50a30c 0x7ff1fd6913ac 0x7ff1fd691e10 0x5917ee 0x591ac9 0x7ff1fd5112a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","\n","Clustering ll\n","tcmalloc: large alloc 9830400000 bytes == 0x7fe4f8100000 @  0x7ff26db7a1e7 0x7ff1fd3f10ce 0x7ff1fd447cf5 0x7ff1fd447e08 0x7ff1fd5070f4 0x7ff1fd50a30c 0x7ff1fd6913ac 0x7ff1fd691e10 0x5917ee 0x591ac9 0x7ff1fd5112a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 42, 145, 111, 144,  47, 261, 188,  76, 218, 139, 104, 171, 117,\n","       145, 150,  96,  80,  64, 107, 143, 140, 210, 171, 181, 106, 106,\n","       155, 170,  27,  64, 211, 199,  32,  13, 227,  86, 169, 203,  92,\n","       169, 155,  92,  92, 170, 134,  79,  59,  75,  50, 103,  72, 229,\n","       150,  86, 180, 121, 111, 169,  42, 138, 152, 105, 133,  73, 131,\n","        91, 159,  81, 124, 193,  40, 187,  87, 121, 131, 100,  94, 120,\n","       179, 144, 152, 100, 133,  74,  92, 112, 191, 163, 116,  79, 164,\n","        76, 105, 111, 149,  74, 157, 122, 147, 152]))\n","ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 31, 167, 138, 182,  56, 257, 194, 104, 198, 135, 102, 153, 131,\n","       126, 124,  93,  92,  79, 118, 151, 165, 149, 147, 160, 128, 121,\n","       138, 199,  30,  87, 197, 193,  51,  12, 246, 104, 168, 206,  65,\n","       149, 125, 124,  95, 208, 112,  63,  61,  52,  28, 104,  71, 150,\n","       110,  79, 194, 119, 123, 170,  53, 143, 160,  92, 121,  68, 167,\n","        94, 163,  88, 135, 199,  30, 190,  94, 108, 126, 118,  71, 139,\n","       161, 149, 131,  83, 134,  78,  90, 124, 200, 138, 117, 101, 164,\n","       101,  84, 125, 144,  81, 166, 125, 157, 154]))\n","test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 82, 275, 229, 297, 103, 509, 324, 191, 364, 237, 254, 299, 249,\n","       328, 244, 194, 187, 106, 244, 330, 308, 440, 333, 338, 241, 199,\n","       308, 352,  77, 165, 366, 362, 110,  24, 462, 207, 413, 383, 163,\n","       313, 267, 200, 157, 387, 241, 159, 151, 158,  62, 202, 174, 407,\n","       286, 152, 358, 251, 247, 297, 141, 260, 326, 200, 311, 141, 305,\n","       178, 355, 187, 278, 355,  80, 347, 163, 248, 236, 223, 169, 240,\n","       319, 278, 238, 170, 284, 143, 173, 234, 321, 322, 233, 178, 313,\n","       207, 222, 206, 290, 172, 279, 278, 321, 310]))\n","\n","x shape: (12500, 256)\n","x_ho shape:(12500, 256)\n","x_t shape: (25000, 256)\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78]\n","\n"]}]},{"cell_type":"markdown","source":["#### Attack"],"metadata":{"id":"YQ1KECYPoRTo"}},{"cell_type":"markdown","source":["Done: 16  \n","[21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, ]\n","\n","Pending: 24  \n","[83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78]"],"metadata":{"id":"0BER-MaDoVq-"}},{"cell_type":"code","source":["import time\n","start = time.time()"],"metadata":{"id":"N-gsIXBpoS_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !python attack_nlp.py --poison_rate 2 --n_clusters 100 --no_setup --n_start 16 --n_attack 14"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqFc_qkhoTV0","executionInfo":{"status":"ok","timestamp":1669916512567,"user_tz":300,"elapsed":22053363,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"622563a9-4727-4873-f60b-9eab5c1192e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-01 11:34:21.155521: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78]\n","\n","Available device:  cuda\n","cluster ind: 83\n","train cluster size: 74\n","test cluster size: 143\n","pois cluster size 156\n","1 [ 252.89329931 -243.28672013]\n","\n","x coll shape: (24857, 256)\n","x_att coll shape:(24857, 256)\n","y coll shape: (24857,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch 0 of 4\n","100% 1582/1582 [03:24<00:00,  7.75it/s]\n","Train loss at epoch 0: 0.27605799120213886\n","Training accuracy - epoch 0: 0.9506163084702908\n","Epoch 1 of 4\n","100% 1582/1582 [03:22<00:00,  7.82it/s]\n","Train loss at epoch 1: 0.16191017907112837\n","Training accuracy - epoch 1: 0.9756637168141593\n","Epoch 2 of 4\n","100% 1582/1582 [03:22<00:00,  7.81it/s]\n","Train loss at epoch 2: 0.09696573256111707\n","Training accuracy - epoch 2: 0.9864096080910241\n","Epoch 3 of 4\n","100% 1582/1582 [03:22<00:00,  7.82it/s]\n","Train loss at epoch 3: 0.055868595961989675\n","Training accuracy - epoch 3: 0.993046776232617\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_83\n","Available device:  cuda\n","100% 1582/1582 [01:08<00:00, 23.03it/s]\n","100% 3125/3125 [02:15<00:00, 23.07it/s]\n","100% 18/18 [00:00<00:00, 23.23it/s]\n","Available device:  cuda\n","100% 3108/3108 [02:14<00:00, 23.12it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 18/18 [00:00<00:00, 22.69it/s]\n","Available device:  cuda\n","100% 3108/3108 [02:14<00:00, 23.05it/s]\n","Eval stats: {'train': 0.993046776232617, 'test': 0.93244, 'pois': 0.8811188811188811, 'train_clus_size': (74,), 'test_clus_size': (143,), 'pois_clus_size': (156,), 'base_def': 0.972027972027972, 'collateral_dmg': 0.002051735929516907}\n","\n","\n","Available device:  cuda\n","cluster ind: 35\n","train cluster size: 86\n","test cluster size: 207\n","pois cluster size 208\n","1 [ 329.04326689 -330.06838083]\n","\n","x coll shape: (24793, 256)\n","x_att coll shape:(24793, 256)\n","y coll shape: (24793,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1589/1589 [03:23<00:00,  7.80it/s]\n","Train loss at epoch 0: 0.29172881827452335\n","Training accuracy - epoch 0: 0.9422592825676526\n","Epoch 1 of 4\n","100% 1589/1589 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 1: 0.17673321921071256\n","Training accuracy - epoch 1: 0.9738042794210195\n","Epoch 2 of 4\n","100% 1589/1589 [03:23<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.10130877161122767\n","Training accuracy - epoch 2: 0.987885462555066\n","Epoch 3 of 4\n","100% 1589/1589 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.05417722211267138\n","Training accuracy - epoch 3: 0.9928414096916299\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_35\n","Available device:  cuda\n","100% 1589/1589 [01:09<00:00, 23.01it/s]\n","100% 3125/3125 [02:15<00:00, 23.03it/s]\n","100% 26/26 [00:01<00:00, 23.20it/s]\n","Available device:  cuda\n","100% 3100/3100 [02:14<00:00, 23.06it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 26/26 [00:01<00:00, 22.81it/s]\n","Available device:  cuda\n","100% 3100/3100 [02:14<00:00, 23.04it/s]\n","Eval stats: {'train': 0.9928391564368901, 'test': 0.92976, 'pois': 0.9178743961352657, 'train_clus_size': (86,), 'test_clus_size': (207,), 'pois_clus_size': (208,), 'base_def': 0.9951690821256038, 'collateral_dmg': 0.004638406001694073}\n","\n","\n","Available device:  cuda\n","cluster ind: 54\n","train cluster size: 180\n","test cluster size: 358\n","pois cluster size 388\n","1 [ 625.38582385 -615.12308264]\n","\n","x coll shape: (24642, 256)\n","x_att coll shape:(24642, 256)\n","y coll shape: (24642,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1611/1611 [03:26<00:00,  7.79it/s]\n","Train loss at epoch 0: 0.30277667014988535\n","Training accuracy - epoch 0: 0.9307107386716326\n","Epoch 1 of 4\n","100% 1611/1611 [03:26<00:00,  7.80it/s]\n","Train loss at epoch 1: 0.18962652738709615\n","Training accuracy - epoch 1: 0.9711359404096834\n","Epoch 2 of 4\n","100% 1611/1611 [03:26<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.11540954002628102\n","Training accuracy - epoch 2: 0.9844040968342644\n","Epoch 3 of 4\n","100% 1611/1611 [03:26<00:00,  7.80it/s]\n","Train loss at epoch 3: 0.06308872455912848\n","Training accuracy - epoch 3: 0.9928615766604594\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_54\n","Available device:  cuda\n","100% 1611/1611 [01:09<00:00, 23.05it/s]\n","100% 3125/3125 [02:15<00:00, 23.02it/s]\n","100% 45/45 [00:01<00:00, 23.14it/s]\n","Available device:  cuda\n","100% 3081/3081 [02:13<00:00, 23.07it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 45/45 [00:01<00:00, 22.99it/s]\n","Available device:  cuda\n","100% 3081/3081 [02:13<00:00, 23.07it/s]\n","Eval stats: {'train': 0.9928615766604594, 'test': 0.92564, 'pois': 0.946927374301676, 'train_clus_size': (180,), 'test_clus_size': (358,), 'pois_clus_size': (388,), 'base_def': 0.9832402234636871, 'collateral_dmg': 0.008968427887346864}\n","\n","\n","Available device:  cuda\n","cluster ind: 75\n","train cluster size: 100\n","test cluster size: 223\n","pois cluster size 236\n","0 [-413.33432341  373.57068062]\n","\n","x coll shape: (24777, 256)\n","x_att coll shape:(24777, 256)\n","y coll shape: (24777,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1592/1592 [03:24<00:00,  7.80it/s]\n","Train loss at epoch 0: 0.30329406566697936\n","Training accuracy - epoch 0: 0.9410332914572864\n","Epoch 1 of 4\n","100% 1592/1592 [03:24<00:00,  7.80it/s]\n","Train loss at epoch 1: 0.19803399049259263\n","Training accuracy - epoch 1: 0.9638819095477387\n","Epoch 2 of 4\n","100% 1592/1592 [03:24<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.11839254391249492\n","Training accuracy - epoch 2: 0.9825690954773869\n","Epoch 3 of 4\n","100% 1592/1592 [03:24<00:00,  7.80it/s]\n","Train loss at epoch 3: 0.06814657845774234\n","Training accuracy - epoch 3: 0.9907349246231156\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_75\n","Available device:  cuda\n","100% 1592/1592 [01:09<00:00, 23.00it/s]\n","100% 3125/3125 [02:15<00:00, 23.01it/s]\n","100% 28/28 [00:01<00:00, 23.12it/s]\n","Available device:  cuda\n","100% 3098/3098 [02:14<00:00, 23.04it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 28/28 [00:01<00:00, 22.84it/s]\n","Available device:  cuda\n","100% 3098/3098 [02:14<00:00, 23.07it/s]\n","Eval stats: {'train': 0.9907349246231156, 'test': 0.92964, 'pois': 0.9775784753363229, 'train_clus_size': (100,), 'test_clus_size': (223,), 'pois_clus_size': (236,), 'base_def': 0.9955156950672646, 'collateral_dmg': 0.00524680146910439}\n","\n","\n","Available device:  cuda\n","cluster ind: 29\n","train cluster size: 64\n","test cluster size: 165\n","pois cluster size 174\n","1 [ 317.90230727 -317.40503192]\n","\n","x coll shape: (24835, 256)\n","x_att coll shape:(24835, 256)\n","y coll shape: (24835,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1585/1585 [03:23<00:00,  7.80it/s]\n","Train loss at epoch 0: 0.28084107001696945\n","Training accuracy - epoch 0: 0.9400630914826499\n","Epoch 1 of 4\n","100% 1585/1585 [03:23<00:00,  7.80it/s]\n","Train loss at epoch 1: 0.1750357309747076\n","Training accuracy - epoch 1: 0.9623028391167192\n","Epoch 2 of 4\n","100% 1585/1585 [03:23<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.1095676355033067\n","Training accuracy - epoch 2: 0.9820189274447949\n","Epoch 3 of 4\n","100% 1585/1585 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.06764701516136133\n","Training accuracy - epoch 3: 0.9864353312302839\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_29\n","Available device:  cuda\n","100% 1585/1585 [01:08<00:00, 23.05it/s]\n","100% 3125/3125 [02:15<00:00, 23.05it/s]\n","100% 21/21 [00:00<00:00, 23.31it/s]\n","Available device:  cuda\n","100% 3105/3105 [02:14<00:00, 23.02it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 21/21 [00:00<00:00, 22.76it/s]\n","Available device:  cuda\n","100% 3105/3105 [02:14<00:00, 23.10it/s]\n","Eval stats: {'train': 0.986428909578665, 'test': 0.92472, 'pois': 0.696969696969697, 'train_clus_size': (64,), 'test_clus_size': (165,), 'pois_clus_size': (174,), 'base_def': 0.9878787878787879, 'collateral_dmg': 0.00841554258103483}\n","\n","\n","Available device:  cuda\n","cluster ind: 5\n","train cluster size: 261\n","test cluster size: 509\n","pois cluster size 514\n","1 [ 929.19924116 -925.77207565]\n","\n","x coll shape: (24491, 256)\n","x_att coll shape:(24491, 256)\n","y coll shape: (24491,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1627/1627 [03:28<00:00,  7.80it/s]\n","Train loss at epoch 0: 0.36135523200044256\n","Training accuracy - epoch 0: 0.9037338660110633\n","Epoch 1 of 4\n","100% 1627/1627 [03:28<00:00,  7.80it/s]\n","Train loss at epoch 1: 0.2690491580444983\n","Training accuracy - epoch 1: 0.9369237861094039\n","Epoch 2 of 4\n","100% 1627/1627 [03:28<00:00,  7.79it/s]\n","Train loss at epoch 2: 0.19923548437895386\n","Training accuracy - epoch 2: 0.9556443351772177\n","Epoch 3 of 4\n","100% 1627/1627 [03:28<00:00,  7.80it/s]\n","Train loss at epoch 3: 0.13929241716065494\n","Training accuracy - epoch 3: 0.9696527350952674\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_5\n","Available device:  cuda\n","100% 1627/1627 [01:10<00:00, 23.05it/s]\n","100% 3125/3125 [02:15<00:00, 23.13it/s]\n","100% 64/64 [00:02<00:00, 23.18it/s]\n","Available device:  cuda\n","100% 3062/3062 [02:12<00:00, 23.12it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 64/64 [00:02<00:00, 22.91it/s]\n","Available device:  cuda\n","100% 3062/3062 [02:12<00:00, 23.14it/s]\n","Eval stats: {'train': 0.9696480713078224, 'test': 0.92892, 'pois': 0.9567779960707269, 'train_clus_size': (261,), 'test_clus_size': (509,), 'pois_clus_size': (514,), 'base_def': 0.9960707269155207, 'collateral_dmg': 0.005389735004695639}\n","\n","\n","Available device:  cuda\n","cluster ind: 98\n","train cluster size: 147\n","test cluster size: 321\n","pois cluster size 314\n","1 [ 563.6822319  -563.83649087]\n","\n","x coll shape: (24679, 256)\n","x_att coll shape:(24679, 256)\n","y coll shape: (24679,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1602/1602 [03:25<00:00,  7.79it/s]\n","Train loss at epoch 0: 0.32403312195859824\n","Training accuracy - epoch 0: 0.9212702871410736\n","Epoch 1 of 4\n","100% 1602/1602 [03:25<00:00,  7.79it/s]\n","Train loss at epoch 1: 0.22256341463968754\n","Training accuracy - epoch 1: 0.9548220973782772\n","Epoch 2 of 4\n","100% 1602/1602 [03:25<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.1513253873683275\n","Training accuracy - epoch 2: 0.9744069912609239\n","Epoch 3 of 4\n","100% 1602/1602 [03:25<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.09337566486898735\n","Training accuracy - epoch 3: 0.9798689138576779\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_98\n","Available device:  cuda\n","100% 1602/1602 [01:09<00:00, 23.02it/s]\n","100% 3125/3125 [02:15<00:00, 23.07it/s]\n","100% 41/41 [00:01<00:00, 23.50it/s]\n","Available device:  cuda\n","100% 3085/3085 [02:13<00:00, 23.07it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 41/41 [00:01<00:00, 23.14it/s]\n","Available device:  cuda\n","100% 3085/3085 [02:13<00:00, 23.09it/s]\n","Eval stats: {'train': 0.9798657718120806, 'test': 0.91872, 'pois': 0.8847352024922118, 'train_clus_size': (147,), 'test_clus_size': (321,), 'pois_clus_size': (314,), 'base_def': 1.0, 'collateral_dmg': 0.014992503748125885}\n","\n","\n","Available device:  cuda\n","cluster ind: 25\n","train cluster size: 106\n","test cluster size: 199\n","pois cluster size 242\n","1 [ 442.34927893 -430.01353264]\n","\n","x coll shape: (24801, 256)\n","x_att coll shape:(24801, 256)\n","y coll shape: (24801,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1593/1593 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 0: 0.29550171244833373\n","Training accuracy - epoch 0: 0.9359437120736556\n","Epoch 1 of 4\n","100% 1593/1593 [03:24<00:00,  7.78it/s]\n","Train loss at epoch 1: 0.19637868135415687\n","Training accuracy - epoch 1: 0.9620213433772756\n","Epoch 2 of 4\n","100% 1593/1593 [03:24<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.1199439344177875\n","Training accuracy - epoch 2: 0.9818738229755178\n","Epoch 3 of 4\n","100% 1593/1593 [03:24<00:00,  7.80it/s]\n","Train loss at epoch 3: 0.07491636172742908\n","Training accuracy - epoch 3: 0.9904268675455116\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_25\n","Available device:  cuda\n","100% 1593/1593 [01:09<00:00, 23.01it/s]\n","100% 3125/3125 [02:15<00:00, 22.99it/s]\n","100% 25/25 [00:01<00:00, 22.99it/s]\n","Available device:  cuda\n","100% 3101/3101 [02:14<00:00, 23.04it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 25/25 [00:01<00:00, 22.53it/s]\n","Available device:  cuda\n","100% 3101/3101 [02:14<00:00, 23.03it/s]\n","Eval stats: {'train': 0.9904253649348611, 'test': 0.92364, 'pois': 0.864321608040201, 'train_clus_size': (106,), 'test_clus_size': (199,), 'pois_clus_size': (242,), 'base_def': 0.9949748743718593, 'collateral_dmg': 0.01040280633845414}\n","\n","\n","Available device:  cuda\n","cluster ind: 84\n","train cluster size: 92\n","test cluster size: 173\n","pois cluster size 180\n","1 [ 324.66239619 -313.6750102 ]\n","\n","x coll shape: (24827, 256)\n","x_att coll shape:(24827, 256)\n","y coll shape: (24827,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1585/1585 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 0: 0.2882525018583807\n","Training accuracy - epoch 0: 0.9477917981072556\n","Epoch 1 of 4\n","100% 1585/1585 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 1: 0.17563405778135646\n","Training accuracy - epoch 1: 0.9687697160883281\n","Epoch 2 of 4\n","100% 1585/1585 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 2: 0.09809437877996545\n","Training accuracy - epoch 2: 0.98903785488959\n","Epoch 3 of 4\n","100% 1585/1585 [03:23<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.05821507841995726\n","Training accuracy - epoch 3: 0.9929810725552051\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_84\n","Available device:  cuda\n","100% 1585/1585 [01:08<00:00, 23.03it/s]\n","100% 3125/3125 [02:15<00:00, 23.02it/s]\n","100% 22/22 [00:00<00:00, 23.55it/s]\n","Available device:  cuda\n","100% 3104/3104 [02:14<00:00, 23.08it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 22/22 [00:00<00:00, 22.33it/s]\n","Available device:  cuda\n","100% 3104/3104 [02:14<00:00, 23.04it/s]\n","Eval stats: {'train': 0.9929810725552051, 'test': 0.9288, 'pois': 0.9595375722543352, 'train_clus_size': (92,), 'test_clus_size': (173,), 'pois_clus_size': (180,), 'base_def': 0.9942196531791907, 'collateral_dmg': 0.006001530591694504}\n","\n","\n","Available device:  cuda\n","cluster ind: 55\n","train cluster size: 121\n","test cluster size: 251\n","pois cluster size 238\n","1 [ 435.21694279 -439.22415352]\n","\n","x coll shape: (24749, 256)\n","x_att coll shape:(24749, 256)\n","y coll shape: (24749,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1593/1593 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 0: 0.31711978395279483\n","Training accuracy - epoch 0: 0.9351067168863779\n","Epoch 1 of 4\n","100% 1593/1593 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 1: 0.21139069980013897\n","Training accuracy - epoch 1: 0.959353421217828\n","Epoch 2 of 4\n","100% 1593/1593 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 2: 0.13058233632336616\n","Training accuracy - epoch 2: 0.9843063402385436\n","Epoch 3 of 4\n","100% 1593/1593 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.07815191517731646\n","Training accuracy - epoch 3: 0.9879943502824858\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_55\n","Available device:  cuda\n","100% 1593/1593 [01:09<00:00, 23.06it/s]\n","100% 3125/3125 [02:15<00:00, 23.08it/s]\n","100% 32/32 [00:01<00:00, 23.51it/s]\n","Available device:  cuda\n","100% 3094/3094 [02:13<00:00, 23.09it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 32/32 [00:01<00:00, 22.90it/s]\n","Available device:  cuda\n","100% 3094/3094 [02:14<00:00, 23.05it/s]\n","Eval stats: {'train': 0.9879886952425813, 'test': 0.92636, 'pois': 0.7450199203187251, 'train_clus_size': (121,), 'test_clus_size': (251,), 'pois_clus_size': (238,), 'base_def': 1.0, 'collateral_dmg': 0.006141662289385397}\n","\n","\n","Available device:  cuda\n","cluster ind: 56\n","train cluster size: 111\n","test cluster size: 247\n","pois cluster size 246\n","1 [ 453.21462083 -441.23036361]\n","\n","x coll shape: (24753, 256)\n","x_att coll shape:(24753, 256)\n","y coll shape: (24753,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1594/1594 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 0: 0.2908128211391597\n","Training accuracy - epoch 0: 0.9392252195734002\n","Epoch 1 of 4\n","100% 1594/1594 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 1: 0.18467917091942332\n","Training accuracy - epoch 1: 0.9647898368883312\n","Epoch 2 of 4\n","100% 1594/1594 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 2: 0.10971055115667175\n","Training accuracy - epoch 2: 0.9865903387703889\n","Epoch 3 of 4\n","100% 1594/1594 [03:24<00:00,  7.79it/s]\n","Train loss at epoch 3: 0.06065167690898377\n","Training accuracy - epoch 3: 0.9916875784190715\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_56\n","Available device:  cuda\n","100% 1594/1594 [01:08<00:00, 23.24it/s]\n","100% 3125/3125 [02:14<00:00, 23.25it/s]\n","100% 31/31 [00:01<00:00, 23.39it/s]\n","Available device:  cuda\n","100% 3095/3095 [02:13<00:00, 23.25it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 31/31 [00:01<00:00, 22.76it/s]\n","Available device:  cuda\n","100% 3095/3095 [02:13<00:00, 23.26it/s]\n","Eval stats: {'train': 0.9916836654636749, 'test': 0.93012, 'pois': 0.9473684210526315, 'train_clus_size': (111,), 'test_clus_size': (247,), 'pois_clus_size': (246,), 'base_def': 0.9959514170040485, 'collateral_dmg': 0.004443905789197289}\n","\n","\n","Available device:  cuda\n","cluster ind: 65\n","train cluster size: 91\n","test cluster size: 178\n","pois cluster size 188\n","1 [ 347.54711843 -345.27639055]\n","\n","x coll shape: (24822, 256)\n","x_att coll shape:(24822, 256)\n","y coll shape: (24822,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1586/1586 [03:22<00:00,  7.82it/s]\n","Train loss at epoch 0: 0.2869322389560372\n","Training accuracy - epoch 0: 0.939312736443884\n","Epoch 1 of 4\n","100% 1586/1586 [03:22<00:00,  7.82it/s]\n","Train loss at epoch 1: 0.1933120471697822\n","Training accuracy - epoch 1: 0.9657944514501892\n","Epoch 2 of 4\n","100% 1586/1586 [03:22<00:00,  7.82it/s]\n","Train loss at epoch 2: 0.11955735887093105\n","Training accuracy - epoch 2: 0.9840006305170239\n","Epoch 3 of 4\n","100% 1586/1586 [03:22<00:00,  7.83it/s]\n","Train loss at epoch 3: 0.07204367130477167\n","Training accuracy - epoch 3: 0.9886506935687264\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_65\n","Available device:  cuda\n","100% 1586/1586 [01:08<00:00, 23.10it/s]\n","100% 3125/3125 [02:14<00:00, 23.22it/s]\n","100% 23/23 [00:00<00:00, 23.79it/s]\n","Available device:  cuda\n","100% 3103/3103 [02:13<00:00, 23.24it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 23/23 [00:00<00:00, 23.01it/s]\n","Available device:  cuda\n","100% 3103/3103 [02:13<00:00, 23.16it/s]\n","Eval stats: {'train': 0.9886506935687264, 'test': 0.9278, 'pois': 0.7752808988764045, 'train_clus_size': (91,), 'test_clus_size': (178,), 'pois_clus_size': (188,), 'base_def': 1.0, 'collateral_dmg': 0.005640157924421851}\n","\n","\n","Available device:  cuda\n","cluster ind: 11\n","train cluster size: 171\n","test cluster size: 299\n","pois cluster size 306\n","1 [ 569.35814595 -568.01781583]\n","\n","x coll shape: (24701, 256)\n","x_att coll shape:(24701, 256)\n","y coll shape: (24701,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1601/1601 [03:24<00:00,  7.81it/s]\n","Train loss at epoch 0: 0.31556544675003695\n","Training accuracy - epoch 0: 0.9323860087445347\n","Epoch 1 of 4\n","100% 1601/1601 [03:25<00:00,  7.81it/s]\n","Train loss at epoch 1: 0.21638389423880483\n","Training accuracy - epoch 1: 0.9564334790755777\n","Epoch 2 of 4\n","100% 1601/1601 [03:24<00:00,  7.83it/s]\n","Train loss at epoch 2: 0.14734898470569027\n","Training accuracy - epoch 2: 0.9761867582760775\n","Epoch 3 of 4\n","100% 1601/1601 [03:24<00:00,  7.83it/s]\n","Train loss at epoch 3: 0.09135458744954153\n","Training accuracy - epoch 3: 0.9831355402873204\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_11\n","Available device:  cuda\n","100% 1601/1601 [01:09<00:00, 23.08it/s]\n","100% 3125/3125 [02:14<00:00, 23.16it/s]\n","100% 38/38 [00:01<00:00, 23.53it/s]\n","Available device:  cuda\n","100% 3088/3088 [02:13<00:00, 23.15it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 38/38 [00:01<00:00, 23.15it/s]\n","Available device:  cuda\n","100% 3088/3088 [02:12<00:00, 23.23it/s]\n","Eval stats: {'train': 0.9831329064501015, 'test': 0.92224, 'pois': 0.8862876254180602, 'train_clus_size': (171,), 'test_clus_size': (299,), 'pois_clus_size': (306,), 'base_def': 1.0, 'collateral_dmg': 0.011537994413181596}\n","\n","\n","Available device:  cuda\n","cluster ind: 78\n","train cluster size: 179\n","test cluster size: 319\n","pois cluster size 322\n","1 [ 608.39685512 -604.01255846]\n","\n","x coll shape: (24681, 256)\n","x_att coll shape:(24681, 256)\n","y coll shape: (24681,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1603/1603 [03:25<00:00,  7.81it/s]\n","Train loss at epoch 0: 0.30657774317226444\n","Training accuracy - epoch 0: 0.9265439800374298\n","Epoch 1 of 4\n","100% 1603/1603 [03:25<00:00,  7.81it/s]\n","Train loss at epoch 1: 0.19974073389875083\n","Training accuracy - epoch 1: 0.9638178415470992\n","Epoch 2 of 4\n","100% 1603/1603 [03:25<00:00,  7.80it/s]\n","Train loss at epoch 2: 0.12143874390471113\n","Training accuracy - epoch 2: 0.9811291328758578\n","Epoch 3 of 4\n","100% 1603/1603 [03:24<00:00,  7.82it/s]\n","Train loss at epoch 3: 0.06734377252022519\n","Training accuracy - epoch 3: 0.9917342482844667\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_78\n","Available device:  cuda\n","100% 1603/1603 [01:09<00:00, 23.20it/s]\n","100% 3125/3125 [02:14<00:00, 23.17it/s]\n","100% 40/40 [00:01<00:00, 23.31it/s]\n","Available device:  cuda\n","100% 3086/3086 [02:12<00:00, 23.25it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 40/40 [00:01<00:00, 22.92it/s]\n","Available device:  cuda\n","100% 3086/3086 [02:12<00:00, 23.22it/s]\n","Eval stats: {'train': 0.9917329589767587, 'test': 0.92788, 'pois': 0.8119122257053292, 'train_clus_size': (179,), 'test_clus_size': (319,), 'pois_clus_size': (322,), 'base_def': 0.9937304075235109, 'collateral_dmg': 0.004862039625623038}\n","\n","\n"]}]},{"cell_type":"code","source":["print(\"Time taken: {}\".format(round((time.time() - start)/60, 3)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Sy8ZUMuoTOv","executionInfo":{"status":"ok","timestamp":1669916512567,"user_tz":300,"elapsed":20,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"a38456ea-1f1c-4e6b-a3b8-944b30750096"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Time taken: 367.567\n"]}]},{"cell_type":"markdown","metadata":{"id":"VMH3ia1WICwP"},"source":["## Merge Evals"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Kw5PBADRIF7A","executionInfo":{"status":"ok","timestamp":1669965891806,"user_tz":300,"elapsed":121,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}}},"outputs":[],"source":["import numpy as np\n","\n","eval_dir = \"/content/drive/MyDrive/storage/results/xlnet\"\n","eval_dir_base = \"/content/drive/MyDrive/storage/results/xlnet_2.0\"\n","eval_base = \"eval-stats_clus100_pois2.0_FT\""]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669965892789,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"R8TCp2iSSfF8","outputId":"519285d0-f8d2-4373-9a13-7a6f2e47be6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29']\n"]}],"source":["suffix_lst = []\n","\n","for i in range(0, 30):\n","  suffix_lst.append(str(i))\n","\n","print(suffix_lst)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10429,"status":"ok","timestamp":1669965909922,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"sCnrUawLIO3w","outputId":"2dd74444-0f37-42a8-f865-434744433c36"},"outputs":[{"output_type":"stream","name":"stdout","text":["21 {'train': 0.9945303953742772, 'test': 0.93312, 'pois': 0.7, 'train_clus_size': (210,), 'test_clus_size': (440,), 'pois_clus_size': (298,), 'base_def': 0.6727272727272727, 'collateral_dmg': 0.0024022801302931995}\n","13 {'train': 0.9945890840652447, 'test': 0.93152, 'pois': 0.6676829268292683, 'train_clus_size': (145,), 'test_clus_size': (328,), 'pois_clus_size': (252,), 'base_def': 0.7042682926829268, 'collateral_dmg': 0.0030398832684824795}\n","38 {'train': 0.9949326999208234, 'test': 0.93328, 'pois': 0.7914110429447853, 'train_clus_size': (92,), 'test_clus_size': (163,), 'pois_clus_size': (130,), 'base_def': 0.8282208588957055, 'collateral_dmg': 0.0014897129282924748}\n","26 {'train': 0.993894802755166, 'test': 0.93464, 'pois': 0.685064935064935, 'train_clus_size': (155,), 'test_clus_size': (308,), 'pois_clus_size': (276,), 'base_def': 0.7077922077922078, 'collateral_dmg': 8.099789405480173e-05}\n","51 {'train': 0.99296875, 'test': 0.93208, 'pois': 0.6633906633906634, 'train_clus_size': (229,), 'test_clus_size': (407,), 'pois_clus_size': (300,), 'base_def': 0.7272727272727273, 'collateral_dmg': 0.0019111129183101427}\n","61 {'train': 0.9953484705140334, 'test': 0.932, 'pois': 0.75, 'train_clus_size': (105,), 'test_clus_size': (200,), 'pois_clus_size': (184,), 'base_def': 0.81, 'collateral_dmg': 0.0025403225806451823}\n","97 {'train': 0.9949019607843137, 'test': 0.93108, 'pois': 0.7446043165467626, 'train_clus_size': (122,), 'test_clus_size': (278,), 'pois_clus_size': (250,), 'base_def': 0.7805755395683454, 'collateral_dmg': 0.0035595825580454488}\n","62 {'train': 0.9952126824674306, 'test': 0.93168, 'pois': 0.7620578778135049, 'train_clus_size': (133,), 'test_clus_size': (311,), 'pois_clus_size': (242,), 'base_def': 0.7781350482315113, 'collateral_dmg': 0.003159301713313578}\n","37 {'train': 0.9917131350681536, 'test': 0.92776, 'pois': 0.6788511749347258, 'train_clus_size': (203,), 'test_clus_size': (383,), 'pois_clus_size': (412,), 'base_def': 0.835509138381201, 'collateral_dmg': 0.004915302433277868}\n","47 {'train': 0.9951602665820375, 'test': 0.93272, 'pois': 0.7531645569620253, 'train_clus_size': (75,), 'test_clus_size': (158,), 'pois_clus_size': (104,), 'base_def': 0.7974683544303798, 'collateral_dmg': 0.0020127203928830273}\n","64 {'train': 0.9911952625837619, 'test': 0.92924, 'pois': 0.9016393442622951, 'train_clus_size': (131,), 'test_clus_size': (305,), 'pois_clus_size': (334,), 'base_def': 0.9901639344262295, 'collateral_dmg': 0.004737801174326761}\n","8 {'train': 0.9920130272952854, 'test': 0.92668, 'pois': 0.9615384615384616, 'train_clus_size': (218,), 'test_clus_size': (364,), 'pois_clus_size': (396,), 'base_def': 0.9752747252747253, 'collateral_dmg': 0.008239974021756802}\n","46 {'train': 0.9942164474726668, 'test': 0.93212, 'pois': 0.8410596026490066, 'train_clus_size': (59,), 'test_clus_size': (151,), 'pois_clus_size': (122,), 'base_def': 0.9470198675496688, 'collateral_dmg': 0.0022536118153647644}\n","15 {'train': 0.9904619265331862, 'test': 0.92952, 'pois': 0.7268041237113402, 'train_clus_size': (96,), 'test_clus_size': (194,), 'pois_clus_size': (186,), 'base_def': 0.9948453608247423, 'collateral_dmg': 0.0034265903410465315}\n","40 {'train': 0.9895686274509804, 'test': 0.92644, 'pois': 0.947565543071161, 'train_clus_size': (155,), 'test_clus_size': (267,), 'pois_clus_size': (250,), 'base_def': 0.9887640449438202, 'collateral_dmg': 0.008207657785145317}\n","6 {'train': 0.9855679702048417, 'test': 0.92672, 'pois': 0.9629629629629629, 'train_clus_size': (188,), 'test_clus_size': (324,), 'pois_clus_size': (388,), 'base_def': 0.9876543209876543, 'collateral_dmg': 0.008064516129032251}\n","83 {'train': 0.993046776232617, 'test': 0.93244, 'pois': 0.8811188811188811, 'train_clus_size': (74,), 'test_clus_size': (143,), 'pois_clus_size': (156,), 'base_def': 0.972027972027972, 'collateral_dmg': 0.002051735929516907}\n","35 {'train': 0.9928391564368901, 'test': 0.92976, 'pois': 0.9178743961352657, 'train_clus_size': (86,), 'test_clus_size': (207,), 'pois_clus_size': (208,), 'base_def': 0.9951690821256038, 'collateral_dmg': 0.004638406001694073}\n","54 {'train': 0.9928615766604594, 'test': 0.92564, 'pois': 0.946927374301676, 'train_clus_size': (180,), 'test_clus_size': (358,), 'pois_clus_size': (388,), 'base_def': 0.9832402234636871, 'collateral_dmg': 0.008968427887346864}\n","75 {'train': 0.9907349246231156, 'test': 0.92964, 'pois': 0.9775784753363229, 'train_clus_size': (100,), 'test_clus_size': (223,), 'pois_clus_size': (236,), 'base_def': 0.9955156950672646, 'collateral_dmg': 0.00524680146910439}\n","29 {'train': 0.986428909578665, 'test': 0.92472, 'pois': 0.696969696969697, 'train_clus_size': (64,), 'test_clus_size': (165,), 'pois_clus_size': (174,), 'base_def': 0.9878787878787879, 'collateral_dmg': 0.00841554258103483}\n","5 {'train': 0.9696480713078224, 'test': 0.92892, 'pois': 0.9567779960707269, 'train_clus_size': (261,), 'test_clus_size': (509,), 'pois_clus_size': (514,), 'base_def': 0.9960707269155207, 'collateral_dmg': 0.005389735004695639}\n","98 {'train': 0.9798657718120806, 'test': 0.91872, 'pois': 0.8847352024922118, 'train_clus_size': (147,), 'test_clus_size': (321,), 'pois_clus_size': (314,), 'base_def': 1.0, 'collateral_dmg': 0.014992503748125885}\n","25 {'train': 0.9904253649348611, 'test': 0.92364, 'pois': 0.864321608040201, 'train_clus_size': (106,), 'test_clus_size': (199,), 'pois_clus_size': (242,), 'base_def': 0.9949748743718593, 'collateral_dmg': 0.01040280633845414}\n","84 {'train': 0.9929810725552051, 'test': 0.9288, 'pois': 0.9595375722543352, 'train_clus_size': (92,), 'test_clus_size': (173,), 'pois_clus_size': (180,), 'base_def': 0.9942196531791907, 'collateral_dmg': 0.006001530591694504}\n","55 {'train': 0.9879886952425813, 'test': 0.92636, 'pois': 0.7450199203187251, 'train_clus_size': (121,), 'test_clus_size': (251,), 'pois_clus_size': (238,), 'base_def': 1.0, 'collateral_dmg': 0.006141662289385397}\n","56 {'train': 0.9916836654636749, 'test': 0.93012, 'pois': 0.9473684210526315, 'train_clus_size': (111,), 'test_clus_size': (247,), 'pois_clus_size': (246,), 'base_def': 0.9959514170040485, 'collateral_dmg': 0.004443905789197289}\n","65 {'train': 0.9886506935687264, 'test': 0.9278, 'pois': 0.7752808988764045, 'train_clus_size': (91,), 'test_clus_size': (178,), 'pois_clus_size': (188,), 'base_def': 1.0, 'collateral_dmg': 0.005640157924421851}\n","11 {'train': 0.9831329064501015, 'test': 0.92224, 'pois': 0.8862876254180602, 'train_clus_size': (171,), 'test_clus_size': (299,), 'pois_clus_size': (306,), 'base_def': 1.0, 'collateral_dmg': 0.011537994413181596}\n","78 {'train': 0.9917329589767587, 'test': 0.92788, 'pois': 0.8119122257053292, 'train_clus_size': (179,), 'test_clus_size': (319,), 'pois_clus_size': (322,), 'base_def': 0.9937304075235109, 'collateral_dmg': 0.004862039625623038}\n"]}],"source":["all_evals = {}\n","\n","for suffix in suffix_lst:\n","  file_path = \"{}/{}-{}.npy\".format(eval_dir, eval_base, suffix)\n","  eval_res = np.load(file_path, allow_pickle=True).item()\n","  for k in eval_res.keys():\n","    print(k, eval_res[k])\n","    all_evals[k] = eval_res[k]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127,"status":"ok","timestamp":1669965913307,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"HJUtCg08JVKH","outputId":"9734bbbd-0f63-4f2e-c587-33518712e1c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["{21: {'train': 0.9945303953742772, 'test': 0.93312, 'pois': 0.7, 'train_clus_size': (210,), 'test_clus_size': (440,), 'pois_clus_size': (298,), 'base_def': 0.6727272727272727, 'collateral_dmg': 0.0024022801302931995}, 13: {'train': 0.9945890840652447, 'test': 0.93152, 'pois': 0.6676829268292683, 'train_clus_size': (145,), 'test_clus_size': (328,), 'pois_clus_size': (252,), 'base_def': 0.7042682926829268, 'collateral_dmg': 0.0030398832684824795}, 38: {'train': 0.9949326999208234, 'test': 0.93328, 'pois': 0.7914110429447853, 'train_clus_size': (92,), 'test_clus_size': (163,), 'pois_clus_size': (130,), 'base_def': 0.8282208588957055, 'collateral_dmg': 0.0014897129282924748}, 26: {'train': 0.993894802755166, 'test': 0.93464, 'pois': 0.685064935064935, 'train_clus_size': (155,), 'test_clus_size': (308,), 'pois_clus_size': (276,), 'base_def': 0.7077922077922078, 'collateral_dmg': 8.099789405480173e-05}, 51: {'train': 0.99296875, 'test': 0.93208, 'pois': 0.6633906633906634, 'train_clus_size': (229,), 'test_clus_size': (407,), 'pois_clus_size': (300,), 'base_def': 0.7272727272727273, 'collateral_dmg': 0.0019111129183101427}, 61: {'train': 0.9953484705140334, 'test': 0.932, 'pois': 0.75, 'train_clus_size': (105,), 'test_clus_size': (200,), 'pois_clus_size': (184,), 'base_def': 0.81, 'collateral_dmg': 0.0025403225806451823}, 97: {'train': 0.9949019607843137, 'test': 0.93108, 'pois': 0.7446043165467626, 'train_clus_size': (122,), 'test_clus_size': (278,), 'pois_clus_size': (250,), 'base_def': 0.7805755395683454, 'collateral_dmg': 0.0035595825580454488}, 62: {'train': 0.9952126824674306, 'test': 0.93168, 'pois': 0.7620578778135049, 'train_clus_size': (133,), 'test_clus_size': (311,), 'pois_clus_size': (242,), 'base_def': 0.7781350482315113, 'collateral_dmg': 0.003159301713313578}, 37: {'train': 0.9917131350681536, 'test': 0.92776, 'pois': 0.6788511749347258, 'train_clus_size': (203,), 'test_clus_size': (383,), 'pois_clus_size': (412,), 'base_def': 0.835509138381201, 'collateral_dmg': 0.004915302433277868}, 47: {'train': 0.9951602665820375, 'test': 0.93272, 'pois': 0.7531645569620253, 'train_clus_size': (75,), 'test_clus_size': (158,), 'pois_clus_size': (104,), 'base_def': 0.7974683544303798, 'collateral_dmg': 0.0020127203928830273}, 64: {'train': 0.9911952625837619, 'test': 0.92924, 'pois': 0.9016393442622951, 'train_clus_size': (131,), 'test_clus_size': (305,), 'pois_clus_size': (334,), 'base_def': 0.9901639344262295, 'collateral_dmg': 0.004737801174326761}, 8: {'train': 0.9920130272952854, 'test': 0.92668, 'pois': 0.9615384615384616, 'train_clus_size': (218,), 'test_clus_size': (364,), 'pois_clus_size': (396,), 'base_def': 0.9752747252747253, 'collateral_dmg': 0.008239974021756802}, 46: {'train': 0.9942164474726668, 'test': 0.93212, 'pois': 0.8410596026490066, 'train_clus_size': (59,), 'test_clus_size': (151,), 'pois_clus_size': (122,), 'base_def': 0.9470198675496688, 'collateral_dmg': 0.0022536118153647644}, 15: {'train': 0.9904619265331862, 'test': 0.92952, 'pois': 0.7268041237113402, 'train_clus_size': (96,), 'test_clus_size': (194,), 'pois_clus_size': (186,), 'base_def': 0.9948453608247423, 'collateral_dmg': 0.0034265903410465315}, 40: {'train': 0.9895686274509804, 'test': 0.92644, 'pois': 0.947565543071161, 'train_clus_size': (155,), 'test_clus_size': (267,), 'pois_clus_size': (250,), 'base_def': 0.9887640449438202, 'collateral_dmg': 0.008207657785145317}, 6: {'train': 0.9855679702048417, 'test': 0.92672, 'pois': 0.9629629629629629, 'train_clus_size': (188,), 'test_clus_size': (324,), 'pois_clus_size': (388,), 'base_def': 0.9876543209876543, 'collateral_dmg': 0.008064516129032251}, 83: {'train': 0.993046776232617, 'test': 0.93244, 'pois': 0.8811188811188811, 'train_clus_size': (74,), 'test_clus_size': (143,), 'pois_clus_size': (156,), 'base_def': 0.972027972027972, 'collateral_dmg': 0.002051735929516907}, 35: {'train': 0.9928391564368901, 'test': 0.92976, 'pois': 0.9178743961352657, 'train_clus_size': (86,), 'test_clus_size': (207,), 'pois_clus_size': (208,), 'base_def': 0.9951690821256038, 'collateral_dmg': 0.004638406001694073}, 54: {'train': 0.9928615766604594, 'test': 0.92564, 'pois': 0.946927374301676, 'train_clus_size': (180,), 'test_clus_size': (358,), 'pois_clus_size': (388,), 'base_def': 0.9832402234636871, 'collateral_dmg': 0.008968427887346864}, 75: {'train': 0.9907349246231156, 'test': 0.92964, 'pois': 0.9775784753363229, 'train_clus_size': (100,), 'test_clus_size': (223,), 'pois_clus_size': (236,), 'base_def': 0.9955156950672646, 'collateral_dmg': 0.00524680146910439}, 29: {'train': 0.986428909578665, 'test': 0.92472, 'pois': 0.696969696969697, 'train_clus_size': (64,), 'test_clus_size': (165,), 'pois_clus_size': (174,), 'base_def': 0.9878787878787879, 'collateral_dmg': 0.00841554258103483}, 5: {'train': 0.9696480713078224, 'test': 0.92892, 'pois': 0.9567779960707269, 'train_clus_size': (261,), 'test_clus_size': (509,), 'pois_clus_size': (514,), 'base_def': 0.9960707269155207, 'collateral_dmg': 0.005389735004695639}, 98: {'train': 0.9798657718120806, 'test': 0.91872, 'pois': 0.8847352024922118, 'train_clus_size': (147,), 'test_clus_size': (321,), 'pois_clus_size': (314,), 'base_def': 1.0, 'collateral_dmg': 0.014992503748125885}, 25: {'train': 0.9904253649348611, 'test': 0.92364, 'pois': 0.864321608040201, 'train_clus_size': (106,), 'test_clus_size': (199,), 'pois_clus_size': (242,), 'base_def': 0.9949748743718593, 'collateral_dmg': 0.01040280633845414}, 84: {'train': 0.9929810725552051, 'test': 0.9288, 'pois': 0.9595375722543352, 'train_clus_size': (92,), 'test_clus_size': (173,), 'pois_clus_size': (180,), 'base_def': 0.9942196531791907, 'collateral_dmg': 0.006001530591694504}, 55: {'train': 0.9879886952425813, 'test': 0.92636, 'pois': 0.7450199203187251, 'train_clus_size': (121,), 'test_clus_size': (251,), 'pois_clus_size': (238,), 'base_def': 1.0, 'collateral_dmg': 0.006141662289385397}, 56: {'train': 0.9916836654636749, 'test': 0.93012, 'pois': 0.9473684210526315, 'train_clus_size': (111,), 'test_clus_size': (247,), 'pois_clus_size': (246,), 'base_def': 0.9959514170040485, 'collateral_dmg': 0.004443905789197289}, 65: {'train': 0.9886506935687264, 'test': 0.9278, 'pois': 0.7752808988764045, 'train_clus_size': (91,), 'test_clus_size': (178,), 'pois_clus_size': (188,), 'base_def': 1.0, 'collateral_dmg': 0.005640157924421851}, 11: {'train': 0.9831329064501015, 'test': 0.92224, 'pois': 0.8862876254180602, 'train_clus_size': (171,), 'test_clus_size': (299,), 'pois_clus_size': (306,), 'base_def': 1.0, 'collateral_dmg': 0.011537994413181596}, 78: {'train': 0.9917329589767587, 'test': 0.92788, 'pois': 0.8119122257053292, 'train_clus_size': (179,), 'test_clus_size': (319,), 'pois_clus_size': (322,), 'base_def': 0.9937304075235109, 'collateral_dmg': 0.004862039625623038}}\n","dict_keys([21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78])\n","30\n"]}],"source":["print(all_evals)\n","print(all_evals.keys())\n","print(len(all_evals.keys()))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6p3NFhUHT5oX","executionInfo":{"status":"ok","timestamp":1669965918361,"user_tz":300,"elapsed":137,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}}},"outputs":[],"source":["save_path = \"{}/{}.npy\".format(eval_dir_base, eval_base)\n","np.save(save_path, all_evals)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1669965924356,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"d8v4ftVqUNpA","outputId":"f2d063b1-0648-4db8-c52b-ccb90e36f0fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["{21: {'train': 0.9945303953742772, 'test': 0.93312, 'pois': 0.7, 'train_clus_size': (210,), 'test_clus_size': (440,), 'pois_clus_size': (298,), 'base_def': 0.6727272727272727, 'collateral_dmg': 0.0024022801302931995}, 13: {'train': 0.9945890840652447, 'test': 0.93152, 'pois': 0.6676829268292683, 'train_clus_size': (145,), 'test_clus_size': (328,), 'pois_clus_size': (252,), 'base_def': 0.7042682926829268, 'collateral_dmg': 0.0030398832684824795}, 38: {'train': 0.9949326999208234, 'test': 0.93328, 'pois': 0.7914110429447853, 'train_clus_size': (92,), 'test_clus_size': (163,), 'pois_clus_size': (130,), 'base_def': 0.8282208588957055, 'collateral_dmg': 0.0014897129282924748}, 26: {'train': 0.993894802755166, 'test': 0.93464, 'pois': 0.685064935064935, 'train_clus_size': (155,), 'test_clus_size': (308,), 'pois_clus_size': (276,), 'base_def': 0.7077922077922078, 'collateral_dmg': 8.099789405480173e-05}, 51: {'train': 0.99296875, 'test': 0.93208, 'pois': 0.6633906633906634, 'train_clus_size': (229,), 'test_clus_size': (407,), 'pois_clus_size': (300,), 'base_def': 0.7272727272727273, 'collateral_dmg': 0.0019111129183101427}, 61: {'train': 0.9953484705140334, 'test': 0.932, 'pois': 0.75, 'train_clus_size': (105,), 'test_clus_size': (200,), 'pois_clus_size': (184,), 'base_def': 0.81, 'collateral_dmg': 0.0025403225806451823}, 97: {'train': 0.9949019607843137, 'test': 0.93108, 'pois': 0.7446043165467626, 'train_clus_size': (122,), 'test_clus_size': (278,), 'pois_clus_size': (250,), 'base_def': 0.7805755395683454, 'collateral_dmg': 0.0035595825580454488}, 62: {'train': 0.9952126824674306, 'test': 0.93168, 'pois': 0.7620578778135049, 'train_clus_size': (133,), 'test_clus_size': (311,), 'pois_clus_size': (242,), 'base_def': 0.7781350482315113, 'collateral_dmg': 0.003159301713313578}, 37: {'train': 0.9917131350681536, 'test': 0.92776, 'pois': 0.6788511749347258, 'train_clus_size': (203,), 'test_clus_size': (383,), 'pois_clus_size': (412,), 'base_def': 0.835509138381201, 'collateral_dmg': 0.004915302433277868}, 47: {'train': 0.9951602665820375, 'test': 0.93272, 'pois': 0.7531645569620253, 'train_clus_size': (75,), 'test_clus_size': (158,), 'pois_clus_size': (104,), 'base_def': 0.7974683544303798, 'collateral_dmg': 0.0020127203928830273}, 64: {'train': 0.9911952625837619, 'test': 0.92924, 'pois': 0.9016393442622951, 'train_clus_size': (131,), 'test_clus_size': (305,), 'pois_clus_size': (334,), 'base_def': 0.9901639344262295, 'collateral_dmg': 0.004737801174326761}, 8: {'train': 0.9920130272952854, 'test': 0.92668, 'pois': 0.9615384615384616, 'train_clus_size': (218,), 'test_clus_size': (364,), 'pois_clus_size': (396,), 'base_def': 0.9752747252747253, 'collateral_dmg': 0.008239974021756802}, 46: {'train': 0.9942164474726668, 'test': 0.93212, 'pois': 0.8410596026490066, 'train_clus_size': (59,), 'test_clus_size': (151,), 'pois_clus_size': (122,), 'base_def': 0.9470198675496688, 'collateral_dmg': 0.0022536118153647644}, 15: {'train': 0.9904619265331862, 'test': 0.92952, 'pois': 0.7268041237113402, 'train_clus_size': (96,), 'test_clus_size': (194,), 'pois_clus_size': (186,), 'base_def': 0.9948453608247423, 'collateral_dmg': 0.0034265903410465315}, 40: {'train': 0.9895686274509804, 'test': 0.92644, 'pois': 0.947565543071161, 'train_clus_size': (155,), 'test_clus_size': (267,), 'pois_clus_size': (250,), 'base_def': 0.9887640449438202, 'collateral_dmg': 0.008207657785145317}, 6: {'train': 0.9855679702048417, 'test': 0.92672, 'pois': 0.9629629629629629, 'train_clus_size': (188,), 'test_clus_size': (324,), 'pois_clus_size': (388,), 'base_def': 0.9876543209876543, 'collateral_dmg': 0.008064516129032251}, 83: {'train': 0.993046776232617, 'test': 0.93244, 'pois': 0.8811188811188811, 'train_clus_size': (74,), 'test_clus_size': (143,), 'pois_clus_size': (156,), 'base_def': 0.972027972027972, 'collateral_dmg': 0.002051735929516907}, 35: {'train': 0.9928391564368901, 'test': 0.92976, 'pois': 0.9178743961352657, 'train_clus_size': (86,), 'test_clus_size': (207,), 'pois_clus_size': (208,), 'base_def': 0.9951690821256038, 'collateral_dmg': 0.004638406001694073}, 54: {'train': 0.9928615766604594, 'test': 0.92564, 'pois': 0.946927374301676, 'train_clus_size': (180,), 'test_clus_size': (358,), 'pois_clus_size': (388,), 'base_def': 0.9832402234636871, 'collateral_dmg': 0.008968427887346864}, 75: {'train': 0.9907349246231156, 'test': 0.92964, 'pois': 0.9775784753363229, 'train_clus_size': (100,), 'test_clus_size': (223,), 'pois_clus_size': (236,), 'base_def': 0.9955156950672646, 'collateral_dmg': 0.00524680146910439}, 29: {'train': 0.986428909578665, 'test': 0.92472, 'pois': 0.696969696969697, 'train_clus_size': (64,), 'test_clus_size': (165,), 'pois_clus_size': (174,), 'base_def': 0.9878787878787879, 'collateral_dmg': 0.00841554258103483}, 5: {'train': 0.9696480713078224, 'test': 0.92892, 'pois': 0.9567779960707269, 'train_clus_size': (261,), 'test_clus_size': (509,), 'pois_clus_size': (514,), 'base_def': 0.9960707269155207, 'collateral_dmg': 0.005389735004695639}, 98: {'train': 0.9798657718120806, 'test': 0.91872, 'pois': 0.8847352024922118, 'train_clus_size': (147,), 'test_clus_size': (321,), 'pois_clus_size': (314,), 'base_def': 1.0, 'collateral_dmg': 0.014992503748125885}, 25: {'train': 0.9904253649348611, 'test': 0.92364, 'pois': 0.864321608040201, 'train_clus_size': (106,), 'test_clus_size': (199,), 'pois_clus_size': (242,), 'base_def': 0.9949748743718593, 'collateral_dmg': 0.01040280633845414}, 84: {'train': 0.9929810725552051, 'test': 0.9288, 'pois': 0.9595375722543352, 'train_clus_size': (92,), 'test_clus_size': (173,), 'pois_clus_size': (180,), 'base_def': 0.9942196531791907, 'collateral_dmg': 0.006001530591694504}, 55: {'train': 0.9879886952425813, 'test': 0.92636, 'pois': 0.7450199203187251, 'train_clus_size': (121,), 'test_clus_size': (251,), 'pois_clus_size': (238,), 'base_def': 1.0, 'collateral_dmg': 0.006141662289385397}, 56: {'train': 0.9916836654636749, 'test': 0.93012, 'pois': 0.9473684210526315, 'train_clus_size': (111,), 'test_clus_size': (247,), 'pois_clus_size': (246,), 'base_def': 0.9959514170040485, 'collateral_dmg': 0.004443905789197289}, 65: {'train': 0.9886506935687264, 'test': 0.9278, 'pois': 0.7752808988764045, 'train_clus_size': (91,), 'test_clus_size': (178,), 'pois_clus_size': (188,), 'base_def': 1.0, 'collateral_dmg': 0.005640157924421851}, 11: {'train': 0.9831329064501015, 'test': 0.92224, 'pois': 0.8862876254180602, 'train_clus_size': (171,), 'test_clus_size': (299,), 'pois_clus_size': (306,), 'base_def': 1.0, 'collateral_dmg': 0.011537994413181596}, 78: {'train': 0.9917329589767587, 'test': 0.92788, 'pois': 0.8119122257053292, 'train_clus_size': (179,), 'test_clus_size': (319,), 'pois_clus_size': (322,), 'base_def': 0.9937304075235109, 'collateral_dmg': 0.004862039625623038}}\n","dict_keys([21, 13, 38, 26, 51, 61, 97, 62, 37, 47, 64, 8, 46, 15, 40, 6, 83, 35, 54, 75, 29, 5, 98, 25, 84, 55, 56, 65, 11, 78])\n","30\n"]}],"source":["file_path = \"{}/{}.npy\".format(eval_dir_base, eval_base)\n","eval_res = np.load(file_path, allow_pickle=True).item()\n","print(all_evals)\n","print(all_evals.keys())\n","print(len(all_evals.keys()))"]},{"cell_type":"markdown","metadata":{"id":"tsJa550WY1eH"},"source":["# Clean-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAG08ySDBMxy"},"outputs":[],"source":["!zip saved_models.zip /content/drive/MyDrive/storage/other/saved_models"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"56lGtHeZtxBG","executionInfo":{"status":"ok","timestamp":1669965936682,"user_tz":300,"elapsed":290,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}}},"outputs":[],"source":["!rm -r /content/drive/MyDrive/storage/results/xlnet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1640,"status":"ok","timestamp":1669443352823,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"1HJyi8r9fIrr","outputId":"f0f34a00-4cf5-4a70-8517-edb475d57c29"},"outputs":[{"name":"stdout","output_type":"stream","text":["HEAD is now at 14d7d6d update\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (1/1), done.\u001b[K\n","Unpacking objects: 100% (5/5), done.\n","remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n","From https://github.com/YunZhi246/subpopulation-data-poisoning-attacks\n","   dbfe57f..2f72ae3  main       -> origin/main\n","Updating 14d7d6d..2f72ae3\n","Fast-forward\n"," attack_nlp.py                           | 70 \u001b[32m+++++++++++++\u001b[m\u001b[31m--------------------\u001b[m\n"," subclass_avail/target_nlp/bert_utils.py |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," 2 files changed, 29 insertions(+), 43 deletions(-)\n"]}],"source":["!git checkout .\n","!git reset --hard HEAD~1\n","!git pull"]}],"metadata":{"colab":{"collapsed_sections":["sulD-2sJkQJC","kwdXdVkLX00V"],"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}