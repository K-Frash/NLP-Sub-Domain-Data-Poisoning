{"cells":[{"cell_type":"markdown","metadata":{"id":"59Vmb2AtkNzp"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"sulD-2sJkQJC"},"source":["## System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfQXSZebkLds","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669636659772,"user_tz":300,"elapsed":15936,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"b137f828-76ac-4b75-e873-078ef35f588e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCQT9cPlkI5a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669636659772,"user_tz":300,"elapsed":11,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"0faba846-ca63-4a90-a424-0afbac2cee2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Nov 28 11:57:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","\n","################################################################################\n","\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","print(\"\\n################################################################################\\n\")\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"kwdXdVkLX00V"},"source":["## GitHub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKgq3FWyblhi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669636660414,"user_tz":300,"elapsed":647,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"d1f663b7-6884-4747-db21-ac60dee4b90c"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n","Cloning into 'subpopulation-data-poisoning-attacks'...\n","remote: Enumerating objects: 131, done.\u001b[K\n","remote: Counting objects: 100% (131/131), done.\u001b[K\n","remote: Compressing objects: 100% (90/90), done.\u001b[K\n","remote: Total 131 (delta 72), reused 93 (delta 39), pack-reused 0\u001b[K\n","Receiving objects: 100% (131/131), 1.61 MiB | 16.18 MiB/s, done.\n","Resolving deltas: 100% (72/72), done.\n"]}],"source":["!ls\n","!git clone https://github.com/YunZhi246/subpopulation-data-poisoning-attacks.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-Jc6ZbZj8QG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669636660415,"user_tz":300,"elapsed":7,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"d2688631-fd41-409a-d194-d9bbfffe80dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/subpopulation-data-poisoning-attacks\n"]}],"source":["%cd /content/subpopulation-data-poisoning-attacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3rXkcpLcP8o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669636688480,"user_tz":300,"elapsed":28070,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"}},"outputId":"73a2c31f-4d38-4150-dcc6-ff92dc8e3e15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n","Collecting pandas==1.0.1\n","  Downloading pandas-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 4.7 MB/s \n","\u001b[?25hCollecting scikit-learn==0.22.1\n","  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[K     |████████████████████████████████| 7.0 MB 35.7 MB/s \n","\u001b[?25hCollecting scipy==1.4.1\n","  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n","\u001b[K     |████████████████████████████████| 26.1 MB 62.4 MB/s \n","\u001b[?25hCollecting seaborn==0.10.0\n","  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n","\u001b[K     |████████████████████████████████| 215 kB 98.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.12.1+cu113)\n","Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n","Collecting transformers==4.20.0\n","  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 73.3 MB/s \n","\u001b[?25hCollecting tables==3.6.1\n","  Downloading tables-3.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 67.8 MB/s \n","\u001b[?25hCollecting datasets==2.7.1\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 87.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2022.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.10.0->-r requirements.txt (line 5)) (3.2.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 91.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 73.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (21.3)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables==3.6.1->-r requirements.txt (line 9)) (2.8.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 89.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (9.0.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (0.3.6)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 80.6 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (2022.11.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (3.8.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->-r requirements.txt (line 6)) (4.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (2.1.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.1->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 87.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.20.0->-r requirements.txt (line 8)) (3.10.0)\n","Installing collected packages: urllib3, xxhash, tokenizers, scipy, responses, pandas, multiprocess, huggingface-hub, transformers, tables, seaborn, scikit-learn, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: tables\n","    Found existing installation: tables 3.7.0\n","    Uninstalling tables-3.7.0:\n","      Successfully uninstalled tables-3.7.0\n","  Attempting uninstall: seaborn\n","    Found existing installation: seaborn 0.11.2\n","    Uninstalling seaborn-0.11.2:\n","      Successfully uninstalled seaborn-0.11.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n","xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.1 which is incompatible.\n","prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n","plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n","plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n","mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n","jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n","google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\u001b[0m\n","Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 pandas-1.0.1 responses-0.18.0 scikit-learn-0.22.1 scipy-1.4.1 seaborn-0.10.0 tables-3.6.1 tokenizers-0.12.1 transformers-4.20.0 urllib3-1.25.11 xxhash-3.1.0\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"-V6Mh6DSkgrf"},"source":["# Train models"]},{"cell_type":"markdown","metadata":{"id":"Wfu_3QhzX7Eh"},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaZmOK79kfJK"},"outputs":[],"source":["# !python train_imdb_bert.py"]},{"cell_type":"markdown","metadata":{"id":"2oqQ4vVRX9-v"},"source":["## Attack"]},{"cell_type":"markdown","metadata":{"id":"p9MC0ivQfUpC"},"source":["### 0.5 Poison Rate"]},{"cell_type":"markdown","metadata":{"id":"lj_1cb-LPiC7"},"source":["#### Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626897,"status":"ok","timestamp":1669444995324,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"kQwZ0mUn2gDJ","outputId":"b02573a2-34d7-4201-f73c-cd9566ef9a5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Performing sub-population poisoning attack, received arguments:\n","{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 0.5, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1}\n","\n","Creating directory: /content/drive/MyDrive/storage/other/saved_models/victims\n","Available device:  cuda\n","Available device:  cuda\n","Loading model: imdb_xlnet_FT_ADV.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n","100% 3/3 [00:00<00:00, 587.55it/s]\n","WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f700cd6f222bd13f.arrow\n","WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b23cfeb68a931a8d.arrow\n","100% 13/13 [00:05<00:00,  2.35ba/s]\n","100% 13/13 [00:05<00:00,  2.34ba/s]\n","100% 25/25 [00:10<00:00,  2.32ba/s]\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","Data shapes:\n","ids_train: 12500\n","att_train: 12500\n","y_train: 12500\n","ids_test: 25000\n","att_test: 25000\n","y_test: 25000\n","Tensors shapes:\n","ids_train: torch.Size([12500, 256])\n","att_train: torch.Size([12500, 256])\n","y_train: torch.Size([12500])\n","ids_test: torch.Size([25000, 256])\n","att_test: torch.Size([25000, 256])\n","y_test: torch.Size([25000])\n","\n","Getting def train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting adv train representations\n","Available device:  cuda\n","Representation size:(12500, 256, 768)\n","\n","Getting test representations\n","Available device:  cuda\n","Representation size:(25000, 256, 768)\n","\n","Computing predictions on the training sets\n","100% 3125/3125 [05:38<00:00,  9.22it/s]\n","100% 3125/3125 [05:37<00:00,  9.26it/s]\n","\n","Shapes\n","\tll: (12500, 196608)\n","\tll_ho: (12500, 196608)\n","\tll_t: (25000, 196608)\n","\n","Clustering ll_ho\n","tcmalloc: large alloc 9830400000 bytes == 0x7f450e100000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8615726 0x7f51c8608475 0x7f51c86b86ec 0x58f62c 0x510bf2 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c\n","tcmalloc: large alloc 9830400000 bytes == 0x7f42c2200000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8611cf5 0x7f51c8611e08 0x7f51c86d10f4 0x7f51c86d430c 0x7f51c885b3ac 0x7f51c885be10 0x5917ee 0x591ac9 0x7f51c86db2a6 0x4e50c9 0x50d124 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x4bad0a 0x7f51c85fc944 0x58f67f 0x50ff13 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37\n","\n","Clustering ll_t\n","tcmalloc: large alloc 19660800000 bytes == 0x7f3e2e400000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8611cf5 0x7f51c8611e08 0x7f51c86d10f4 0x7f51c86d430c 0x7f51c885b3ac 0x7f51c885be10 0x5917ee 0x591ac9 0x7f51c86db2a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","\n","Clustering ll\n","tcmalloc: large alloc 9830400000 bytes == 0x7f450e100000 @  0x7f5238d441e7 0x7f51c85bb0ce 0x7f51c8611cf5 0x7f51c8611e08 0x7f51c86d10f4 0x7f51c86d430c 0x7f51c885b3ac 0x7f51c885be10 0x5917ee 0x591ac9 0x7f51c86db2a6 0x4e50c9 0x50d124 0x58fd37 0x50c4fc 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82\n","labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 43, 142, 106, 142,  47, 259, 188,  75, 217, 137,  99, 174, 118,\n","       145, 151,  97,  80,  61, 107, 144, 123, 212, 177, 177, 106, 104,\n","       152, 172,  27,  68, 211, 187,  34,  13, 227,  77, 169, 201,  92,\n","       169, 149,  91,  88, 172, 134,  77,  68,  75,  50, 105,  82, 235,\n","       149,  86, 181, 131, 121, 169,  43, 138, 151, 104, 142,  65, 134,\n","        94, 156,  77, 124, 193,  41, 190,  86, 121, 130, 103,  93, 118,\n","       178, 140, 162, 101, 138,  73,  89, 103, 191, 148, 117,  88, 162,\n","        76, 106, 105, 150,  74, 158, 137, 152, 156]))\n","ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 31, 172, 134, 181,  56, 252, 194, 104, 199, 130,  96, 159, 130,\n","       124, 127,  94,  92,  79, 118, 151, 153, 154, 153, 159, 128, 120,\n","       143, 200,  30,  85, 202, 181,  51,  12, 246,  95, 162, 205,  65,\n","       152, 121, 122,  95, 207, 112,  61,  69,  52,  28, 101,  79, 168,\n","       109,  79, 202, 124, 129, 170,  55, 146, 160,  93, 120,  65, 168,\n","        99, 160,  87, 134, 194,  32, 193,  99, 108, 126, 115,  70, 139,\n","       158, 137, 142,  82, 138,  78,  90, 114, 198, 128, 116, 101, 158,\n","       101,  84, 122, 143,  81, 165, 141, 156, 157]))\n","test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n","       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n","       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n","       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n","      dtype=int32), array([ 86, 285, 230, 295, 101, 495, 328, 191, 360, 233, 244, 307, 244,\n","       327, 248, 194, 187, 105, 244, 324, 279, 455, 350, 340, 241, 194,\n","       311, 355,  78, 157, 376, 332, 112,  24, 464, 194, 398, 380, 169,\n","       323, 270, 203, 151, 384, 241, 163, 166, 155,  62, 200, 179, 437,\n","       272, 154, 358, 265, 265, 293, 143, 267, 326, 202, 324, 135, 307,\n","       177, 352, 193, 280, 353,  76, 351, 160, 248, 238, 227, 168, 237,\n","       324, 264, 265, 165, 284, 138, 171, 227, 318, 303, 235, 176, 315,\n","       207, 221, 206, 277, 166, 277, 295, 315, 309]))\n","\n","x shape: (12500, 256)\n","x_ho shape:(12500, 256)\n","x_t shape: (25000, 256)\n","Indices of clusters to evaluate: 30\n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n"]}],"source":["# !python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --setup"]},{"cell_type":"markdown","metadata":{"id":"X3mvaXFEPlAE"},"source":["#### Attack"]},{"cell_type":"markdown","metadata":{"id":"NXB3x-qKP3Y8"},"source":["Done: 17  \n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, ]\n","\n","\n","\n","Pending: 13  \n","[83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n"]},{"cell_type":"code","source":["import time\n","\n","start = time.time()"],"metadata":{"id":"oo_VIWH8HgH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nY_DadrDunU7","outputId":"1400aa91-645e-4f7e-d9c1-0ca984ac9874"},"outputs":[{"output_type":"stream","name":"stdout","text":["Indices of clusters to evaluate: 30\n","[21, 13, 38, 51, 61, 26, 97, 62, 37, 47, 64, 8, 46, 39, 15, 40, 6, 83, 54, 28, 98, 29, 84, 5, 55, 11, 25, 56, 65, 78]\n","\n","Available device:  cuda\n","cluster ind: 83\n","train cluster size: 73\n","test cluster size: 138\n","pois cluster size 39\n","1 [ 252.8933402 -243.2867465]\n","\n","x coll shape: (24862, 256)\n","x_att coll shape:(24862, 256)\n","y coll shape: (24862,)\n","Training new model\n","Available device:  cuda\n","Downloading: 100% 760/760 [00:00<00:00, 793kB/s]\n","Downloading: 100% 445M/445M [00:06<00:00, 71.0MB/s]\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch 0 of 4\n","100% 1568/1568 [14:20<00:00,  1.82it/s]\n","Train loss at epoch 0: 0.2577364192349\n","Training accuracy - epoch 0: 0.9532844387755102\n","Epoch 1 of 4\n","100% 1568/1568 [14:28<00:00,  1.81it/s]\n","Train loss at epoch 1: 0.15251279680821\n","Training accuracy - epoch 1: 0.9775191326530612\n","Epoch 2 of 4\n","100% 1568/1568 [14:31<00:00,  1.80it/s]\n","Train loss at epoch 2: 0.08931453858590709\n","Training accuracy - epoch 2: 0.9903539540816326\n","Epoch 3 of 4\n","100% 1568/1568 [14:27<00:00,  1.81it/s]\n","Train loss at epoch 3: 0.04858950658701954\n","Training accuracy - epoch 3: 0.9936224489795918\n","Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_xlnet_83\n","Available device:  cuda\n","100% 1568/1568 [06:12<00:00,  4.21it/s]\n","100% 3125/3125 [12:28<00:00,  4.17it/s]\n","100% 18/18 [00:04<00:00,  4.40it/s]\n","Available device:  cuda\n","100% 3108/3108 [12:24<00:00,  4.17it/s]\n","Loading model: imdb_xlnet_FT_DEF.ckpt\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 18/18 [00:04<00:00,  4.39it/s]\n","Available device:  cuda\n","100% 3108/3108 [12:26<00:00,  4.16it/s]\n","Eval stats: {'train': 0.9936199058936119, 'test': 0.93356, 'pois': 0.9202898550724637, 'train_clus_size': (73,), 'test_clus_size': (138,), 'pois_clus_size': (39,), 'base_def': 0.9710144927536232, 'collateral_dmg': 0.0011664387418550692}\n","\n","\n","Available device:  cuda\n","cluster ind: 54\n","train cluster size: 181\n","test cluster size: 358\n","pois cluster size 101\n","1 [ 651.31304073 -639.85670745]\n","\n","x coll shape: (24642, 256)\n","x_att coll shape:(24642, 256)\n","y coll shape: (24642,)\n","Training new model\n","Available device:  cuda\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 0 of 4\n","100% 1576/1576 [14:35<00:00,  1.80it/s]\n","Train loss at epoch 0: 0.26408000768169404\n","Training accuracy - epoch 0: 0.9478902284263959\n","Epoch 1 of 4\n","100% 1576/1576 [14:35<00:00,  1.80it/s]\n","Train loss at epoch 1: 0.16298382835277134\n","Training accuracy - epoch 1: 0.9758090101522843\n","Epoch 2 of 4\n","  9% 149/1576 [01:22<13:07,  1.81it/s]"]}],"source":["!python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 17 --n_attack 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoj6dy8MusO5"},"outputs":[],"source":["print(\"Time taken: {}\".format(round((time.time() - start)/60, 3)))"]},{"cell_type":"markdown","metadata":{"id":"Z5lDQ4P5fXhD"},"source":["### 1.0 Poison Rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJ5mteAAuizB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzw3ouH1JPpV"},"outputs":[],"source":["!python attack_nlp.py --poison_rate 1 --n_clusters 100"]},{"cell_type":"markdown","metadata":{"id":"pbshFYkhfZg5"},"source":["### 2.0 Poison Rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gx74wrQ7JRNl"},"outputs":[],"source":["!python attack_nlp.py --poison_rate 2 --n_clusters 100"]},{"cell_type":"markdown","metadata":{"id":"tsJa550WY1eH"},"source":["## Clean-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAG08ySDBMxy"},"outputs":[],"source":["!zip saved_models.zip /content/drive/MyDrive/storage/other/saved_models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56lGtHeZtxBG"},"outputs":[],"source":["!rm -r /content/drive/MyDrive/storage/other/saved_models/victims"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1640,"status":"ok","timestamp":1669443352823,"user":{"displayName":"YunZhi Lin","userId":"16244880243279239671"},"user_tz":300},"id":"1HJyi8r9fIrr","outputId":"f0f34a00-4cf5-4a70-8517-edb475d57c29"},"outputs":[{"name":"stdout","output_type":"stream","text":["HEAD is now at 14d7d6d update\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (1/1), done.\u001b[K\n","Unpacking objects: 100% (5/5), done.\n","remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n","From https://github.com/YunZhi246/subpopulation-data-poisoning-attacks\n","   dbfe57f..2f72ae3  main       -> origin/main\n","Updating 14d7d6d..2f72ae3\n","Fast-forward\n"," attack_nlp.py                           | 70 \u001b[32m+++++++++++++\u001b[m\u001b[31m--------------------\u001b[m\n"," subclass_avail/target_nlp/bert_utils.py |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," 2 files changed, 29 insertions(+), 43 deletions(-)\n"]}],"source":["!git checkout .\n","!git reset --hard HEAD~1\n","!git pull"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sulD-2sJkQJC","kwdXdVkLX00V"],"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}