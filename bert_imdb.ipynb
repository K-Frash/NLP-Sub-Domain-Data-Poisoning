{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNs8oNp7Xc9DM+cnDgmiMiZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XLfgjzDJ3Xn","executionInfo":{"status":"ok","timestamp":1669019982697,"user_tz":300,"elapsed":7382,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"bf01665c-84c2-448e-c52a-df2b9a597518"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (4.64.1)\n"]}],"source":["!pip install transformers\n","!pip install pytorch-nlp"]},{"cell_type":"code","source":["# import matplotlib.pyplot as plt\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import random as rn\n","# import sys\n","import time\n","import torch\n","# from keras_preprocessing.sequence import pad_sequences\n","# from sklearn.metrics import classification_report\n","# from torch import nn\n","from torch.optim import AdamW\n","# from torch.nn.utils import clip_grad_norm_\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torchnlp.datasets import imdb_dataset  # comment out if we decide to use a downloaded dataset\n","from transformers import BertTokenizer, BertForSequenceClassification, BertConfig"],"metadata":{"id":"apMlDHYWJ5SX","executionInfo":{"status":"ok","timestamp":1669019987126,"user_tz":300,"elapsed":4437,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKxoFLB3wjyS","executionInfo":{"status":"ok","timestamp":1669019987127,"user_tz":300,"elapsed":10,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"e9a58479-978d-4692-f668-27e3f9888b34"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["# Initializing seed values to stabilize the outcomes.\n","rn.seed(321)\n","np.random.seed(321)\n","torch.manual_seed(321)\n","torch.cuda.manual_seed(321)"],"metadata":{"id":"U1PbC6orKLFl","executionInfo":{"status":"ok","timestamp":1669019987128,"user_tz":300,"elapsed":9,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["TOKEN_MAX_LENGTH = 256\n","BATCH_SIZE = 8\n","EPOCHS = 4\n","LEARNING_RATE = 10e-5"],"metadata":{"id":"ea4ohkbV1Eke","executionInfo":{"status":"ok","timestamp":1669019987129,"user_tz":300,"elapsed":10,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Dataset setup"],"metadata":{"id":"dDhJFrXXWgF1"}},{"cell_type":"code","source":["train_data_full = imdb_dataset(train=True)\n","test_data_full = imdb_dataset(test=True)\n","\n","rn.shuffle(train_data_full)\n","rn.shuffle(test_data_full)\n","\n","print(\"\\nTraining set size: {}\".format(len(train_data_full)))\n","print(\"Test set size: {}\".format(len(test_data_full)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gABudKUxLlw1","executionInfo":{"status":"ok","timestamp":1669019989092,"user_tz":300,"elapsed":1973,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"1977ab4c-2226-45ad-e88e-aa13e75b893b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training set size: 25000\n","Test set size: 25000\n"]}]},{"cell_type":"code","source":["# experimenting here with a sample of dataset, to avoid memory overflow.\n","train_data = train_data_full[:12500]\n","val_data = train_data_full[12500:13000]\n","test_data = test_data_full\n","\n","print(\"Training set size: {}\".format(len(train_data)))\n","print(\"Test set size: {}\".format(len(test_data)))\n","print(train_data[0])\n","print(test_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-eeqSvqoO0v-","executionInfo":{"status":"ok","timestamp":1669019989093,"user_tz":300,"elapsed":17,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"e06a6fc1-67ec-4379-8d27-8a6b4898c7bf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set size: 12500\n","Test set size: 25000\n","{'text': 'i\\'m not even sure what to say about this film. it\\'s one of only a handful of movies ever made that i would consider romantic. to try to talk plot or performance or technical details about this film would be in the words of frank zappa \"like dancing about architecture\". it absolutely hits the nail right on the head in the way it captures those fleeting moments in life that move us and then run away from us never to be experienced again. this seems like the movie the character version of charlie kaufman in the movie Adaptation wanted to write. the ending is left open and ambiguous, no happy ending here, just mystery. no profound life lessons, just a couple of horny and intelligent kids exploring the ability to feel the most irrational and unrealistic of feelings...... romantic love.<br /><br />10 out of 10 watch it with your special lady and recommend it to a stranger................', 'sentiment': 'pos'}\n","{'text': \"There were heist movies before this one, and indeed the likes of Rififi were an obvious influence on it - but The Red Circle is more than just another entry in an overpopulated genre and with this film, director Jean-Pierre Melville has managed to create something that both thrills on the surface and gives its audience something to think about. Being cool is just as important a feature of the modern crime movie as guns and gangsters, and Melville delivers that with this film in droves; the tone of the film is very relaxed too and Melville allows the bulk of the film to bubble under the cool exterior. The story has a number of angles but the central character is Corey - a thief who is released from prison. His release coincides with the escape of infamous murderer Vogel, who slips from under the nose of Police Commissioner Mattei during a train ride. The first thing Corey does upon release is steal some money from his former boss Rico, and the second thing he does is recruit Vogel and a sharpshooter to help him pull of a jewel heist. But Rico and the police are hot on the thieves' tails...<br /><br />The film is bolted together by four excellent central performances. Alain Delon is calm and calculating as the film's anti-hero, while Gian Maria Volontè looks formidable in his role as the escaped murderer. François Périer is good also as a dubious club owner, while the real standout performance comes from André Bourvil in his role as the police commissioner. The film runs at almost two and a half hours and is not exactly a thrill ride. However, the director keeps things interesting by keeping the action focused on the important elements. The film does feature crime film stapes such as shootings, but they are kept to a minimum. The first two thirds of the movie are really just building up to the suspenseful heist scene towards the end. Rififi was most famous for its heist sequence - an intricately designed scene in which nobody speaks a word. The heist in this film is similar in that it is also wordless, and I have to say that I preferred the scene in Rififi; but Melville's skill in direction and the calm and composed way that it plays out make good of it. The film boils down to an exciting climax that rounds it all off nicely. Overall, this might not appeal to all crime film fans as the action is more than a little bit slow; but The Red Circle is an excellent film and deserves its reputation as a masterpiece.\", 'sentiment': 'pos'}\n"]}]},{"cell_type":"code","source":["# Split data in texts and labels\n","train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n","val_texts, val_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), val_data)))\n","test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n","\n","print(\"Train text length:  {}\\tTest text length:  {}\\nTrain label length: {}\\tTest label length: {}\".\n","      format(len(train_texts), len(test_texts), len(train_labels), len(test_labels)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YpZ8DJxO3BX","executionInfo":{"status":"ok","timestamp":1669019989093,"user_tz":300,"elapsed":15,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"c5c5d80e-962a-43be-d1c4-6500753f2535"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Train text length:  12500\tTest text length:  25000\n","Train label length: 12500\tTest label length: 25000\n"]}]},{"cell_type":"code","source":["# Calculate percentage pos\n","train_y = np.array(train_labels) == 'pos'\n","val_y = np.array(val_labels) == 'pos'\n","test_y = np.array(test_labels) == 'pos'\n","\n","print(\"Train records pos: {}/{}\\nTest records pos: {}/{}\".\n","      format(np.sum(train_y), len(train_y), np.sum(test_y), len(test_y)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmLteiuBxTaX","executionInfo":{"status":"ok","timestamp":1669019989094,"user_tz":300,"elapsed":12,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"3bac0a29-7084-4664-e57a-49d89fa098f2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train records pos: 6240/12500\n","Test records pos: 12500/25000\n"]}]},{"cell_type":"markdown","source":["## Tokenize input and create DataLoader"],"metadata":{"id":"9dIKUV2zxkeN"}},{"cell_type":"code","source":["# Token embeddings\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KclI0dfTPPUo","executionInfo":{"status":"ok","timestamp":1669019989094,"user_tz":300,"elapsed":10,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"07f28d15-3311-4673-dca9-93ca7f80f8cc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","def tokenize_text(sentences):\n","  ids = []\n","  masks = []\n","\n","  # For every sentence...\n","  for sent in sentences:\n","      # `encode_plus` will:\n","      #   (1) Tokenize the sentence.\n","      #   (2) Prepend the `[CLS]` token to the start.\n","      #   (3) Append the `[SEP]` token to the end.\n","      #   (4) Map tokens to their IDs.\n","      #   (5) Pad or truncate the sentence to `max_length`\n","      #   (6) Create attention masks for [PAD] tokens.\n","      encoded_dict = tokenizer.encode_plus(\n","                          sent,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = TOKEN_MAX_LENGTH,  # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt'     # Return pytorch tensors.\n","                    )\n","      \n","      # Add the encoded sentence to the list.    \n","      ids.append(encoded_dict['input_ids'])\n","      \n","      # And its attention mask (simply differentiates padding from non-padding).\n","      masks.append(encoded_dict['attention_mask'])\n","\n","  # Convert the lists into tensors.\n","  ids = torch.cat(ids, dim=0)\n","  masks = torch.cat(masks, dim=0)\n","  return ids, masks"],"metadata":{"id":"QusJcrWTyZwq","executionInfo":{"status":"ok","timestamp":1669019989094,"user_tz":300,"elapsed":8,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_ids, train_masks = tokenize_text(train_texts)\n","val_ids, val_masks = tokenize_text(val_texts)\n","test_ids, test_masks = tokenize_text(test_texts)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', train_texts[0])\n","print('Token IDs:', train_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYKqozeW4E3z","executionInfo":{"status":"ok","timestamp":1669020210371,"user_tz":300,"elapsed":221285,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"85da051b-c0bb-49a1-d586-a6cce27f8489"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  i'm not even sure what to say about this film. it's one of only a handful of movies ever made that i would consider romantic. to try to talk plot or performance or technical details about this film would be in the words of frank zappa \"like dancing about architecture\". it absolutely hits the nail right on the head in the way it captures those fleeting moments in life that move us and then run away from us never to be experienced again. this seems like the movie the character version of charlie kaufman in the movie Adaptation wanted to write. the ending is left open and ambiguous, no happy ending here, just mystery. no profound life lessons, just a couple of horny and intelligent kids exploring the ability to feel the most irrational and unrealistic of feelings...... romantic love.<br /><br />10 out of 10 watch it with your special lady and recommend it to a stranger................\n","Token IDs: tensor([  101,  1045,  1005,  1049,  2025,  2130,  2469,  2054,  2000,  2360,\n","         2055,  2023,  2143,  1012,  2009,  1005,  1055,  2028,  1997,  2069,\n","         1037,  9210,  1997,  5691,  2412,  2081,  2008,  1045,  2052,  5136,\n","         6298,  1012,  2000,  3046,  2000,  2831,  5436,  2030,  2836,  2030,\n","         4087,  4751,  2055,  2023,  2143,  2052,  2022,  1999,  1996,  2616,\n","         1997,  3581, 23564, 13944,  1000,  2066,  5613,  2055,  4294,  1000,\n","         1012,  2009,  7078,  4978,  1996, 13774,  2157,  2006,  1996,  2132,\n","         1999,  1996,  2126,  2009, 19566,  2216, 25085,  5312,  1999,  2166,\n","         2008,  2693,  2149,  1998,  2059,  2448,  2185,  2013,  2149,  2196,\n","         2000,  2022,  5281,  2153,  1012,  2023,  3849,  2066,  1996,  3185,\n","         1996,  2839,  2544,  1997,  4918, 23699,  1999,  1996,  3185,  6789,\n","         2359,  2000,  4339,  1012,  1996,  4566,  2003,  2187,  2330,  1998,\n","        20080,  1010,  2053,  3407,  4566,  2182,  1010,  2074,  6547,  1012,\n","         2053, 13769,  2166,  8220,  1010,  2074,  1037,  3232,  1997,  7109,\n","         2100,  1998,  9414,  4268, 11131,  1996,  3754,  2000,  2514,  1996,\n","         2087, 23179,  1998,  4895, 22852,  6553,  1997,  5346,  1012,  1012,\n","         1012,  1012,  1012,  1012,  6298,  2293,  1012,  1026,  7987,  1013,\n","         1028,  1026,  7987,  1013,  1028,  2184,  2041,  1997,  2184,  3422,\n","         2009,  2007,  2115,  2569,  3203,  1998, 16755,  2009,  2000,  1037,\n","         7985,  1012,  1012,  1012,  1012,  1012,  1012,  1012,  1012,  1012,\n","         1012,  1012,  1012,  1012,  1012,  1012,  1012,   102,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","source":["train_y_pos = np.array(train_labels) == 'pos'\n","train_y_neg = np.array(train_labels) == 'neg'\n","train_y_both = np.column_stack((train_y_pos, train_y_neg))\n","train_y_both = train_y_both.astype(float)\n","train_labels_tensor = torch.tensor(train_y_both)\n","print(train_labels_tensor.shape)\n","\n","val_y_pos = np.array(val_labels) == 'pos'\n","val_y_neg = np.array(val_labels) == 'neg'\n","val_y_both = np.column_stack((val_y_pos, val_y_neg))\n","val_y_both = val_y_both.astype(float)\n","val_labels_tensor = torch.tensor(val_y_both)\n","print(val_labels_tensor.shape)\n","\n","test_y_pos = np.array(test_labels) == 'pos'\n","test_y_neg = np.array(test_labels) == 'neg'\n","test_y_both = np.column_stack((test_y_pos, test_y_neg))\n","test_y_both = test_y_both.astype(float)\n","test_labels_tensor = torch.tensor(test_y_both)\n","print(test_labels_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWNSu2OWAgQE","executionInfo":{"status":"ok","timestamp":1669020210372,"user_tz":300,"elapsed":17,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"db3b9046-b388-4fcc-9932-e322f37d9e9b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([12500, 2])\n","torch.Size([500, 2])\n","torch.Size([25000, 2])\n"]}]},{"cell_type":"code","source":["# Setting up dataloaders\n","train_dataset = TensorDataset(train_ids, train_masks, train_labels_tensor)\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","val_dataset = TensorDataset(val_ids, val_masks, val_labels_tensor)\n","val_sampler = SequentialSampler(val_dataset)\n","val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=BATCH_SIZE)\n","\n","test_dataset = TensorDataset(test_ids, test_masks, test_labels_tensor)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"],"metadata":{"id":"i7oYDiNw0oKh","executionInfo":{"status":"ok","timestamp":1669020210373,"user_tz":300,"elapsed":14,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"zsD18BEpWjPj"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsQmwjBQ5Dzp","executionInfo":{"status":"ok","timestamp":1669020215275,"user_tz":300,"elapsed":4915,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"6e8fc769-68fb-4aa1-bfbb-602117f93e1b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-idREUk5rtR","executionInfo":{"status":"ok","timestamp":1669020215275,"user_tz":300,"elapsed":33,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"5042fb07-0650-4b04-90d0-04b97e70013d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}]},{"cell_type":"code","source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = LEARNING_RATE, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                  )"],"metadata":{"id":"Ako50eEw57vh","executionInfo":{"status":"ok","timestamp":1669020215276,"user_tz":300,"elapsed":30,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * EPOCHS\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"metadata":{"id":"w0sp0sL9RkeB","executionInfo":{"status":"ok","timestamp":1669020215277,"user_tz":300,"elapsed":30,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Fine-tune BERT"],"metadata":{"id":"ZtZ5osDwZljU"}},{"cell_type":"markdown","source":["### Helpers"],"metadata":{"id":"5Lz3xK8_DE0B"}},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    # pred_flat = np.argmax(preds, axis=1).flatten()\n","    # labels_flat = labels.flatten()\n","    pred_flat = np.argmax(preds, axis=1)\n","    labels_flat = np.argmax(labels, axis=1)\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"fa47Uwv_6kll","executionInfo":{"status":"ok","timestamp":1669023981973,"user_tz":300,"elapsed":4,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"YNVhy7mo6nMM","executionInfo":{"status":"ok","timestamp":1669020215277,"user_tz":300,"elapsed":29,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def validate_model(model, validation_dataloader):\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask,\n","                            labels=b_labels.float())\n","            loss = outputs['loss']\n","            logits = outputs['logits']\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","\n","    return avg_val_accuracy, avg_val_loss"],"metadata":{"id":"lIWtyF748nTm","executionInfo":{"status":"ok","timestamp":1669020215278,"user_tz":300,"elapsed":30,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"enjYlDBIDHa6"}},{"cell_type":"code","source":["# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, EPOCHS):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass.\n","        model.zero_grad()\n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels.float())\n","        loss = outputs['loss']\n","        logits = outputs['logits']\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","\n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    avg_val_accuracy, avg_val_loss = validate_model(model, val_dataloader)\n","\n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBvPfMh76xd4","executionInfo":{"status":"ok","timestamp":1669022621693,"user_tz":300,"elapsed":2406444,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"1c16408e-e0a9-4431-8b3e-6b734b6f56ea"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of  1,563.    Elapsed: 0:00:15.\n","  Batch    80  of  1,563.    Elapsed: 0:00:29.\n","  Batch   120  of  1,563.    Elapsed: 0:00:44.\n","  Batch   160  of  1,563.    Elapsed: 0:00:59.\n","  Batch   200  of  1,563.    Elapsed: 0:01:14.\n","  Batch   240  of  1,563.    Elapsed: 0:01:30.\n","  Batch   280  of  1,563.    Elapsed: 0:01:45.\n","  Batch   320  of  1,563.    Elapsed: 0:02:00.\n","  Batch   360  of  1,563.    Elapsed: 0:02:15.\n","  Batch   400  of  1,563.    Elapsed: 0:02:31.\n","  Batch   440  of  1,563.    Elapsed: 0:02:46.\n","  Batch   480  of  1,563.    Elapsed: 0:03:01.\n","  Batch   520  of  1,563.    Elapsed: 0:03:16.\n","  Batch   560  of  1,563.    Elapsed: 0:03:32.\n","  Batch   600  of  1,563.    Elapsed: 0:03:47.\n","  Batch   640  of  1,563.    Elapsed: 0:04:02.\n","  Batch   680  of  1,563.    Elapsed: 0:04:17.\n","  Batch   720  of  1,563.    Elapsed: 0:04:33.\n","  Batch   760  of  1,563.    Elapsed: 0:04:48.\n","  Batch   800  of  1,563.    Elapsed: 0:05:03.\n","  Batch   840  of  1,563.    Elapsed: 0:05:19.\n","  Batch   880  of  1,563.    Elapsed: 0:05:34.\n","  Batch   920  of  1,563.    Elapsed: 0:05:49.\n","  Batch   960  of  1,563.    Elapsed: 0:06:04.\n","  Batch 1,000  of  1,563.    Elapsed: 0:06:20.\n","  Batch 1,040  of  1,563.    Elapsed: 0:06:35.\n","  Batch 1,080  of  1,563.    Elapsed: 0:06:50.\n","  Batch 1,120  of  1,563.    Elapsed: 0:07:05.\n","  Batch 1,160  of  1,563.    Elapsed: 0:07:21.\n","  Batch 1,200  of  1,563.    Elapsed: 0:07:36.\n","  Batch 1,240  of  1,563.    Elapsed: 0:07:51.\n","  Batch 1,280  of  1,563.    Elapsed: 0:08:06.\n","  Batch 1,320  of  1,563.    Elapsed: 0:08:22.\n","  Batch 1,360  of  1,563.    Elapsed: 0:08:37.\n","  Batch 1,400  of  1,563.    Elapsed: 0:08:52.\n","  Batch 1,440  of  1,563.    Elapsed: 0:09:07.\n","  Batch 1,480  of  1,563.    Elapsed: 0:09:23.\n","  Batch 1,520  of  1,563.    Elapsed: 0:09:38.\n","  Batch 1,560  of  1,563.    Elapsed: 0:09:53.\n","\n","  Average training loss: 0.61\n","  Training epcoh took: 0:09:54\n","\n","Running Validation...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  import sys\n"]},{"output_type":"stream","name":"stdout","text":["  Accuracy: 0.00\n","  Validation Loss: 0.48\n","  Validation took: 0:00:07\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of  1,563.    Elapsed: 0:00:15.\n","  Batch    80  of  1,563.    Elapsed: 0:00:30.\n","  Batch   120  of  1,563.    Elapsed: 0:00:46.\n","  Batch   160  of  1,563.    Elapsed: 0:01:01.\n","  Batch   200  of  1,563.    Elapsed: 0:01:16.\n","  Batch   240  of  1,563.    Elapsed: 0:01:31.\n","  Batch   280  of  1,563.    Elapsed: 0:01:47.\n","  Batch   320  of  1,563.    Elapsed: 0:02:02.\n","  Batch   360  of  1,563.    Elapsed: 0:02:17.\n","  Batch   400  of  1,563.    Elapsed: 0:02:32.\n","  Batch   440  of  1,563.    Elapsed: 0:02:48.\n","  Batch   480  of  1,563.    Elapsed: 0:03:03.\n","  Batch   520  of  1,563.    Elapsed: 0:03:18.\n","  Batch   560  of  1,563.    Elapsed: 0:03:33.\n","  Batch   600  of  1,563.    Elapsed: 0:03:48.\n","  Batch   640  of  1,563.    Elapsed: 0:04:04.\n","  Batch   680  of  1,563.    Elapsed: 0:04:19.\n","  Batch   720  of  1,563.    Elapsed: 0:04:34.\n","  Batch   760  of  1,563.    Elapsed: 0:04:49.\n","  Batch   800  of  1,563.    Elapsed: 0:05:04.\n","  Batch   840  of  1,563.    Elapsed: 0:05:20.\n","  Batch   880  of  1,563.    Elapsed: 0:05:35.\n","  Batch   920  of  1,563.    Elapsed: 0:05:50.\n","  Batch   960  of  1,563.    Elapsed: 0:06:05.\n","  Batch 1,000  of  1,563.    Elapsed: 0:06:20.\n","  Batch 1,040  of  1,563.    Elapsed: 0:06:36.\n","  Batch 1,080  of  1,563.    Elapsed: 0:06:51.\n","  Batch 1,120  of  1,563.    Elapsed: 0:07:06.\n","  Batch 1,160  of  1,563.    Elapsed: 0:07:21.\n","  Batch 1,200  of  1,563.    Elapsed: 0:07:37.\n","  Batch 1,240  of  1,563.    Elapsed: 0:07:52.\n","  Batch 1,280  of  1,563.    Elapsed: 0:08:07.\n","  Batch 1,320  of  1,563.    Elapsed: 0:08:22.\n","  Batch 1,360  of  1,563.    Elapsed: 0:08:37.\n","  Batch 1,400  of  1,563.    Elapsed: 0:08:53.\n","  Batch 1,440  of  1,563.    Elapsed: 0:09:08.\n","  Batch 1,480  of  1,563.    Elapsed: 0:09:23.\n","  Batch 1,520  of  1,563.    Elapsed: 0:09:38.\n","  Batch 1,560  of  1,563.    Elapsed: 0:09:53.\n","\n","  Average training loss: 0.61\n","  Training epcoh took: 0:09:54\n","\n","Running Validation...\n","  Accuracy: 0.00\n","  Validation Loss: 0.63\n","  Validation took: 0:00:07\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of  1,563.    Elapsed: 0:00:15.\n","  Batch    80  of  1,563.    Elapsed: 0:00:30.\n","  Batch   120  of  1,563.    Elapsed: 0:00:46.\n","  Batch   160  of  1,563.    Elapsed: 0:01:01.\n","  Batch   200  of  1,563.    Elapsed: 0:01:16.\n","  Batch   240  of  1,563.    Elapsed: 0:01:31.\n","  Batch   280  of  1,563.    Elapsed: 0:01:46.\n","  Batch   320  of  1,563.    Elapsed: 0:02:02.\n","  Batch   360  of  1,563.    Elapsed: 0:02:17.\n","  Batch   400  of  1,563.    Elapsed: 0:02:32.\n","  Batch   440  of  1,563.    Elapsed: 0:02:47.\n","  Batch   480  of  1,563.    Elapsed: 0:03:02.\n","  Batch   520  of  1,563.    Elapsed: 0:03:18.\n","  Batch   560  of  1,563.    Elapsed: 0:03:33.\n","  Batch   600  of  1,563.    Elapsed: 0:03:48.\n","  Batch   640  of  1,563.    Elapsed: 0:04:03.\n","  Batch   680  of  1,563.    Elapsed: 0:04:19.\n","  Batch   720  of  1,563.    Elapsed: 0:04:34.\n","  Batch   760  of  1,563.    Elapsed: 0:04:49.\n","  Batch   800  of  1,563.    Elapsed: 0:05:04.\n","  Batch   840  of  1,563.    Elapsed: 0:05:19.\n","  Batch   880  of  1,563.    Elapsed: 0:05:35.\n","  Batch   920  of  1,563.    Elapsed: 0:05:50.\n","  Batch   960  of  1,563.    Elapsed: 0:06:05.\n","  Batch 1,000  of  1,563.    Elapsed: 0:06:20.\n","  Batch 1,040  of  1,563.    Elapsed: 0:06:35.\n","  Batch 1,080  of  1,563.    Elapsed: 0:06:51.\n","  Batch 1,120  of  1,563.    Elapsed: 0:07:06.\n","  Batch 1,160  of  1,563.    Elapsed: 0:07:21.\n","  Batch 1,200  of  1,563.    Elapsed: 0:07:36.\n","  Batch 1,240  of  1,563.    Elapsed: 0:07:52.\n","  Batch 1,280  of  1,563.    Elapsed: 0:08:07.\n","  Batch 1,320  of  1,563.    Elapsed: 0:08:22.\n","  Batch 1,360  of  1,563.    Elapsed: 0:08:37.\n","  Batch 1,400  of  1,563.    Elapsed: 0:08:52.\n","  Batch 1,440  of  1,563.    Elapsed: 0:09:08.\n","  Batch 1,480  of  1,563.    Elapsed: 0:09:23.\n","  Batch 1,520  of  1,563.    Elapsed: 0:09:38.\n","  Batch 1,560  of  1,563.    Elapsed: 0:09:53.\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:09:54\n","\n","Running Validation...\n","  Accuracy: 0.00\n","  Validation Loss: 0.70\n","  Validation took: 0:00:07\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of  1,563.    Elapsed: 0:00:15.\n","  Batch    80  of  1,563.    Elapsed: 0:00:30.\n","  Batch   120  of  1,563.    Elapsed: 0:00:46.\n","  Batch   160  of  1,563.    Elapsed: 0:01:01.\n","  Batch   200  of  1,563.    Elapsed: 0:01:16.\n","  Batch   240  of  1,563.    Elapsed: 0:01:31.\n","  Batch   280  of  1,563.    Elapsed: 0:01:46.\n","  Batch   320  of  1,563.    Elapsed: 0:02:02.\n","  Batch   360  of  1,563.    Elapsed: 0:02:17.\n","  Batch   400  of  1,563.    Elapsed: 0:02:32.\n","  Batch   440  of  1,563.    Elapsed: 0:02:47.\n","  Batch   480  of  1,563.    Elapsed: 0:03:03.\n","  Batch   520  of  1,563.    Elapsed: 0:03:18.\n","  Batch   560  of  1,563.    Elapsed: 0:03:33.\n","  Batch   600  of  1,563.    Elapsed: 0:03:48.\n","  Batch   640  of  1,563.    Elapsed: 0:04:03.\n","  Batch   680  of  1,563.    Elapsed: 0:04:19.\n","  Batch   720  of  1,563.    Elapsed: 0:04:34.\n","  Batch   760  of  1,563.    Elapsed: 0:04:49.\n","  Batch   800  of  1,563.    Elapsed: 0:05:04.\n","  Batch   840  of  1,563.    Elapsed: 0:05:20.\n","  Batch   880  of  1,563.    Elapsed: 0:05:35.\n","  Batch   920  of  1,563.    Elapsed: 0:05:50.\n","  Batch   960  of  1,563.    Elapsed: 0:06:05.\n","  Batch 1,000  of  1,563.    Elapsed: 0:06:20.\n","  Batch 1,040  of  1,563.    Elapsed: 0:06:36.\n","  Batch 1,080  of  1,563.    Elapsed: 0:06:51.\n","  Batch 1,120  of  1,563.    Elapsed: 0:07:06.\n","  Batch 1,160  of  1,563.    Elapsed: 0:07:21.\n","  Batch 1,200  of  1,563.    Elapsed: 0:07:36.\n","  Batch 1,240  of  1,563.    Elapsed: 0:07:52.\n","  Batch 1,280  of  1,563.    Elapsed: 0:08:07.\n","  Batch 1,320  of  1,563.    Elapsed: 0:08:22.\n","  Batch 1,360  of  1,563.    Elapsed: 0:08:37.\n","  Batch 1,400  of  1,563.    Elapsed: 0:08:52.\n","  Batch 1,440  of  1,563.    Elapsed: 0:09:08.\n","  Batch 1,480  of  1,563.    Elapsed: 0:09:23.\n","  Batch 1,520  of  1,563.    Elapsed: 0:09:38.\n","  Batch 1,560  of  1,563.    Elapsed: 0:09:53.\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:09:54\n","\n","Running Validation...\n","  Accuracy: 0.00\n","  Validation Loss: 0.36\n","  Validation took: 0:00:07\n","\n","Training complete!\n","Total training took 0:40:06 (h:mm:ss)\n"]}]},{"cell_type":"code","source":["# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"tCXgDoxI9o6s","executionInfo":{"status":"ok","timestamp":1669022990244,"user_tz":300,"elapsed":6,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"fb679bd7-f4d2-4a7b-bb86-f6c98f373966"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.61         0.48            0.0       0:09:54         0:00:07\n","2               0.61         0.63            0.0       0:09:54         0:00:07\n","3               0.63         0.70            0.0       0:09:54         0:00:07\n","4               0.50         0.36            0.0       0:09:54         0:00:07"],"text/html":["\n","  <div id=\"df-c79836e4-1580-4343-8e55-fdbbad3f02eb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.61</td>\n","      <td>0.48</td>\n","      <td>0.0</td>\n","      <td>0:09:54</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.61</td>\n","      <td>0.63</td>\n","      <td>0.0</td>\n","      <td>0:09:54</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.63</td>\n","      <td>0.70</td>\n","      <td>0.0</td>\n","      <td>0:09:54</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.50</td>\n","      <td>0.36</td>\n","      <td>0.0</td>\n","      <td>0:09:54</td>\n","      <td>0:00:07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c79836e4-1580-4343-8e55-fdbbad3f02eb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c79836e4-1580-4343-8e55-fdbbad3f02eb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c79836e4-1580-4343-8e55-fdbbad3f02eb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["### Test on test data"],"metadata":{"id":"x_5E1t7L9yO3"}},{"cell_type":"code","source":["print(\"\")\n","print(\"Running Test Set...\")\n","\n","t0 = time.time()\n","\n","avg_accuracy, avg_loss = validate_model(model, test_dataloader)\n","\n","# Measure how long the validation run took.\n","test_time = format_time(time.time() - t0)\n","\n","print(\"  Accuracy: {0:.2f}\".format(avg_accuracy))\n","print(\"  Loss: {0:.2f}\".format(avg_loss))\n","print(\"  Time taken: {:}\".format(test_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PFaNbMTjrCg","executionInfo":{"status":"ok","timestamp":1669024373231,"user_tz":300,"elapsed":368605,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}},"outputId":"0b2301d8-fcb6-4274-b8de-5c603099337b"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running Test Set...\n","  Accuracy: 0.83\n","  Loss: 0.45\n","  Time taken: 0:06:08\n"]}]},{"cell_type":"code","source":["model.save_pretrained(\"bert_imdb\")"],"metadata":{"id":"_axqT1lcqHdl","executionInfo":{"status":"ok","timestamp":1669025312382,"user_tz":300,"elapsed":1755,"user":{"displayName":"Judy Lin","userId":"04117229972901548352"}}},"execution_count":50,"outputs":[]}]}