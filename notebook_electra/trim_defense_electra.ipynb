{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c6b1bac27914f569dfc9a720605c17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49d538c7598f44768ec49f3f5c44495a",
              "IPY_MODEL_756b40c3550446099eab7fd1cf637ca8",
              "IPY_MODEL_03c043d3b2e34121901be605b4d486ac"
            ],
            "layout": "IPY_MODEL_29d48fa4b40f4e96928a2a0614f8b1d3"
          }
        },
        "49d538c7598f44768ec49f3f5c44495a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2091b47c98944fccb4075854cc1182ba",
            "placeholder": "​",
            "style": "IPY_MODEL_7089212c55734095b42236e2396f0e72",
            "value": "Downloading: 100%"
          }
        },
        "756b40c3550446099eab7fd1cf637ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cf734f88e44669875c4125a1c8402d",
            "max": 1103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56b1cf04f74a4790bc6bef391d3206db",
            "value": 1103
          }
        },
        "03c043d3b2e34121901be605b4d486ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6097850c9464d4ea394b3f53d3f2c40",
            "placeholder": "​",
            "style": "IPY_MODEL_28c18f64aadc4c9398ca5b07a4f35941",
            "value": " 1.08k/1.08k [00:00&lt;00:00, 47.9kB/s]"
          }
        },
        "29d48fa4b40f4e96928a2a0614f8b1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2091b47c98944fccb4075854cc1182ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7089212c55734095b42236e2396f0e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06cf734f88e44669875c4125a1c8402d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b1cf04f74a4790bc6bef391d3206db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6097850c9464d4ea394b3f53d3f2c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c18f64aadc4c9398ca5b07a4f35941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27a3e488e6264832ae4dab754f431efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dd17beaf8b7492c8c356a0011acefb7",
              "IPY_MODEL_a877d578837243adaa5e0e1a9a22bdd2",
              "IPY_MODEL_ded007ff88224962bf9cd74613c763f7"
            ],
            "layout": "IPY_MODEL_1eae2941b2d34a3c9ff33d6df839c7d6"
          }
        },
        "0dd17beaf8b7492c8c356a0011acefb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a358a71add9e4386aee3ab93dceba4fd",
            "placeholder": "​",
            "style": "IPY_MODEL_c925e91c42944a7bbcd8c5803b4e26e0",
            "value": "Downloading: 100%"
          }
        },
        "a877d578837243adaa5e0e1a9a22bdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa703e6ed4484b359b5a872a35a55a6c",
            "max": 134401001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a4abb95e5c4a64a70e00c1a66f298b",
            "value": 134401001
          }
        },
        "ded007ff88224962bf9cd74613c763f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c3c56fb13e4882ab76ce4bc647a9c6",
            "placeholder": "​",
            "style": "IPY_MODEL_432b3b89aef244b48d7baa82eaca9cca",
            "value": " 128M/128M [00:01&lt;00:00, 83.0MB/s]"
          }
        },
        "1eae2941b2d34a3c9ff33d6df839c7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a358a71add9e4386aee3ab93dceba4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c925e91c42944a7bbcd8c5803b4e26e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa703e6ed4484b359b5a872a35a55a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a4abb95e5c4a64a70e00c1a66f298b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7c3c56fb13e4882ab76ce4bc647a9c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432b3b89aef244b48d7baa82eaca9cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_g7U7dyCb_Q",
        "outputId": "44fdf636-ace6-41a1-a861-e6a6ac5c34a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "print(\"\\n################################################################################\\n\")\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEbVIMHECld4",
        "outputId": "a289ea2c-f2b5-4759-a87f-e5c14964f9d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  8 16:55:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    58W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "################################################################################\n",
            "\n",
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!git clone https://github.com/YunZhi246/subpopulation-data-poisoning-attacks.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ1ccC8BCl1N",
        "outputId": "dc749e41-2334-4859-b0f9-72b6296091cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "Cloning into 'subpopulation-data-poisoning-attacks'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 137 (delta 77), reused 98 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (137/137), 1.61 MiB | 10.73 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/subpopulation-data-poisoning-attacks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-7S0MGvCplX",
        "outputId": "ea207a0c-a587-4d5c-a1b6-334dd1192ac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/subpopulation-data-poisoning-attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kupnfMrYCq3y",
        "outputId": "01380fcf-8961-4f8a-9a0c-cf45b357ebbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n",
            "Collecting pandas==1.0.1\n",
            "  Downloading pandas-1.0.1-cp38-cp38-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 4.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 85.6 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.10.0\n",
            "  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 92.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n",
            "Collecting transformers==4.20.0\n",
            "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting tables==3.6.1\n",
            "  Downloading tables-3.6.1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 57.3 MB/s \n",
            "\u001b[?25hCollecting datasets==2.7.1\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 86.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from seaborn==0.10.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 92.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (21.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.8/dist-packages (from tables==3.6.1->-r requirements.txt (line 9)) (2.8.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (0.3.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 95.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 92.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (2022.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.5.0->-r requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (6.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 91.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, xxhash, tokenizers, scipy, responses, pandas, multiprocess, huggingface-hub, transformers, tables, seaborn, scikit-learn, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: tables\n",
            "    Found existing installation: tables 3.7.0\n",
            "    Uninstalling tables-3.7.0:\n",
            "      Successfully uninstalled tables-3.7.0\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.1 which is incompatible.\n",
            "xarray-einstats 0.3.0 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n",
            "plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\u001b[0m\n",
            "Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 pandas-1.0.1 responses-0.18.0 scikit-learn-0.22.1 scipy-1.4.1 seaborn-0.10.0 tables-3.6.1 tokenizers-0.12.1 transformers-4.20.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2VLX2JKCr4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook"
      ],
      "metadata": {
        "id": "DaXEf76hCwkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "GHGXxuy7Cx0u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n"
      ],
      "metadata": {
        "id": "D_LPxSD4CyeO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from attack_nlp import init_cluster_attack\n",
        "from subclass_avail import common\n",
        "from subclass_avail.target_nlp import bert_utils"
      ],
      "metadata": {
        "id": "Z2rfGqPlCzdY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "\n",
        "seed = 42\n",
        "batch = 4\n",
        "lr = 1e-5\n",
        "epochs = 4\n",
        "\n",
        "# Run specific parameters\n",
        "pois_rate = 2.0\n",
        "cl_ind = 49\n",
        "n_remove = 150\n",
        "base_def = 0.992462\n",
        "\n",
        "m_type = 'FT'\n",
        "frozen = False\n"
      ],
      "metadata": {
        "id": "Wt718qiLC25m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = bert_utils.get_device()\n",
        "bert_utils.set_seed(device, seed=seed)  # Seed all the PRNGs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeW_yaMCDBUM",
        "outputId": "387a561b-07c9-46d3-df8b-31a4f9ea7bc4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common.create_dirs()\n",
        "\n",
        "model_name = bert_utils.get_model_name()\n",
        "victim_dir = \"/content/drive/MyDrive/storage/other/saved_models/victims\"\n",
        "save_path = os.path.join(\n",
        "    victim_dir,\n",
        "    'attack_setup_{}_{}.npy'.format(model_name, pois_rate)\n",
        ")\n",
        "setup_params = np.load(save_path, allow_pickle=True).item()\n",
        "\n",
        "all_inds = setup_params[\"all_inds\"]\n",
        "labels = setup_params[\"labels\"]\n",
        "labels_t = setup_params[\"labels_t\"]\n",
        "labels_ho = setup_params[\"labels_ho\"]\n",
        "preds_ho = setup_params[\"preds_ho\"]\n",
        "x = setup_params[\"x\"]\n",
        "x_att = setup_params[\"x_att\"]\n",
        "x_ho = setup_params[\"x_ho\"]\n",
        "x_ho_att = setup_params[\"x_ho_att\"]\n",
        "x_t = setup_params[\"x_t\"]\n",
        "x_t_att = setup_params[\"x_t_att\"]\n",
        "y = setup_params[\"y\"]\n",
        "y_t = setup_params[\"y_t\"]\n",
        "y_ho = setup_params[\"y_ho\"]\n",
        "\n",
        "print('\\nx shape: {}\\nx_ho shape:{}\\nx_t shape: {}'.format(x.shape, x_ho.shape, x_t.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OibRX9ipDDej",
        "outputId": "afaafb81-6ef8-4ed4-e75e-e86bf8daeaca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "x shape: (12500, 256)\n",
            "x_ho shape:(12500, 256)\n",
            "x_t shape: (25000, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_inds = np.where(labels == cl_ind)[0]\n",
        "tst_inds = np.where(labels_t == cl_ind)[0]\n",
        "ho_inds = np.where(labels_ho == cl_ind)[0]\n",
        "pois_inds = np.random.choice(\n",
        "    ho_inds,\n",
        "    int(ho_inds.shape[0] * pois_rate),\n",
        "    replace=True\n",
        ")\n",
        "print(\"cluster ind:\", cl_ind)\n",
        "print(\"train cluster size:\", trn_inds.shape[0])\n",
        "print(\"test cluster size:\", tst_inds.shape[0])\n",
        "print(\"pois cluster size\", pois_inds.shape[0])\n",
        "trn_x = x\n",
        "trn_y = y\n",
        "trn_x_att = x_att\n",
        "\n",
        "preds_cl = preds_ho[ho_inds].sum(axis=0)\n",
        "assert preds_cl.size == 2\n",
        "\n",
        "worst_class = np.argmin(preds_cl)\n",
        "print(worst_class, preds_cl)\n",
        "\n",
        "pois_x = np.take(x_ho, pois_inds, axis=0)\n",
        "pois_y = np.take(y_ho, pois_inds, axis=0)\n",
        "pois_x_att = np.take(x_ho_att, pois_inds, axis=0)\n",
        "\n",
        "pois_y[:] = worst_class  # Assigns the worst class label to every poison point\n",
        "trn_x = np.concatenate((trn_x, pois_x))\n",
        "trn_y = np.concatenate((trn_y, pois_y))\n",
        "trn_x_att = np.concatenate((trn_x_att, pois_x_att))\n",
        "rand_inds = np.random.choice(trn_x.shape[0], trn_x.shape[0], replace=False)\n",
        "xt_p, xt_p_att, yt_p = x_t[tst_inds], x_t_att[tst_inds], y_t[tst_inds]\n",
        "\n",
        "# Create the subset of the test set not containing the targeted\n",
        "# sub population to compute the collateral damage\n",
        "x_coll = x_t[[i for i in range(x_t.shape[0]) if i not in tst_inds]]\n",
        "x_coll_att = x_t_att[[i for i in range(x_t_att.shape[0]) if i not in tst_inds]]\n",
        "y_coll = y_t[[i for i in range(y_t.shape[0]) if i not in tst_inds]]\n",
        "print('\\nx coll shape: {}\\nx_att coll shape:{}\\ny coll shape: {}'.format(\n",
        "    x_coll.shape, x_coll_att.shape, y_coll.shape))"
      ],
      "metadata": {
        "id": "MKjK8MizDStz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73ff60b-0902-4a43-c66a-0b2590f6e6c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cluster ind: 49\n",
            "train cluster size: 188\n",
            "test cluster size: 398\n",
            "pois cluster size 342\n",
            "1 [ 329.69856811 -315.1231035 ]\n",
            "\n",
            "x coll shape: (24602, 256)\n",
            "x_att coll shape:(24602, 256)\n",
            "y coll shape: (24602,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trim(dataset, size, x, x_att, y, num_remove):\n",
        "    inds = []\n",
        "    new_inds = list(range(x.shape[0]))\n",
        "    it = 0\n",
        "    while sorted(new_inds) != sorted(inds) and it < 5:\n",
        "        print('Trim iteration: {}\\n'.format(it))\n",
        "        it += 1\n",
        "        inds = new_inds[:]\n",
        "        \n",
        "        # model = train_model(dataset, model_type, trn_x, trn_y, tst_x, tst_y)  \n",
        "        model = bert_utils.wrap_train(\n",
        "            x,\n",
        "            y,\n",
        "            x_att,\n",
        "            b_size=batch,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            frozen=frozen\n",
        "        ) \n",
        "        \n",
        "        # Prepare torch loader\n",
        "        device = bert_utils.get_device()\n",
        "\n",
        "        test_ds = TensorDataset(\n",
        "            torch.from_numpy(x),\n",
        "            torch.from_numpy(x_att),\n",
        "            torch.from_numpy(y)\n",
        "        )\n",
        "        test_dl = DataLoader(test_ds, shuffle=False, batch_size=batch)\n",
        "         \n",
        "        # preds = model.predict(x)\n",
        "        _, preds_raw = bert_utils.predict_bert(model, device, test_dl, raw=True)\n",
        "        preds = [np.array(p) for p in preds_raw]\n",
        "        preds = np.concatenate(preds)\n",
        "        \n",
        "        # One hot encode labels\n",
        "        onehoty = OneHotEncoder().fit_transform(y.reshape(-1, 1)).toarray()\n",
        "        \n",
        "        probs = np.multiply(preds, onehoty).sum(axis=1)\n",
        "        new_inds = np.argpartition(probs, num_remove)[num_remove:]\n",
        "    return model, new_inds\n"
      ],
      "metadata": {
        "id": "MyKtuo26q98U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%time\n",
        "trim_model, trim_inds = trim(\n",
        "    dataset='imdb',\n",
        "    size=256,\n",
        "    x=trn_x[rand_inds],\n",
        "    x_att=trn_x_att[rand_inds],\n",
        "    y=trn_y[rand_inds],\n",
        "    num_remove=n_remove\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c6b1bac27914f569dfc9a720605c17a",
            "49d538c7598f44768ec49f3f5c44495a",
            "756b40c3550446099eab7fd1cf637ca8",
            "03c043d3b2e34121901be605b4d486ac",
            "29d48fa4b40f4e96928a2a0614f8b1d3",
            "2091b47c98944fccb4075854cc1182ba",
            "7089212c55734095b42236e2396f0e72",
            "06cf734f88e44669875c4125a1c8402d",
            "56b1cf04f74a4790bc6bef391d3206db",
            "b6097850c9464d4ea394b3f53d3f2c40",
            "28c18f64aadc4c9398ca5b07a4f35941",
            "27a3e488e6264832ae4dab754f431efc",
            "0dd17beaf8b7492c8c356a0011acefb7",
            "a877d578837243adaa5e0e1a9a22bdd2",
            "ded007ff88224962bf9cd74613c763f7",
            "1eae2941b2d34a3c9ff33d6df839c7d6",
            "a358a71add9e4386aee3ab93dceba4fd",
            "c925e91c42944a7bbcd8c5803b4e26e0",
            "fa703e6ed4484b359b5a872a35a55a6c",
            "61a4abb95e5c4a64a70e00c1a66f298b",
            "b7c3c56fb13e4882ab76ce4bc647a9c6",
            "432b3b89aef244b48d7baa82eaca9cca"
          ]
        },
        "id": "jiLgppTPrAg8",
        "outputId": "b041ba23-39fd-4770-a420-c176624fa1bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trim iteration: 0\n",
            "\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c6b1bac27914f569dfc9a720605c17a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/128M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27a3e488e6264832ae4dab754f431efc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:42<00:00, 19.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 0: 0.4526310321680299\n",
            "Training accuracy - epoch 0: 0.8582995951417004\n",
            "Epoch 1 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:37<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1: 0.30840358688408753\n",
            "Training accuracy - epoch 1: 0.9138118966054188\n",
            "Epoch 2 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:39<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 2: 0.2317668064087003\n",
            "Training accuracy - epoch 2: 0.9356898162566178\n",
            "Epoch 3 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:37<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 3: 0.19029599993699384\n",
            "Training accuracy - epoch 3: 0.9464341326689505\n",
            "Saving to bert_tuned\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [00:35<00:00, 90.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trim iteration: 1\n",
            "\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:38<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 0: 0.42694962596766156\n",
            "Training accuracy - epoch 0: 0.8879632513235752\n",
            "Epoch 1 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:37<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1: 0.2856705100114603\n",
            "Training accuracy - epoch 1: 0.9239333540952974\n",
            "Epoch 2 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:38<00:00, 20.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 2: 0.22518946582115595\n",
            "Training accuracy - epoch 2: 0.9428526938648396\n",
            "Epoch 3 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:37<00:00, 20.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 3: 0.1847059335118744\n",
            "Training accuracy - epoch 3: 0.9521955777016505\n",
            "Saving to bert_tuned\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [00:35<00:00, 89.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trim iteration: 2\n",
            "\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:39<00:00, 20.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 0: 0.4286693590546705\n",
            "Training accuracy - epoch 0: 0.8920896916848334\n",
            "Epoch 1 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:40<00:00, 19.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1: 0.2967961870635068\n",
            "Training accuracy - epoch 1: 0.9106197446278418\n",
            "Epoch 2 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:44<00:00, 19.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 2: 0.22922214266865268\n",
            "Training accuracy - epoch 2: 0.9405948302709436\n",
            "Epoch 3 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:45<00:00, 19.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 3: 0.18652589006650508\n",
            "Training accuracy - epoch 3: 0.9501712862036749\n",
            "Saving to bert_tuned\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [00:36<00:00, 87.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trim iteration: 3\n",
            "\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:44<00:00, 19.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 0: 0.42741068012430006\n",
            "Training accuracy - epoch 0: 0.8926346932419806\n",
            "Epoch 1 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:45<00:00, 19.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1: 0.2828751096559375\n",
            "Training accuracy - epoch 1: 0.907349735284958\n",
            "Epoch 2 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:46<00:00, 19.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 2: 0.2166490690345864\n",
            "Training accuracy - epoch 2: 0.946589847399564\n",
            "Epoch 3 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:44<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 3: 0.17580399388660295\n",
            "Training accuracy - epoch 3: 0.9569448769853628\n",
            "Saving to bert_tuned\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [00:37<00:00, 86.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trim iteration: 4\n",
            "\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:46<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 0: 0.41257033439550916\n",
            "Training accuracy - epoch 0: 0.8943475552787293\n",
            "Epoch 1 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:47<00:00, 19.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 1: 0.2788562644267242\n",
            "Training accuracy - epoch 1: 0.9283712239177826\n",
            "Epoch 2 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:46<00:00, 19.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 2: 0.22211553349572385\n",
            "Training accuracy - epoch 2: 0.9424634070383058\n",
            "Epoch 3 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [02:47<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at epoch 3: 0.17967044233368568\n",
            "Training accuracy - epoch 3: 0.9516505761445033\n",
            "Saving to bert_tuned\n",
            "Available device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3211/3211 [00:36<00:00, 88.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 9min 9s, sys: 21.9 s, total: 1h 9min 31s\n",
            "Wall time: 1h 9min 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trim model\n",
        "save_pth = os.path.join(\n",
        "    victim_dir,\n",
        "    'imdb_electra_{}_TRM_pois{}_ind{}.ckpt'.format(m_type, pois_rate, cl_ind)\n",
        ")\n",
        "print(save_pth)\n",
        "\n",
        "torch.save(trim_model.state_dict(), save_pth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXAVBHDUrC6x",
        "outputId": "96f3311c-d4da-464c-94b4-3cc0d6769d35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/storage/other/saved_models/victims/imdb_electra_FT_TRM_pois2.0_ind49.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "pois_ds = TensorDataset(\n",
        "    torch.from_numpy(xt_p),\n",
        "    torch.from_numpy(xt_p_att),\n",
        "    torch.from_numpy(yt_p)\n",
        ")\n",
        "\n",
        "pois_dl = DataLoader(pois_ds, shuffle=False, batch_size=batch)"
      ],
      "metadata": {
        "id": "QOyQJe-RrLHv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trim_acc = bert_utils.predict_bert(trim_model, device, pois_dl, acc=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPbE7esdrNRa",
        "outputId": "cc7a54ee-8d4a-40f8-a8dd-ec768063a2f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 87.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of Trim model on the poisoned data: {}'.format(trim_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJoio5oQrPHU",
        "outputId": "b1ccc86f-7291-4510-a35f-3c5d4a2bf2cf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Trim model on the poisoned data: 0.4623115577889447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('New targeted damage: {}'.format(base_def - trim_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpIAHPMZrQzq",
        "outputId": "02a4c815-eca5-4bb1-bdad-9f80fb007686"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New targeted damage: 0.5301504422110552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqBgHr-IrR7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}