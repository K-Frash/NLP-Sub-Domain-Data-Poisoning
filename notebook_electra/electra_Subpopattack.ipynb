{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evc-qYeCPlyq",
        "outputId": "70969eee-9156-4639-8f7b-ef78e8cb425f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx4SORFPPqq1",
        "outputId": "4bd0f2b8-43e0-46e2-d317-8d3f5286c475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  7 18:30:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "################################################################################\n",
            "\n",
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "print(\"\\n################################################################################\\n\")\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8QkQTwVPsXo",
        "outputId": "9b2068c0-e951-40a0-e14b-7d779dcf0f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "Cloning into 'subpopulation-data-poisoning-attacks'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 137 (delta 77), reused 98 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (137/137), 1.61 MiB | 10.60 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!ls\n",
        "!git clone https://github.com/YunZhi246/subpopulation-data-poisoning-attacks.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLF7cK-nP9II",
        "outputId": "eb6a8dfd-3b78-47b6-dfa8-ef57d0b311d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/subpopulation-data-poisoning-attacks\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%cd /content/subpopulation-data-poisoning-attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y77JHMMfQK4n",
        "outputId": "38241814-6479-4100-a341-7a312defb063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n",
            "Collecting pandas==1.0.1\n",
            "  Downloading pandas-1.0.1-cp38-cp38-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 4.8 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 84.6 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.10.0\n",
            "  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 94.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n",
            "Collecting transformers==4.20.0\n",
            "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 80.2 MB/s \n",
            "\u001b[?25hCollecting tables==3.6.1\n",
            "  Downloading tables-3.6.1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 75.2 MB/s \n",
            "\u001b[?25hCollecting datasets==2.7.1\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 91.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2022.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from seaborn==0.10.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 94.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 81.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.8/dist-packages (from tables==3.6.1->-r requirements.txt (line 9)) (2.8.4)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 93.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 92.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (2022.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.5.0->-r requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (4.0.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 92.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, xxhash, tokenizers, scipy, responses, pandas, multiprocess, huggingface-hub, transformers, tables, seaborn, scikit-learn, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: tables\n",
            "    Found existing installation: tables 3.7.0\n",
            "    Uninstalling tables-3.7.0:\n",
            "      Successfully uninstalled tables-3.7.0\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.1 which is incompatible.\n",
            "xarray-einstats 0.3.0 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n",
            "plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\u001b[0m\n",
            "Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 pandas-1.0.1 responses-0.18.0 scikit-learn-0.22.1 scipy-1.4.1 seaborn-0.10.0 tables-3.6.1 tokenizers-0.12.1 transformers-4.20.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas",
                  "scipy",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRmpy8ugQLxn",
        "outputId": "c4d8e5a9-3107-4aff-e890-7b290a5c409d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine tuning BERT model, received arguments:\n",
            "{'batch': 16, 'epochs': 4, 'length': 256, 'workers': 8, 'seed': 42, 'learning_rate': 1e-05, 'frozen': False, 'all': False}\n",
            "\n",
            "Available device:  cuda\n",
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
            "100% 3/3 [00:00<00:00, 559.07it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2eff9f118d84c6fe.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5e4fceb9d9e3c6f7.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-304051a844a15290.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-db0e155c86b7fe01.arrow\n",
            "Loading data took 2.31 seconds\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "Fine tuning DEF model\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0 of 4\n",
            "100% 782/782 [00:43<00:00, 18.00it/s]\n",
            "Train loss at epoch 0: 0.43853279677650814\n",
            "Training accuracy - epoch 0: 0.8904251918158568\n",
            "Epoch 1 of 4\n",
            "100% 782/782 [00:42<00:00, 18.35it/s]\n",
            "Train loss at epoch 1: 0.2872641726642314\n",
            "Training accuracy - epoch 1: 0.914002557544757\n",
            "Epoch 2 of 4\n",
            "100% 782/782 [00:42<00:00, 18.39it/s]\n",
            "Train loss at epoch 2: 0.24519909894012887\n",
            "Training accuracy - epoch 2: 0.9303868286445013\n",
            "Epoch 3 of 4\n",
            "100% 782/782 [00:42<00:00, 18.43it/s]\n",
            "Train loss at epoch 3: 0.2188322587972483\n",
            "Training accuracy - epoch 3: 0.935821611253197\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/imdb_electra-base-emotion_FT_DEF\n",
            "Fine tuning model took 213.95 seconds\n",
            "100% 1563/1563 [00:19<00:00, 79.60it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.904163  0.891360  0.897716     12500\n",
            "           1   0.892877  0.905520  0.899154     12500\n",
            "\n",
            "    accuracy                       0.898440     25000\n",
            "   macro avg   0.898520  0.898440  0.898435     25000\n",
            "weighted avg   0.898520  0.898440  0.898435     25000\n",
            "\n",
            "[[11142  1358]\n",
            " [ 1181 11319]]\n",
            "Fine tuning ADV model\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 782/782 [00:42<00:00, 18.32it/s]\n",
            "Train loss at epoch 0: 0.4686892521770104\n",
            "Training accuracy - epoch 0: 0.8823529411764706\n",
            "Epoch 1 of 4\n",
            "100% 782/782 [00:42<00:00, 18.32it/s]\n",
            "Train loss at epoch 1: 0.3007252495974074\n",
            "Training accuracy - epoch 1: 0.9046515345268542\n",
            "Epoch 2 of 4\n",
            "100% 782/782 [00:42<00:00, 18.31it/s]\n",
            "Train loss at epoch 2: 0.25160778805499184\n",
            "Training accuracy - epoch 2: 0.9271099744245525\n",
            "Epoch 3 of 4\n",
            "100% 782/782 [00:42<00:00, 18.32it/s]\n",
            "Train loss at epoch 3: 0.22508574983157464\n",
            "Training accuracy - epoch 3: 0.9322250639386189\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/imdb_electra-base-emotion_FT_ADV\n",
            "Fine tuning model took 211.19 seconds\n",
            "100% 1563/1563 [00:19<00:00, 79.52it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.893796  0.892080  0.892937     12500\n",
            "           1   0.892287  0.894000  0.893143     12500\n",
            "\n",
            "    accuracy                       0.893040     25000\n",
            "   macro avg   0.893041  0.893040  0.893040     25000\n",
            "weighted avg   0.893041  0.893040  0.893040     25000\n",
            "\n",
            "[[11151  1349]\n",
            " [ 1325 11175]]\n"
          ]
        }
      ],
      "source": [
        "!python train_imdb_bert.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnCu5pWnRHKJ",
        "outputId": "e2037a3d-5fdf-4bde-9d06-05f6f67e983b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing sub-population poisoning attack, received arguments:\n",
            "{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 0.5, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1, 'eval_only': False}\n",
            "\n",
            "Available device:  cuda\n",
            "Available device:  cuda\n",
            "Loading model: imdb_electra-base-emotion_FT_ADV.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
            "100% 3/3 [00:00<00:00, 558.20it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2eff9f118d84c6fe.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5e4fceb9d9e3c6f7.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-304051a844a15290.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-db0e155c86b7fe01.arrow\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "\n",
            "Getting def train representations\n",
            "Available device:  cuda\n",
            "Representation size:(12500, 256, 256)\n",
            "Representations file not found, creating it now.\n",
            "100% 3125/3125 [00:45<00:00, 68.09it/s]\n",
            "\n",
            "Getting adv train representations\n",
            "Available device:  cuda\n",
            "Representation size:(12500, 256, 256)\n",
            "Representations file not found, creating it now.\n",
            "100% 3125/3125 [00:48<00:00, 64.00it/s]\n",
            "\n",
            "Getting test representations\n",
            "Available device:  cuda\n",
            "Representation size:(25000, 256, 256)\n",
            "Representations file not found, creating it now.\n",
            "100% 6250/6250 [01:38<00:00, 63.72it/s]\n",
            "\n",
            "Computing predictions on the training sets\n",
            "100% 3125/3125 [00:35<00:00, 87.61it/s]\n",
            "100% 3125/3125 [00:35<00:00, 89.10it/s]\n",
            "\n",
            "Shapes\n",
            "\tll: (12500, 65536)\n",
            "\tll_ho: (12500, 65536)\n",
            "\tll_t: (25000, 65536)\n",
            "\n",
            "Clustering ll_ho\n",
            "tcmalloc: large alloc 3276800000 bytes == 0xb3042000 @  0x7f3c705731e7 0x7f3c0056914e 0x7f3c005c5166 0x7f3c005b7665 0x7f3c0066875c 0x5aa114 0x49ced5 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ec69 0x55e858 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x7f36ccc00000 @  0x7f3c705731e7 0x7f3c0056914e 0x7f3c005c1745 0x7f3c005c1878 0x7f3c00681604 0x7f3c006848ec 0x7f3c0080fbd4 0x4eb089 0x5d86fe 0x7f3c0068b286 0x606ad6 0x5132dc 0x55fce5 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e858 0x5d7cf1 0x5d77c6 0x7f3c005ab944 0x5d74fd 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c\n",
            "\n",
            "Clustering ll_t\n",
            "tcmalloc: large alloc 6553600000 bytes == 0x7f3546200000 @  0x7f3c705731e7 0x7f3c0056914e 0x7f3c005c1745 0x7f3c005c1878 0x7f3c00681604 0x7f3c006848ec 0x7f3c0080fbd4 0x4eb089 0x5d86fe 0x7f3c0068b286 0x606ad6 0x5132dc 0x55fce5 0x4fda1b 0x49ec69 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be 0x644688 0x644c2c\n",
            "\n",
            "Clustering ll\n",
            "tcmalloc: large alloc 3276800000 bytes == 0xb3042000 @  0x7f3c705731e7 0x7f3c0056914e 0x7f3c005c1745 0x7f3c005c1878 0x7f3c00681604 0x7f3c006848ec 0x7f3c0080fbd4 0x4eb089 0x5d86fe 0x7f3c0068b286 0x606ad6 0x5132dc 0x55fce5 0x4fda1b 0x49ec69 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be 0x644688 0x644c2c\n",
            "labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([135, 135,  93,  54, 133, 103, 109, 134, 227, 227, 131, 111, 147,\n",
            "        92, 129,  72,  99,  67, 116, 216,  87,  72, 155, 166,  74, 101,\n",
            "       152,  73, 264, 120, 105, 111,  97,  97, 116,  83,  82, 128,  98,\n",
            "       123, 120, 159, 206, 124,  75, 146,  94, 154,  72, 188, 131, 277,\n",
            "       104,  84,  74, 189, 125, 145,  79,  92, 143,  57, 163,  80, 135,\n",
            "       143, 107, 115, 110,  62, 111, 213,  80, 124,  93, 113, 106, 152,\n",
            "       198, 198, 139, 159, 128, 176,  83, 149,  81, 237, 100, 114, 235,\n",
            "        42, 105, 128, 169, 118, 104,  55, 105,  98]))\n",
            "ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([154, 153, 110,  64, 158,  82,  93, 144, 217, 241, 155, 113, 147,\n",
            "        83, 122,  89,  95,  62, 113, 193,  72,  55, 164, 155,  70, 109,\n",
            "       160,  72, 231, 118,  89,  77,  97, 110, 118, 102,  88, 134, 101,\n",
            "       147, 114, 187, 159, 140,  61, 172,  94, 157,  87, 171, 123, 267,\n",
            "       112,  88,  78, 213, 116, 111,  75,  84, 168,  54, 153,  72,  99,\n",
            "       154, 129, 104, 107,  66, 105, 212,  96, 128,  93, 112,  96, 158,\n",
            "       188, 202, 156, 171, 126, 166,  80, 129,  87, 233,  80, 128, 220,\n",
            "        35,  89, 119, 191, 140, 112,  75,  89, 112]))\n",
            "test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([277, 288, 157, 108, 335, 202, 199, 254, 468, 496, 303, 237, 272,\n",
            "       170, 243, 168, 239, 118, 208, 343, 193, 131, 312, 341, 163, 214,\n",
            "       327, 144, 480, 228, 179, 161, 194, 259, 225, 179, 177, 272, 195,\n",
            "       290, 214, 377, 359, 271, 140, 302, 207, 323, 191, 398, 210, 554,\n",
            "       226, 179, 140, 404, 211, 230, 156, 185, 282, 121, 292, 155, 201,\n",
            "       265, 248, 226, 209, 133, 207, 427, 156, 225, 201, 238, 193, 356,\n",
            "       403, 421, 279, 335, 219, 377, 135, 291, 189, 499, 168, 255, 445,\n",
            "        76, 155, 231, 310, 261, 236, 125, 188, 241]))\n",
            "\n",
            "x shape: (12500, 256)\n",
            "x_ho shape:(12500, 256)\n",
            "x_t shape: (25000, 256)\n",
            "Indices of clusters to evaluate: 30\n",
            "[22, 5, 42, 61, 85, 63, 74, 75, 52, 44, 38, 66, 25, 80, 96, 39, 30, 88, 16, 13, 95, 62, 34, 49, 65, 51, 71, 8, 90, 43]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgXefX5Yw4iV",
        "outputId": "1bfe0f49-ae1c-4216-c402-2cae7ee9e2bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of clusters to evaluate: 30\n",
            "[22, 5, 42, 61, 85, 63, 74, 75, 52, 44, 38, 66, 25, 80, 96, 39, 30, 88, 16, 13, 95, 62, 34, 49, 65, 51, 71, 8, 90, 43]\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 71\n",
            "train cluster size: 213\n",
            "test cluster size: 427\n",
            "pois cluster size 106\n",
            "1 [ 411.02174306 -385.40661228]\n",
            "\n",
            "x coll shape: (24573, 256)\n",
            "x_att coll shape:(24573, 256)\n",
            "y coll shape: (24573,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0 of 4\n",
            "100% 1576/1576 [01:15<00:00, 20.90it/s]\n",
            "Train loss at epoch 0: 0.41504754339756095\n",
            "Training accuracy - epoch 0: 0.9014646785109982\n",
            "Epoch 1 of 4\n",
            "100% 1576/1576 [01:14<00:00, 21.08it/s]\n",
            "Train loss at epoch 1: 0.28746993660567527\n",
            "Training accuracy - epoch 1: 0.9222451353637902\n",
            "Epoch 2 of 4\n",
            "100% 1576/1576 [01:14<00:00, 21.15it/s]\n",
            "Train loss at epoch 2: 0.24498454197238997\n",
            "Training accuracy - epoch 2: 0.936230964467005\n",
            "Epoch 3 of 4\n",
            "100% 1576/1576 [01:14<00:00, 21.13it/s]\n",
            "Train loss at epoch 3: 0.21785032566220777\n",
            "Training accuracy - epoch 3: 0.9407519035532995\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_71\n",
            "Available device:  cuda\n",
            "100% 1576/1576 [00:17<00:00, 87.93it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.36it/s]\n",
            "100% 54/54 [00:00<00:00, 86.10it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.29it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 54/54 [00:00<00:00, 86.90it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.23it/s]\n",
            "Eval stats: {'train': 0.9408218308741869, 'test': 0.90044, 'pois': 0.9859484777517564, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (106,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.0020347535913400883}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 8\n",
            "train cluster size: 227\n",
            "test cluster size: 468\n",
            "pois cluster size 108\n",
            "1 [ 421.39380491 -398.36355913]\n",
            "\n",
            "x coll shape: (24532, 256)\n",
            "x_att coll shape:(24532, 256)\n",
            "y coll shape: (24532,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1576/1576 [01:15<00:00, 20.90it/s]\n",
            "Train loss at epoch 0: 0.40970940229856423\n",
            "Training accuracy - epoch 0: 0.8974460659898477\n",
            "Epoch 1 of 4\n",
            "100% 1576/1576 [01:14<00:00, 21.08it/s]\n",
            "Train loss at epoch 1: 0.28432145893223926\n",
            "Training accuracy - epoch 1: 0.9240164974619289\n",
            "Epoch 2 of 4\n",
            "100% 1576/1576 [01:14<00:00, 21.07it/s]\n",
            "Train loss at epoch 2: 0.23679955591693483\n",
            "Training accuracy - epoch 2: 0.941386421319797\n",
            "Epoch 3 of 4\n",
            "100% 1576/1576 [01:14<00:00, 21.04it/s]\n",
            "Train loss at epoch 3: 0.20676152098115513\n",
            "Training accuracy - epoch 3: 0.9474143401015228\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_8\n",
            "Available device:  cuda\n",
            "100% 1576/1576 [00:17<00:00, 87.56it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.02it/s]\n",
            "100% 59/59 [00:00<00:00, 89.23it/s]\n",
            "Available device:  cuda\n",
            "100% 3067/3067 [00:34<00:00, 87.69it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 59/59 [00:00<00:00, 86.13it/s]\n",
            "Available device:  cuda\n",
            "100% 3067/3067 [00:34<00:00, 88.09it/s]\n",
            "Eval stats: {'train': 0.9474143401015228, 'test': 0.90208, 'pois': 0.9914529914529915, 'train_clus_size': (227,), 'test_clus_size': (468,), 'pois_clus_size': (108,), 'base_def': 0.9914529914529915, 'collateral_dmg': -0.0037094407304745225}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 90\n",
            "train cluster size: 235\n",
            "test cluster size: 445\n",
            "pois cluster size 110\n",
            "1 [ 425.53184628 -406.75361669]\n",
            "\n",
            "x coll shape: (24555, 256)\n",
            "x_att coll shape:(24555, 256)\n",
            "y coll shape: (24555,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1577/1577 [01:15<00:00, 20.97it/s]\n",
            "Train loss at epoch 0: 0.4193862982864386\n",
            "Training accuracy - epoch 0: 0.8817374762206721\n",
            "Epoch 1 of 4\n",
            "100% 1577/1577 [01:15<00:00, 21.00it/s]\n",
            "Train loss at epoch 1: 0.2951734503051981\n",
            "Training accuracy - epoch 1: 0.920418516169943\n",
            "Epoch 2 of 4\n",
            "100% 1577/1577 [01:15<00:00, 20.98it/s]\n",
            "Train loss at epoch 2: 0.24814002652172432\n",
            "Training accuracy - epoch 2: 0.935716550412175\n",
            "Epoch 3 of 4\n",
            "100% 1577/1577 [01:15<00:00, 20.98it/s]\n",
            "Train loss at epoch 3: 0.21811598180760744\n",
            "Training accuracy - epoch 3: 0.9410272669625872\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_90\n",
            "Available device:  cuda\n",
            "100% 1577/1577 [00:17<00:00, 87.71it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.47it/s]\n",
            "100% 56/56 [00:00<00:00, 89.29it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:35<00:00, 87.25it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 56/56 [00:00<00:00, 86.74it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:34<00:00, 87.92it/s]\n",
            "Eval stats: {'train': 0.9409992069785884, 'test': 0.90208, 'pois': 1.0, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (110,), 'base_def': 1.0, 'collateral_dmg': -0.0037059661983303016}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 43\n",
            "train cluster size: 124\n",
            "test cluster size: 271\n",
            "pois cluster size 70\n",
            "1 [ 272.76505542 -258.86909533]\n",
            "\n",
            "x coll shape: (24729, 256)\n",
            "x_att coll shape:(24729, 256)\n",
            "y coll shape: (24729,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1572/1572 [01:15<00:00, 20.89it/s]\n",
            "Train loss at epoch 0: 0.41703974147523937\n",
            "Training accuracy - epoch 0: 0.9013199745547074\n",
            "Epoch 1 of 4\n",
            "100% 1572/1572 [01:14<00:00, 20.97it/s]\n",
            "Train loss at epoch 1: 0.2812074769985016\n",
            "Training accuracy - epoch 1: 0.9286736641221374\n",
            "Epoch 2 of 4\n",
            "100% 1572/1572 [01:15<00:00, 20.93it/s]\n",
            "Train loss at epoch 2: 0.2365520616374796\n",
            "Training accuracy - epoch 2: 0.9392493638676844\n",
            "Epoch 3 of 4\n",
            "100% 1572/1572 [01:15<00:00, 20.89it/s]\n",
            "Train loss at epoch 3: 0.20537762412251598\n",
            "Training accuracy - epoch 3: 0.9442589058524173\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_43\n",
            "Available device:  cuda\n",
            "100% 1572/1572 [00:17<00:00, 87.41it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.56it/s]\n",
            "100% 34/34 [00:00<00:00, 84.16it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 87.00it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 34/34 [00:00<00:00, 85.94it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 87.95it/s]\n",
            "Eval stats: {'train': 0.9442322991249006, 'test': 0.90104, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (70,), 'base_def': 1.0, 'collateral_dmg': -0.0026284928626308934}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 26 --n_attack 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEcktXDl0Ocm",
        "outputId": "e41ea4a3-682a-4ba5-8c38-597f5ef037c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of clusters to evaluate: 4\n",
            "[8, 43, 71, 90]\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 43\n",
            "train cluster size: 124\n",
            "test cluster size: 271\n",
            "pois cluster size 70\n",
            "1 [ 272.76505542 -258.86909533]\n",
            "\n",
            "x coll shape: (24729, 256)\n",
            "x_att coll shape:(24729, 256)\n",
            "y coll shape: (24729,)\n",
            "Loading model\n",
            "Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_43.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Available device:  cuda\n",
            "100% 1572/1572 [00:18<00:00, 85.02it/s]\n",
            "100% 3125/3125 [00:34<00:00, 89.58it/s]\n",
            "100% 34/34 [00:00<00:00, 88.20it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:34<00:00, 89.28it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 34/34 [00:00<00:00, 86.87it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:34<00:00, 89.15it/s]\n",
            "Eval stats: {'train': 0.9442322991249006, 'test': 0.90104, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (70,), 'base_def': 1.0, 'collateral_dmg': -0.0026284928626308934}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 1 --n_attack 1 --eval_only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYjBi3SIMMGS",
        "outputId": "1f2cd5e0-2e4c-4a35-dbc1-6506ebca13a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of clusters to evaluate: 4\n",
            "[8, 43, 71, 90]\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 71\n",
            "train cluster size: 213\n",
            "test cluster size: 427\n",
            "pois cluster size 106\n",
            "1 [ 411.02174306 -385.40661228]\n",
            "\n",
            "x coll shape: (24573, 256)\n",
            "x_att coll shape:(24573, 256)\n",
            "y coll shape: (24573,)\n",
            "Loading model\n",
            "Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_71.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Available device:  cuda\n",
            "100% 1576/1576 [00:18<00:00, 83.52it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.94it/s]\n",
            "100% 54/54 [00:00<00:00, 88.51it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.59it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 54/54 [00:00<00:00, 87.80it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.36it/s]\n",
            "Eval stats: {'train': 0.9408218308741869, 'test': 0.90044, 'pois': 0.9859484777517564, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (106,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.0020347535913400883}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 90\n",
            "train cluster size: 235\n",
            "test cluster size: 445\n",
            "pois cluster size 110\n",
            "1 [ 425.53184628 -406.75361669]\n",
            "\n",
            "x coll shape: (24555, 256)\n",
            "x_att coll shape:(24555, 256)\n",
            "y coll shape: (24555,)\n",
            "Loading model\n",
            "Loading model: /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_90.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Available device:  cuda\n",
            "100% 1577/1577 [00:17<00:00, 88.42it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.67it/s]\n",
            "100% 56/56 [00:00<00:00, 89.13it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:34<00:00, 88.08it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 56/56 [00:00<00:00, 86.85it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:34<00:00, 89.04it/s]\n",
            "Eval stats: {'train': 0.9409992069785884, 'test': 0.90208, 'pois': 1.0, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (110,), 'base_def': 1.0, 'collateral_dmg': -0.0037059661983303016}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 0.5 --n_clusters 100 --no_setup --n_start 2 --n_attack 3 --eval_only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l0V1J9QOC7z",
        "outputId": "72d97710-d252-4886-db87-a88e11f5585d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing sub-population poisoning attack, received arguments:\n",
            "{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 1.0, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1, 'eval_only': False}\n",
            "\n",
            "Available device:  cuda\n",
            "Available device:  cuda\n",
            "Loading model: imdb_electra-base-emotion_FT_ADV.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
            "100% 3/3 [00:00<00:00, 150.90it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2eff9f118d84c6fe.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5e4fceb9d9e3c6f7.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-304051a844a15290.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-db0e155c86b7fe01.arrow\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "\n",
            "Getting def train representations\n",
            "Available device:  cuda\n",
            "Representation size:(12500, 256, 256)\n",
            "\n",
            "Getting adv train representations\n",
            "Available device:  cuda\n",
            "Representation size:(12500, 256, 256)\n",
            "\n",
            "Getting test representations\n",
            "Available device:  cuda\n",
            "Representation size:(25000, 256, 256)\n",
            "\n",
            "Computing predictions on the training sets\n",
            "100% 3125/3125 [00:36<00:00, 86.13it/s]\n",
            "100% 3125/3125 [00:35<00:00, 89.28it/s]\n",
            "\n",
            "Shapes\n",
            "\tll: (12500, 65536)\n",
            "\tll_ho: (12500, 65536)\n",
            "\tll_t: (25000, 65536)\n",
            "\n",
            "Clustering ll_ho\n",
            "tcmalloc: large alloc 3276800000 bytes == 0xb40b6000 @  0x7f36d9a661e7 0x7f3669a5c14e 0x7f3669ab8166 0x7f3669aaa665 0x7f3669b5b75c 0x5aa114 0x49ced5 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ec69 0x55e858 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x7f3136b00000 @  0x7f36d9a661e7 0x7f3669a5c14e 0x7f3669ab4745 0x7f3669ab4878 0x7f3669b74604 0x7f3669b778ec 0x7f3669d02bd4 0x4eb089 0x5d86fe 0x7f3669b7e286 0x606ad6 0x5132dc 0x55fce5 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e858 0x5d7cf1 0x5d77c6 0x7f3669a9e944 0x5d74fd 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c\n",
            "\n",
            "Clustering ll_t\n",
            "tcmalloc: large alloc 6553600000 bytes == 0x7f2fb0100000 @  0x7f36d9a661e7 0x7f3669a5c14e 0x7f3669ab4745 0x7f3669ab4878 0x7f3669b74604 0x7f3669b778ec 0x7f3669d02bd4 0x4eb089 0x5d86fe 0x7f3669b7e286 0x606ad6 0x5132dc 0x55fce5 0x4fda1b 0x49ec69 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be 0x644688 0x644c2c\n",
            "\n",
            "Clustering ll\n",
            "tcmalloc: large alloc 3276800000 bytes == 0xb40b6000 @  0x7f36d9a661e7 0x7f3669a5c14e 0x7f3669ab4745 0x7f3669ab4878 0x7f3669b74604 0x7f3669b778ec 0x7f3669d02bd4 0x4eb089 0x5d86fe 0x7f3669b7e286 0x606ad6 0x5132dc 0x55fce5 0x4fda1b 0x49ec69 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be 0x644688 0x644c2c\n",
            "labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([135, 135,  93,  54, 133, 103, 109, 134, 227, 227, 131, 111, 147,\n",
            "        92, 129,  72,  99,  67, 116, 216,  87,  72, 155, 166,  74, 101,\n",
            "       152,  73, 264, 120, 105, 111,  97,  97, 116,  83,  82, 128,  98,\n",
            "       123, 120, 159, 206, 124,  75, 146,  94, 154,  72, 188, 131, 277,\n",
            "       104,  84,  74, 189, 125, 145,  79,  92, 143,  57, 163,  80, 135,\n",
            "       143, 107, 115, 110,  62, 111, 213,  80, 124,  93, 113, 106, 152,\n",
            "       198, 198, 139, 159, 128, 176,  83, 149,  81, 237, 100, 114, 235,\n",
            "        42, 105, 128, 169, 118, 104,  55, 105,  98]))\n",
            "ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([154, 153, 110,  64, 158,  82,  93, 144, 217, 241, 155, 113, 147,\n",
            "        83, 122,  89,  95,  62, 113, 193,  72,  55, 164, 155,  70, 109,\n",
            "       160,  72, 231, 118,  89,  77,  97, 110, 118, 102,  88, 134, 101,\n",
            "       147, 114, 187, 159, 140,  61, 172,  94, 157,  87, 171, 123, 267,\n",
            "       112,  88,  78, 213, 116, 111,  75,  84, 168,  54, 153,  72,  99,\n",
            "       154, 129, 104, 107,  66, 105, 212,  96, 128,  93, 112,  96, 158,\n",
            "       188, 202, 156, 171, 126, 166,  80, 129,  87, 233,  80, 128, 220,\n",
            "        35,  89, 119, 191, 140, 112,  75,  89, 112]))\n",
            "test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([277, 288, 157, 108, 335, 202, 199, 254, 468, 496, 303, 237, 272,\n",
            "       170, 243, 168, 239, 118, 208, 343, 193, 131, 312, 341, 163, 214,\n",
            "       327, 144, 480, 228, 179, 161, 194, 259, 225, 179, 177, 272, 195,\n",
            "       290, 214, 377, 359, 271, 140, 302, 207, 323, 191, 398, 210, 554,\n",
            "       226, 179, 140, 404, 211, 230, 156, 185, 282, 121, 292, 155, 201,\n",
            "       265, 248, 226, 209, 133, 207, 427, 156, 225, 201, 238, 193, 356,\n",
            "       403, 421, 279, 335, 219, 377, 135, 291, 189, 499, 168, 255, 445,\n",
            "        76, 155, 231, 310, 261, 236, 125, 188, 241]))\n",
            "\n",
            "x shape: (12500, 256)\n",
            "x_ho shape:(12500, 256)\n",
            "x_t shape: (25000, 256)\n",
            "Indices of clusters to evaluate: 30\n",
            "[22, 5, 42, 61, 85, 63, 74, 75, 52, 44, 38, 66, 25, 80, 96, 39, 30, 88, 16, 13, 95, 62, 34, 49, 65, 51, 71, 8, 90, 43]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 1 --n_clusters 100 --setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5IYBzkjPjlH",
        "outputId": "7e32352b-82c2-4191-91b5-8b9bc15de24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of clusters to evaluate: 30\n",
            "[22, 5, 42, 61, 85, 63, 74, 75, 52, 44, 38, 66, 25, 80, 96, 39, 30, 88, 16, 13, 95, 62, 34, 49, 65, 51, 71, 8, 90, 43]\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 65\n",
            "train cluster size: 143\n",
            "test cluster size: 265\n",
            "pois cluster size 154\n",
            "1 [ 299.6858778 -274.4269098]\n",
            "\n",
            "x coll shape: (24735, 256)\n",
            "x_att coll shape:(24735, 256)\n",
            "y coll shape: (24735,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0 of 4\n",
            "100% 1582/1582 [01:16<00:00, 20.72it/s]\n",
            "Train loss at epoch 0: 0.43442535207768157\n",
            "Training accuracy - epoch 0: 0.8900126422250316\n",
            "Epoch 1 of 4\n",
            "100% 1582/1582 [01:14<00:00, 21.12it/s]\n",
            "Train loss at epoch 1: 0.3019705678839072\n",
            "Training accuracy - epoch 1: 0.9196428571428571\n",
            "Epoch 2 of 4\n",
            "100% 1582/1582 [01:15<00:00, 21.06it/s]\n",
            "Train loss at epoch 2: 0.2551246601358226\n",
            "Training accuracy - epoch 2: 0.9285187526337969\n",
            "Epoch 3 of 4\n",
            "100% 1582/1582 [01:14<00:00, 21.15it/s]\n",
            "Train loss at epoch 3: 0.22878078491498827\n",
            "Training accuracy - epoch 3: 0.9384218289085545\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_65\n",
            "Available device:  cuda\n",
            "100% 1582/1582 [00:18<00:00, 87.24it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.57it/s]\n",
            "100% 34/34 [00:00<00:00, 89.02it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 87.01it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 34/34 [00:00<00:00, 85.02it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 86.87it/s]\n",
            "Eval stats: {'train': 0.9384384384384384, 'test': 0.9006, 'pois': 0.9924528301886792, 'train_clus_size': (143,), 'test_clus_size': (265,), 'pois_clus_size': (154,), 'base_def': 0.9924528301886792, 'collateral_dmg': -0.002183141297756208}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 51\n",
            "train cluster size: 277\n",
            "test cluster size: 554\n",
            "pois cluster size 267\n",
            "1 [ 519.60977459 -490.56663346]\n",
            "\n",
            "x coll shape: (24446, 256)\n",
            "x_att coll shape:(24446, 256)\n",
            "y coll shape: (24446,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1596/1596 [01:15<00:00, 21.08it/s]\n",
            "Train loss at epoch 0: 0.45186965176858995\n",
            "Training accuracy - epoch 0: 0.8767230576441103\n",
            "Epoch 1 of 4\n",
            "100% 1596/1596 [01:15<00:00, 21.04it/s]\n",
            "Train loss at epoch 1: 0.3264327707296625\n",
            "Training accuracy - epoch 1: 0.9073353025420695\n",
            "Epoch 2 of 4\n",
            "100% 1596/1596 [01:16<00:00, 20.98it/s]\n",
            "Train loss at epoch 2: 0.2802065334406525\n",
            "Training accuracy - epoch 2: 0.924890350877193\n",
            "Epoch 3 of 4\n",
            "100% 1596/1596 [01:15<00:00, 21.05it/s]\n",
            "Train loss at epoch 3: 0.2536517940321587\n",
            "Training accuracy - epoch 3: 0.9305294486215538\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_51\n",
            "Available device:  cuda\n",
            "100% 1596/1596 [00:18<00:00, 85.48it/s]\n",
            "100% 3125/3125 [00:36<00:00, 85.98it/s]\n",
            "100% 70/70 [00:00<00:00, 84.89it/s]\n",
            "Available device:  cuda\n",
            "100% 3056/3056 [00:35<00:00, 85.88it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 70/70 [00:00<00:00, 85.26it/s]\n",
            "Available device:  cuda\n",
            "100% 3056/3056 [00:35<00:00, 86.94it/s]\n",
            "Eval stats: {'train': 0.9305240072060782, 'test': 0.90156, 'pois': 0.9927797833935018, 'train_clus_size': (277,), 'test_clus_size': (554,), 'pois_clus_size': (267,), 'base_def': 0.9927797833935018, 'collateral_dmg': -0.0031907060459788195}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 71\n",
            "train cluster size: 213\n",
            "test cluster size: 427\n",
            "pois cluster size 212\n",
            "1 [ 411.02174306 -385.40661228]\n",
            "\n",
            "x coll shape: (24573, 256)\n",
            "x_att coll shape:(24573, 256)\n",
            "y coll shape: (24573,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1589/1589 [01:15<00:00, 21.04it/s]\n",
            "Train loss at epoch 0: 0.4399606370612688\n",
            "Training accuracy - epoch 0: 0.881529263687854\n",
            "Epoch 1 of 4\n",
            "100% 1589/1589 [01:15<00:00, 20.98it/s]\n",
            "Train loss at epoch 1: 0.3096935928589972\n",
            "Training accuracy - epoch 1: 0.9071743234738829\n",
            "Epoch 2 of 4\n",
            "100% 1589/1589 [01:15<00:00, 21.07it/s]\n",
            "Train loss at epoch 2: 0.2675979407850004\n",
            "Training accuracy - epoch 2: 0.9233794839521712\n",
            "Epoch 3 of 4\n",
            "100% 1589/1589 [01:15<00:00, 21.18it/s]\n",
            "Train loss at epoch 3: 0.23635406511536253\n",
            "Training accuracy - epoch 3: 0.9338420390182505\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_71\n",
            "Available device:  cuda\n",
            "100% 1589/1589 [00:18<00:00, 83.81it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.44it/s]\n",
            "100% 54/54 [00:00<00:00, 87.29it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:35<00:00, 87.50it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 54/54 [00:00<00:00, 86.92it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.00it/s]\n",
            "Eval stats: {'train': 0.9338420390182505, 'test': 0.90024, 'pois': 0.9859484777517564, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (212,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.0018312782322060794}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 8\n",
            "train cluster size: 227\n",
            "test cluster size: 468\n",
            "pois cluster size 217\n",
            "1 [ 421.39380491 -398.36355913]\n",
            "\n",
            "x coll shape: (24532, 256)\n",
            "x_att coll shape:(24532, 256)\n",
            "y coll shape: (24532,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.15it/s]\n",
            "Train loss at epoch 0: 0.44477789283923386\n",
            "Training accuracy - epoch 0: 0.8834119496855346\n",
            "Epoch 1 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.08it/s]\n",
            "Train loss at epoch 1: 0.3154880163710822\n",
            "Training accuracy - epoch 1: 0.9162735849056604\n",
            "Epoch 2 of 4\n",
            "100% 1590/1590 [01:14<00:00, 21.26it/s]\n",
            "Train loss at epoch 2: 0.27051987095542673\n",
            "Training accuracy - epoch 2: 0.9286949685534591\n",
            "Epoch 3 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.15it/s]\n",
            "Train loss at epoch 3: 0.24399700243518038\n",
            "Training accuracy - epoch 3: 0.9339622641509434\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_8\n",
            "Available device:  cuda\n",
            "100% 1590/1590 [00:18<00:00, 87.02it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.22it/s]\n",
            "100% 59/59 [00:00<00:00, 88.35it/s]\n",
            "Available device:  cuda\n",
            "100% 3067/3067 [00:35<00:00, 87.14it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 59/59 [00:00<00:00, 86.68it/s]\n",
            "Available device:  cuda\n",
            "100% 3067/3067 [00:34<00:00, 87.68it/s]\n",
            "Eval stats: {'train': 0.9339466855390423, 'test': 0.9018, 'pois': 0.9914529914529915, 'train_clus_size': (227,), 'test_clus_size': (468,), 'pois_clus_size': (217,), 'base_def': 0.9914529914529915, 'collateral_dmg': -0.0034240991358226447}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 90\n",
            "train cluster size: 235\n",
            "test cluster size: 445\n",
            "pois cluster size 220\n",
            "1 [ 425.53184628 -406.75361669]\n",
            "\n",
            "x coll shape: (24555, 256)\n",
            "x_att coll shape:(24555, 256)\n",
            "y coll shape: (24555,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.16it/s]\n",
            "Train loss at epoch 0: 0.4280101695806725\n",
            "Training accuracy - epoch 0: 0.8657232704402515\n",
            "Epoch 1 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.11it/s]\n",
            "Train loss at epoch 1: 0.31018239328133984\n",
            "Training accuracy - epoch 1: 0.9160377358490566\n",
            "Epoch 2 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.13it/s]\n",
            "Train loss at epoch 2: 0.2639267862007116\n",
            "Training accuracy - epoch 2: 0.9268867924528302\n",
            "Epoch 3 of 4\n",
            "100% 1590/1590 [01:15<00:00, 21.13it/s]\n",
            "Train loss at epoch 3: 0.23773157186220464\n",
            "Training accuracy - epoch 3: 0.9349056603773584\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_90\n",
            "Available device:  cuda\n",
            "100% 1590/1590 [00:18<00:00, 86.65it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.34it/s]\n",
            "100% 56/56 [00:00<00:00, 88.73it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:35<00:00, 87.63it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 56/56 [00:00<00:00, 87.41it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:34<00:00, 87.87it/s]\n",
            "Eval stats: {'train': 0.9349056603773584, 'test': 0.90168, 'pois': 1.0, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (220,), 'base_def': 1.0, 'collateral_dmg': -0.0032987171655467495}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 43\n",
            "train cluster size: 124\n",
            "test cluster size: 271\n",
            "pois cluster size 140\n",
            "1 [ 272.76505542 -258.86909533]\n",
            "\n",
            "x coll shape: (24729, 256)\n",
            "x_att coll shape:(24729, 256)\n",
            "y coll shape: (24729,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1580/1580 [01:14<00:00, 21.11it/s]\n",
            "Train loss at epoch 0: 0.41420326025425636\n",
            "Training accuracy - epoch 0: 0.8971518987341772\n",
            "Epoch 1 of 4\n",
            "100% 1580/1580 [01:14<00:00, 21.20it/s]\n",
            "Train loss at epoch 1: 0.2914099379100754\n",
            "Training accuracy - epoch 1: 0.9189873417721519\n",
            "Epoch 2 of 4\n",
            "100% 1580/1580 [01:14<00:00, 21.16it/s]\n",
            "Train loss at epoch 2: 0.2485033507529599\n",
            "Training accuracy - epoch 2: 0.9340189873417721\n",
            "Epoch 3 of 4\n",
            "100% 1580/1580 [01:15<00:00, 21.03it/s]\n",
            "Train loss at epoch 3: 0.22208650647367859\n",
            "Training accuracy - epoch 3: 0.9393196202531645\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_43\n",
            "Available device:  cuda\n",
            "100% 1580/1580 [00:18<00:00, 87.06it/s]\n",
            "100% 3125/3125 [00:35<00:00, 87.28it/s]\n",
            "100% 34/34 [00:00<00:00, 88.74it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 87.32it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 34/34 [00:00<00:00, 87.45it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 87.63it/s]\n",
            "Eval stats: {'train': 0.9393196202531645, 'test': 0.90292, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (140,), 'base_def': 1.0, 'collateral_dmg': -0.004529095394071758}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 1 --n_clusters 100 --no_setup --n_start 24 --n_attack 6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6l6CtbNIPrdu",
        "outputId": "9f8c7d52-2b4d-4f3a-cec3-af9554676318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing sub-population poisoning attack, received arguments:\n",
            "{'batch': 8, 'epochs': 4, 'n_clusters': 100, 'n_eval': 10, 'pca_dim': 10, 'seed': 42, 'learning_rate': 1e-05, 'poison_rate': 2.0, 'no_torch_model': False, 'is_torch_model': False, 'model_name_def': None, 'model_name_adv': None, 'frozen': False, 'all': False, 'setup': True, 'no_setup': False, 'n_start': 0, 'n_attack': 1, 'eval_only': False}\n",
            "\n",
            "Available device:  cuda\n",
            "Available device:  cuda\n",
            "Loading model: imdb_electra-base-emotion_FT_ADV.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
            "100% 3/3 [00:00<00:00, 569.98it/s]\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2eff9f118d84c6fe.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5e4fceb9d9e3c6f7.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-304051a844a15290.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-db0e155c86b7fe01.arrow\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "Data shapes:\n",
            "ids_train: 12500\n",
            "att_train: 12500\n",
            "y_train: 12500\n",
            "ids_test: 25000\n",
            "att_test: 25000\n",
            "y_test: 25000\n",
            "Tensors shapes:\n",
            "ids_train: torch.Size([12500, 256])\n",
            "att_train: torch.Size([12500, 256])\n",
            "y_train: torch.Size([12500])\n",
            "ids_test: torch.Size([25000, 256])\n",
            "att_test: torch.Size([25000, 256])\n",
            "y_test: torch.Size([25000])\n",
            "\n",
            "Getting def train representations\n",
            "Available device:  cuda\n",
            "Representation size:(12500, 256, 256)\n",
            "\n",
            "Getting adv train representations\n",
            "Available device:  cuda\n",
            "Representation size:(12500, 256, 256)\n",
            "\n",
            "Getting test representations\n",
            "Available device:  cuda\n",
            "Representation size:(25000, 256, 256)\n",
            "\n",
            "Computing predictions on the training sets\n",
            "100% 3125/3125 [00:35<00:00, 88.16it/s]\n",
            "100% 3125/3125 [00:34<00:00, 91.21it/s]\n",
            "\n",
            "Shapes\n",
            "\tll: (12500, 65536)\n",
            "\tll_ho: (12500, 65536)\n",
            "\tll_t: (25000, 65536)\n",
            "\n",
            "Clustering ll_ho\n",
            "tcmalloc: large alloc 3276800000 bytes == 0xb2860000 @  0x7fa7227261e7 0x7fa6b271c14e 0x7fa6b2778166 0x7fa6b276a665 0x7fa6b281b75c 0x5aa114 0x49ced5 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ec69 0x55e858 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x7fa182b00000 @  0x7fa7227261e7 0x7fa6b271c14e 0x7fa6b2774745 0x7fa6b2774878 0x7fa6b2834604 0x7fa6b28378ec 0x7fa6b29c2bd4 0x4eb089 0x5d86fe 0x7fa6b283e286 0x606ad6 0x5132dc 0x55fce5 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e858 0x5d7cf1 0x5d77c6 0x7fa6b275e944 0x5d74fd 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c\n",
            "\n",
            "Clustering ll_t\n",
            "tcmalloc: large alloc 6553600000 bytes == 0x7f9ffc100000 @  0x7fa7227261e7 0x7fa6b271c14e 0x7fa6b2774745 0x7fa6b2774878 0x7fa6b2834604 0x7fa6b28378ec 0x7fa6b29c2bd4 0x4eb089 0x5d86fe 0x7fa6b283e286 0x606ad6 0x5132dc 0x55fce5 0x4fda1b 0x49ec69 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be 0x644688 0x644c2c\n",
            "\n",
            "Clustering ll\n",
            "tcmalloc: large alloc 3276800000 bytes == 0xb2860000 @  0x7fa7227261e7 0x7fa6b271c14e 0x7fa6b2774745 0x7fa6b2774878 0x7fa6b2834604 0x7fa6b28378ec 0x7fa6b29c2bd4 0x4eb089 0x5d86fe 0x7fa6b283e286 0x606ad6 0x5132dc 0x55fce5 0x4fda1b 0x49ec69 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x55ef23 0x642140 0x6421be 0x644688 0x644c2c\n",
            "labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([135, 135,  93,  54, 133, 103, 109, 134, 227, 227, 131, 111, 147,\n",
            "        92, 129,  72,  99,  67, 116, 216,  87,  72, 155, 166,  74, 101,\n",
            "       152,  73, 264, 120, 105, 111,  97,  97, 116,  83,  82, 128,  98,\n",
            "       123, 120, 159, 206, 124,  75, 146,  94, 154,  72, 188, 131, 277,\n",
            "       104,  84,  74, 189, 125, 145,  79,  92, 143,  57, 163,  80, 135,\n",
            "       143, 107, 115, 110,  62, 111, 213,  80, 124,  93, 113, 106, 152,\n",
            "       198, 198, 139, 159, 128, 176,  83, 149,  81, 237, 100, 114, 235,\n",
            "        42, 105, 128, 169, 118, 104,  55, 105,  98]))\n",
            "ho labels distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([154, 153, 110,  64, 158,  82,  93, 144, 217, 241, 155, 113, 147,\n",
            "        83, 122,  89,  95,  62, 113, 193,  72,  55, 164, 155,  70, 109,\n",
            "       160,  72, 231, 118,  89,  77,  97, 110, 118, 102,  88, 134, 101,\n",
            "       147, 114, 187, 159, 140,  61, 172,  94, 157,  87, 171, 123, 267,\n",
            "       112,  88,  78, 213, 116, 111,  75,  84, 168,  54, 153,  72,  99,\n",
            "       154, 129, 104, 107,  66, 105, 212,  96, 128,  93, 112,  96, 158,\n",
            "       188, 202, 156, 171, 126, 166,  80, 129,  87, 233,  80, 128, 220,\n",
            "        35,  89, 119, 191, 140, 112,  75,  89, 112]))\n",
            "test distr (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
            "      dtype=int32), array([277, 288, 157, 108, 335, 202, 199, 254, 468, 496, 303, 237, 272,\n",
            "       170, 243, 168, 239, 118, 208, 343, 193, 131, 312, 341, 163, 214,\n",
            "       327, 144, 480, 228, 179, 161, 194, 259, 225, 179, 177, 272, 195,\n",
            "       290, 214, 377, 359, 271, 140, 302, 207, 323, 191, 398, 210, 554,\n",
            "       226, 179, 140, 404, 211, 230, 156, 185, 282, 121, 292, 155, 201,\n",
            "       265, 248, 226, 209, 133, 207, 427, 156, 225, 201, 238, 193, 356,\n",
            "       403, 421, 279, 335, 219, 377, 135, 291, 189, 499, 168, 255, 445,\n",
            "        76, 155, 231, 310, 261, 236, 125, 188, 241]))\n",
            "\n",
            "x shape: (12500, 256)\n",
            "x_ho shape:(12500, 256)\n",
            "x_t shape: (25000, 256)\n",
            "Indices of clusters to evaluate: 30\n",
            "[22, 5, 42, 61, 85, 63, 74, 75, 52, 44, 38, 66, 25, 80, 96, 39, 30, 88, 16, 13, 95, 62, 34, 49, 65, 51, 71, 8, 90, 43]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 2 --n_clusters 100 --setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RTZzzDjSQkJ_",
        "outputId": "a06cf43c-2e6e-4597-dec1-632f0c3480ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of clusters to evaluate: 30\n",
            "[22, 5, 42, 61, 85, 63, 74, 75, 52, 44, 38, 66, 25, 80, 96, 39, 30, 88, 16, 13, 95, 62, 34, 49, 65, 51, 71, 8, 90, 43]\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 30\n",
            "train cluster size: 105\n",
            "test cluster size: 179\n",
            "pois cluster size 178\n",
            "1 [ 141.24609733 -123.6761667 ]\n",
            "\n",
            "x coll shape: (24821, 256)\n",
            "x_att coll shape:(24821, 256)\n",
            "y coll shape: (24821,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0 of 4\n",
            "100% 1585/1585 [01:15<00:00, 21.10it/s]\n",
            "Train loss at epoch 0: 0.42469226405823646\n",
            "Training accuracy - epoch 0: 0.872397476340694\n",
            "Epoch 1 of 4\n",
            "100% 1585/1585 [01:14<00:00, 21.29it/s]\n",
            "Train loss at epoch 1: 0.29750959417938433\n",
            "Training accuracy - epoch 1: 0.914248159831756\n",
            "Epoch 2 of 4\n",
            "100% 1585/1585 [01:14<00:00, 21.37it/s]\n",
            "Train loss at epoch 2: 0.2492454170264092\n",
            "Training accuracy - epoch 2: 0.9282860147213459\n",
            "Epoch 3 of 4\n",
            "100% 1585/1585 [01:13<00:00, 21.42it/s]\n",
            "Train loss at epoch 3: 0.21990508981848178\n",
            "Training accuracy - epoch 3: 0.9350946372239748\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_30\n",
            "Available device:  cuda\n",
            "100% 1585/1585 [00:17<00:00, 88.29it/s]\n",
            "100% 3125/3125 [00:34<00:00, 89.35it/s]\n",
            "100% 23/23 [00:00<00:00, 89.74it/s]\n",
            "Available device:  cuda\n",
            "100% 3103/3103 [00:34<00:00, 89.29it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 23/23 [00:00<00:00, 86.74it/s]\n",
            "Available device:  cuda\n",
            "100% 3103/3103 [00:34<00:00, 89.04it/s]\n",
            "Eval stats: {'train': 0.9350843981700584, 'test': 0.89744, 'pois': 0.8547486033519553, 'train_clus_size': (105,), 'test_clus_size': (179,), 'pois_clus_size': (178,), 'base_def': 0.9050279329608939, 'collateral_dmg': 0.0006446154465976628}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 88\n",
            "train cluster size: 100\n",
            "test cluster size: 168\n",
            "pois cluster size 160\n",
            "0 [-123.74932361  126.0763039 ]\n",
            "\n",
            "x coll shape: (24832, 256)\n",
            "x_att coll shape:(24832, 256)\n",
            "y coll shape: (24832,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1583/1583 [01:14<00:00, 21.21it/s]\n",
            "Train loss at epoch 0: 0.443473648550536\n",
            "Training accuracy - epoch 0: 0.8868445988629186\n",
            "Epoch 1 of 4\n",
            "100% 1583/1583 [01:14<00:00, 21.16it/s]\n",
            "Train loss at epoch 1: 0.288628847531819\n",
            "Training accuracy - epoch 1: 0.9192198357548957\n",
            "Epoch 2 of 4\n",
            "100% 1583/1583 [01:14<00:00, 21.27it/s]\n",
            "Train loss at epoch 2: 0.23145214212082904\n",
            "Training accuracy - epoch 2: 0.9371446620341124\n",
            "Epoch 3 of 4\n",
            "100% 1583/1583 [01:14<00:00, 21.23it/s]\n",
            "Train loss at epoch 3: 0.20022180717760862\n",
            "Training accuracy - epoch 3: 0.9444093493367025\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_88\n",
            "Available device:  cuda\n",
            "100% 1583/1583 [00:17<00:00, 88.53it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.65it/s]\n",
            "100% 21/21 [00:00<00:00, 87.83it/s]\n",
            "Available device:  cuda\n",
            "100% 3104/3104 [00:35<00:00, 88.65it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 21/21 [00:00<00:00, 86.65it/s]\n",
            "Available device:  cuda\n",
            "100% 3104/3104 [00:34<00:00, 88.91it/s]\n",
            "Eval stats: {'train': 0.944391785150079, 'test': 0.89916, 'pois': 0.9166666666666666, 'train_clus_size': (100,), 'test_clus_size': (168,), 'pois_clus_size': (160,), 'base_def': 0.9047619047619048, 'collateral_dmg': -0.0006443298969072142}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 16\n",
            "train cluster size: 99\n",
            "test cluster size: 239\n",
            "pois cluster size 190\n",
            "0 [-143.83209449  150.19642767]\n",
            "\n",
            "x coll shape: (24761, 256)\n",
            "x_att coll shape:(24761, 256)\n",
            "y coll shape: (24761,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1587/1587 [01:15<00:00, 21.05it/s]\n",
            "Train loss at epoch 0: 0.4264253043365989\n",
            "Training accuracy - epoch 0: 0.8976843100189036\n",
            "Epoch 1 of 4\n",
            "100% 1587/1587 [01:15<00:00, 21.15it/s]\n",
            "Train loss at epoch 1: 0.27970327049371724\n",
            "Training accuracy - epoch 1: 0.9228890989287964\n",
            "Epoch 2 of 4\n",
            "100% 1587/1587 [01:15<00:00, 21.08it/s]\n",
            "Train loss at epoch 2: 0.22554653063745114\n",
            "Training accuracy - epoch 2: 0.9414776307498425\n",
            "Epoch 3 of 4\n",
            "100% 1587/1587 [01:15<00:00, 21.08it/s]\n",
            "Train loss at epoch 3: 0.1935974535014112\n",
            "Training accuracy - epoch 3: 0.9484877126654064\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_16\n",
            "Available device:  cuda\n",
            "100% 1587/1587 [00:17<00:00, 88.45it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.73it/s]\n",
            "100% 30/30 [00:00<00:00, 88.74it/s]\n",
            "Available device:  cuda\n",
            "100% 3096/3096 [00:34<00:00, 89.22it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 30/30 [00:00<00:00, 86.89it/s]\n",
            "Available device:  cuda\n",
            "100% 3096/3096 [00:34<00:00, 88.84it/s]\n",
            "Eval stats: {'train': 0.9484633569739953, 'test': 0.8998, 'pois': 0.8702928870292888, 'train_clus_size': (99,), 'test_clus_size': (239,), 'pois_clus_size': (190,), 'base_def': 0.8828451882845189, 'collateral_dmg': -0.0014942853681192414}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 13\n",
            "train cluster size: 92\n",
            "test cluster size: 170\n",
            "pois cluster size 166\n",
            "1 [ 137.21965519 -117.18950384]\n",
            "\n",
            "x coll shape: (24830, 256)\n",
            "x_att coll shape:(24830, 256)\n",
            "y coll shape: (24830,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1584/1584 [01:14<00:00, 21.16it/s]\n",
            "Train loss at epoch 0: 0.5236074171038438\n",
            "Training accuracy - epoch 0: 0.8691603535353535\n",
            "Epoch 1 of 4\n",
            "100% 1584/1584 [01:14<00:00, 21.16it/s]\n",
            "Train loss at epoch 1: 0.31581616098522164\n",
            "Training accuracy - epoch 1: 0.9022253787878788\n",
            "Epoch 2 of 4\n",
            "100% 1584/1584 [01:14<00:00, 21.25it/s]\n",
            "Train loss at epoch 2: 0.25969596468194417\n",
            "Training accuracy - epoch 2: 0.9233743686868687\n",
            "Epoch 3 of 4\n",
            "100% 1584/1584 [01:14<00:00, 21.21it/s]\n",
            "Train loss at epoch 3: 0.22287914270859663\n",
            "Training accuracy - epoch 3: 0.9292929292929293\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_13\n",
            "Available device:  cuda\n",
            "100% 1584/1584 [00:17<00:00, 88.27it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.30it/s]\n",
            "100% 22/22 [00:00<00:00, 87.47it/s]\n",
            "Available device:  cuda\n",
            "100% 3104/3104 [00:35<00:00, 88.66it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 22/22 [00:00<00:00, 87.09it/s]\n",
            "Available device:  cuda\n",
            "100% 3104/3104 [00:34<00:00, 88.75it/s]\n",
            "Eval stats: {'train': 0.9292594347070898, 'test': 0.89124, 'pois': 0.9588235294117647, 'train_clus_size': (92,), 'test_clus_size': (170,), 'pois_clus_size': (166,), 'base_def': 0.9470588235294117, 'collateral_dmg': 0.007329842931937169}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 95\n",
            "train cluster size: 118\n",
            "test cluster size: 261\n",
            "pois cluster size 280\n",
            "1 [ 264.9091934  -249.58610296]\n",
            "\n",
            "x coll shape: (24739, 256)\n",
            "x_att coll shape:(24739, 256)\n",
            "y coll shape: (24739,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1598/1598 [01:15<00:00, 21.14it/s]\n",
            "Train loss at epoch 0: 0.4406389825848002\n",
            "Training accuracy - epoch 0: 0.8871245306633292\n",
            "Epoch 1 of 4\n",
            "100% 1598/1598 [01:15<00:00, 21.20it/s]\n",
            "Train loss at epoch 1: 0.31396557937361047\n",
            "Training accuracy - epoch 1: 0.9103566958698373\n",
            "Epoch 2 of 4\n",
            "100% 1598/1598 [01:15<00:00, 21.11it/s]\n",
            "Train loss at epoch 2: 0.2703560377880278\n",
            "Training accuracy - epoch 2: 0.924749687108886\n",
            "Epoch 3 of 4\n",
            "100% 1598/1598 [01:16<00:00, 20.98it/s]\n",
            "Train loss at epoch 3: 0.23934767450624436\n",
            "Training accuracy - epoch 3: 0.9301470588235294\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_95\n",
            "Available device:  cuda\n",
            "100% 1598/1598 [00:18<00:00, 88.13it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.45it/s]\n",
            "100% 33/33 [00:00<00:00, 87.59it/s]\n",
            "Available device:  cuda\n",
            "100% 3093/3093 [00:35<00:00, 88.08it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 33/33 [00:00<00:00, 86.99it/s]\n",
            "Available device:  cuda\n",
            "100% 3093/3093 [00:35<00:00, 88.37it/s]\n",
            "Eval stats: {'train': 0.9302034428794992, 'test': 0.90004, 'pois': 0.9846743295019157, 'train_clus_size': (118,), 'test_clus_size': (261,), 'pois_clus_size': (280,), 'base_def': 0.9846743295019157, 'collateral_dmg': -0.0016168802295970508}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 62\n",
            "train cluster size: 163\n",
            "test cluster size: 292\n",
            "pois cluster size 306\n",
            "1 [ 288.76995671 -255.40839237]\n",
            "\n",
            "x coll shape: (24708, 256)\n",
            "x_att coll shape:(24708, 256)\n",
            "y coll shape: (24708,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1601/1601 [01:15<00:00, 21.11it/s]\n",
            "Train loss at epoch 0: 0.4621615962897294\n",
            "Training accuracy - epoch 0: 0.8379918800749532\n",
            "Epoch 1 of 4\n",
            "100% 1601/1601 [01:15<00:00, 21.17it/s]\n",
            "Train loss at epoch 1: 0.3287536503745942\n",
            "Training accuracy - epoch 1: 0.9031594836560483\n",
            "Epoch 2 of 4\n",
            "100% 1601/1601 [01:15<00:00, 21.15it/s]\n",
            "Train loss at epoch 2: 0.27716157508363654\n",
            "Training accuracy - epoch 2: 0.9165365396627108\n",
            "Epoch 3 of 4\n",
            "100% 1601/1601 [01:15<00:00, 21.14it/s]\n",
            "Train loss at epoch 3: 0.24392367118526295\n",
            "Training accuracy - epoch 3: 0.9248126171143035\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_62\n",
            "Available device:  cuda\n",
            "100% 1601/1601 [00:18<00:00, 88.58it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.50it/s]\n",
            "100% 37/37 [00:00<00:00, 87.58it/s]\n",
            "Available device:  cuda\n",
            "100% 3089/3089 [00:35<00:00, 87.70it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 37/37 [00:00<00:00, 85.72it/s]\n",
            "Available device:  cuda\n",
            "100% 3089/3089 [00:34<00:00, 88.48it/s]\n",
            "Eval stats: {'train': 0.9248008745900359, 'test': 0.89304, 'pois': 0.958904109589041, 'train_clus_size': (163,), 'test_clus_size': (292,), 'pois_clus_size': (306,), 'base_def': 0.9794520547945206, 'collateral_dmg': 0.00522098105876645}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 34\n",
            "train cluster size: 116\n",
            "test cluster size: 225\n",
            "pois cluster size 236\n",
            "1 [ 224.02990878 -205.54366589]\n",
            "\n",
            "x coll shape: (24775, 256)\n",
            "x_att coll shape:(24775, 256)\n",
            "y coll shape: (24775,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1592/1592 [01:15<00:00, 21.10it/s]\n",
            "Train loss at epoch 0: 0.44028946310843353\n",
            "Training accuracy - epoch 0: 0.8835584170854272\n",
            "Epoch 1 of 4\n",
            "100% 1592/1592 [01:15<00:00, 21.10it/s]\n",
            "Train loss at epoch 1: 0.3108953492500674\n",
            "Training accuracy - epoch 1: 0.915358040201005\n",
            "Epoch 2 of 4\n",
            "100% 1592/1592 [01:15<00:00, 21.16it/s]\n",
            "Train loss at epoch 2: 0.26188863788137035\n",
            "Training accuracy - epoch 2: 0.9287060301507538\n",
            "Epoch 3 of 4\n",
            "100% 1592/1592 [01:15<00:00, 21.15it/s]\n",
            "Train loss at epoch 3: 0.22970557998018762\n",
            "Training accuracy - epoch 3: 0.9356155778894473\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_34\n",
            "Available device:  cuda\n",
            "100% 1592/1592 [00:17<00:00, 88.52it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.75it/s]\n",
            "100% 29/29 [00:00<00:00, 88.02it/s]\n",
            "Available device:  cuda\n",
            "100% 3097/3097 [00:34<00:00, 88.62it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 29/29 [00:00<00:00, 86.54it/s]\n",
            "Available device:  cuda\n",
            "100% 3097/3097 [00:34<00:00, 89.11it/s]\n",
            "Eval stats: {'train': 0.9356155778894473, 'test': 0.8986, 'pois': 0.9911111111111112, 'train_clus_size': (116,), 'test_clus_size': (225,), 'pois_clus_size': (236,), 'base_def': 0.9911111111111112, 'collateral_dmg': -0.00016145307769932504}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 49\n",
            "train cluster size: 188\n",
            "test cluster size: 398\n",
            "pois cluster size 342\n",
            "1 [ 329.69856811 -315.1231035 ]\n",
            "\n",
            "x coll shape: (24602, 256)\n",
            "x_att coll shape:(24602, 256)\n",
            "y coll shape: (24602,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1606/1606 [01:15<00:00, 21.38it/s]\n",
            "Train loss at epoch 0: 0.46087317467942035\n",
            "Training accuracy - epoch 0: 0.8404420921544209\n",
            "Epoch 1 of 4\n",
            "100% 1606/1606 [01:15<00:00, 21.36it/s]\n",
            "Train loss at epoch 1: 0.32194630269791613\n",
            "Training accuracy - epoch 1: 0.8968711083437111\n",
            "Epoch 2 of 4\n",
            "100% 1606/1606 [01:14<00:00, 21.53it/s]\n",
            "Train loss at epoch 2: 0.2643568501419215\n",
            "Training accuracy - epoch 2: 0.9191313823163139\n",
            "Epoch 3 of 4\n",
            "100% 1606/1606 [01:14<00:00, 21.50it/s]\n",
            "Train loss at epoch 3: 0.23462252284064983\n",
            "Training accuracy - epoch 3: 0.9266811955168119\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_49\n",
            "Available device:  cuda\n",
            "100% 1606/1606 [00:18<00:00, 87.84it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.97it/s]\n",
            "100% 50/50 [00:00<00:00, 90.61it/s]\n",
            "Available device:  cuda\n",
            "100% 3076/3076 [00:34<00:00, 88.50it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 50/50 [00:00<00:00, 87.88it/s]\n",
            "Available device:  cuda\n",
            "100% 3076/3076 [00:34<00:00, 89.17it/s]\n",
            "Eval stats: {'train': 0.9266469397290141, 'test': 0.88564, 'pois': 0.4648241206030151, 'train_clus_size': (188,), 'test_clus_size': (398,), 'pois_clus_size': (342,), 'base_def': 0.992462311557789, 'collateral_dmg': 0.0044711812047800725}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 65\n",
            "train cluster size: 143\n",
            "test cluster size: 265\n",
            "pois cluster size 308\n",
            "1 [ 299.6858778 -274.4269098]\n",
            "\n",
            "x coll shape: (24735, 256)\n",
            "x_att coll shape:(24735, 256)\n",
            "y coll shape: (24735,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1601/1601 [01:14<00:00, 21.54it/s]\n",
            "Train loss at epoch 0: 0.4510429464350411\n",
            "Training accuracy - epoch 0: 0.8713304184884447\n",
            "Epoch 1 of 4\n",
            "100% 1601/1601 [01:14<00:00, 21.35it/s]\n",
            "Train loss at epoch 1: 0.33443559937965567\n",
            "Training accuracy - epoch 1: 0.8988132417239225\n",
            "Epoch 2 of 4\n",
            "100% 1601/1601 [01:14<00:00, 21.56it/s]\n",
            "Train loss at epoch 2: 0.28676236779903114\n",
            "Training accuracy - epoch 2: 0.9213772642098689\n",
            "Epoch 3 of 4\n",
            "100% 1601/1601 [01:14<00:00, 21.41it/s]\n",
            "Train loss at epoch 3: 0.2532405464826786\n",
            "Training accuracy - epoch 3: 0.9272329793878826\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_65\n",
            "Available device:  cuda\n",
            "100% 1601/1601 [00:18<00:00, 88.52it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.26it/s]\n",
            "100% 34/34 [00:00<00:00, 88.84it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:35<00:00, 88.31it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 34/34 [00:00<00:00, 84.97it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:34<00:00, 88.87it/s]\n",
            "Eval stats: {'train': 0.9272329793878826, 'test': 0.89952, 'pois': 0.9886792452830189, 'train_clus_size': (143,), 'test_clus_size': (265,), 'pois_clus_size': (308,), 'base_def': 0.9924528301886792, 'collateral_dmg': -0.001131999191429145}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 51\n",
            "train cluster size: 277\n",
            "test cluster size: 554\n",
            "pois cluster size 534\n",
            "1 [ 519.60977459 -490.56663346]\n",
            "\n",
            "x coll shape: (24446, 256)\n",
            "x_att coll shape:(24446, 256)\n",
            "y coll shape: (24446,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1630/1630 [01:15<00:00, 21.52it/s]\n",
            "Train loss at epoch 0: 0.46631912717515706\n",
            "Training accuracy - epoch 0: 0.8687883435582822\n",
            "Epoch 1 of 4\n",
            "100% 1630/1630 [01:15<00:00, 21.50it/s]\n",
            "Train loss at epoch 1: 0.35799961164593697\n",
            "Training accuracy - epoch 1: 0.8940950920245399\n",
            "Epoch 2 of 4\n",
            "100% 1630/1630 [01:15<00:00, 21.48it/s]\n",
            "Train loss at epoch 2: 0.31153573236811016\n",
            "Training accuracy - epoch 2: 0.9059049079754601\n",
            "Epoch 3 of 4\n",
            "100% 1630/1630 [01:16<00:00, 21.45it/s]\n",
            "Train loss at epoch 3: 0.28316122330496646\n",
            "Training accuracy - epoch 3: 0.910122699386503\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_51\n",
            "Available device:  cuda\n",
            "100% 1630/1630 [00:18<00:00, 88.50it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.39it/s]\n",
            "100% 70/70 [00:00<00:00, 89.22it/s]\n",
            "Available device:  cuda\n",
            "100% 3056/3056 [00:34<00:00, 87.41it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 70/70 [00:00<00:00, 88.00it/s]\n",
            "Available device:  cuda\n",
            "100% 3056/3056 [00:34<00:00, 89.15it/s]\n",
            "Eval stats: {'train': 0.9100813257633881, 'test': 0.9008, 'pois': 0.9927797833935018, 'train_clus_size': (277,), 'test_clus_size': (554,), 'pois_clus_size': (534,), 'base_def': 0.9927797833935018, 'collateral_dmg': -0.002413482778368614}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 71\n",
            "train cluster size: 213\n",
            "test cluster size: 427\n",
            "pois cluster size 424\n",
            "1 [ 411.02174306 -385.40661228]\n",
            "\n",
            "x coll shape: (24573, 256)\n",
            "x_att coll shape:(24573, 256)\n",
            "y coll shape: (24573,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1616/1616 [01:15<00:00, 21.40it/s]\n",
            "Train loss at epoch 0: 0.44660125670511974\n",
            "Training accuracy - epoch 0: 0.8783261138613861\n",
            "Epoch 1 of 4\n",
            "100% 1616/1616 [01:15<00:00, 21.45it/s]\n",
            "Train loss at epoch 1: 0.33187994232060075\n",
            "Training accuracy - epoch 1: 0.8797184405940595\n",
            "Epoch 2 of 4\n",
            "100% 1616/1616 [01:15<00:00, 21.45it/s]\n",
            "Train loss at epoch 2: 0.2841186963948467\n",
            "Training accuracy - epoch 2: 0.9211014851485149\n",
            "Epoch 3 of 4\n",
            "100% 1616/1616 [01:15<00:00, 21.44it/s]\n",
            "Train loss at epoch 3: 0.25221091677148894\n",
            "Training accuracy - epoch 3: 0.9253558168316832\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_71\n",
            "Available device:  cuda\n",
            "100% 1616/1616 [00:18<00:00, 88.27it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.61it/s]\n",
            "100% 54/54 [00:00<00:00, 87.32it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.62it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 54/54 [00:00<00:00, 88.07it/s]\n",
            "Available device:  cuda\n",
            "100% 3072/3072 [00:34<00:00, 88.56it/s]\n",
            "Eval stats: {'train': 0.9254100897554937, 'test': 0.90212, 'pois': 0.9836065573770492, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (424,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.003784641679892564}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 8\n",
            "train cluster size: 227\n",
            "test cluster size: 468\n",
            "pois cluster size 434\n",
            "1 [ 421.39380491 -398.36355913]\n",
            "\n",
            "x coll shape: (24532, 256)\n",
            "x_att coll shape:(24532, 256)\n",
            "y coll shape: (24532,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1617/1617 [01:15<00:00, 21.36it/s]\n",
            "Train loss at epoch 0: 0.45717804361049524\n",
            "Training accuracy - epoch 0: 0.8569367140795713\n",
            "Epoch 1 of 4\n",
            "100% 1617/1617 [01:15<00:00, 21.52it/s]\n",
            "Train loss at epoch 1: 0.3463522079587904\n",
            "Training accuracy - epoch 1: 0.9010513296227582\n",
            "Epoch 2 of 4\n",
            "100% 1617/1617 [01:15<00:00, 21.45it/s]\n",
            "Train loss at epoch 2: 0.3004526032633669\n",
            "Training accuracy - epoch 2: 0.9143475572047001\n",
            "Epoch 3 of 4\n",
            "100% 1617/1617 [01:15<00:00, 21.44it/s]\n",
            "Train loss at epoch 3: 0.2720974071242777\n",
            "Training accuracy - epoch 3: 0.9181096681096681\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_8\n",
            "Available device:  cuda\n",
            "100% 1617/1617 [00:18<00:00, 88.08it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.61it/s]\n",
            "100% 59/59 [00:00<00:00, 89.58it/s]\n",
            "Available device:  cuda\n",
            "100% 3067/3067 [00:34<00:00, 88.73it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 59/59 [00:00<00:00, 85.95it/s]\n",
            "Available device:  cuda\n",
            "100% 3067/3067 [00:34<00:00, 88.76it/s]\n",
            "Eval stats: {'train': 0.9181227771764342, 'test': 0.90084, 'pois': 0.9914529914529915, 'train_clus_size': (227,), 'test_clus_size': (468,), 'pois_clus_size': (434,), 'base_def': 0.9914529914529915, 'collateral_dmg': -0.0024457850970162065}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 90\n",
            "train cluster size: 235\n",
            "test cluster size: 445\n",
            "pois cluster size 440\n",
            "1 [ 425.53184628 -406.75361669]\n",
            "\n",
            "x coll shape: (24555, 256)\n",
            "x_att coll shape:(24555, 256)\n",
            "y coll shape: (24555,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1618/1618 [01:15<00:00, 21.49it/s]\n",
            "Train loss at epoch 0: 0.4921985405217511\n",
            "Training accuracy - epoch 0: 0.8712917181705809\n",
            "Epoch 1 of 4\n",
            "100% 1618/1618 [01:15<00:00, 21.47it/s]\n",
            "Train loss at epoch 1: 0.3418720233425664\n",
            "Training accuracy - epoch 1: 0.896168108776267\n",
            "Epoch 2 of 4\n",
            "100% 1618/1618 [01:16<00:00, 21.27it/s]\n",
            "Train loss at epoch 2: 0.2851648021498591\n",
            "Training accuracy - epoch 2: 0.9092243510506799\n",
            "Epoch 3 of 4\n",
            "100% 1618/1618 [01:15<00:00, 21.37it/s]\n",
            "Train loss at epoch 3: 0.24659206123265112\n",
            "Training accuracy - epoch 3: 0.9174907292954264\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_90\n",
            "Available device:  cuda\n",
            "100% 1618/1618 [00:18<00:00, 88.84it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.94it/s]\n",
            "100% 56/56 [00:00<00:00, 90.13it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:34<00:00, 88.01it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 56/56 [00:00<00:00, 87.46it/s]\n",
            "Available device:  cuda\n",
            "100% 3070/3070 [00:34<00:00, 89.10it/s]\n",
            "Eval stats: {'train': 0.9175425038639876, 'test': 0.90188, 'pois': 0.9910112359550561, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (440,), 'base_def': 1.0, 'collateral_dmg': -0.0036652412950519686}\n",
            "\n",
            "\n",
            "Available device:  cuda\n",
            "cluster ind: 43\n",
            "train cluster size: 124\n",
            "test cluster size: 271\n",
            "pois cluster size 280\n",
            "1 [ 272.76505542 -258.86909533]\n",
            "\n",
            "x coll shape: (24729, 256)\n",
            "x_att coll shape:(24729, 256)\n",
            "y coll shape: (24729,)\n",
            "Training new model\n",
            "Available device:  cuda\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 0 of 4\n",
            "100% 1598/1598 [01:14<00:00, 21.49it/s]\n",
            "Train loss at epoch 0: 0.44461856246255665\n",
            "Training accuracy - epoch 0: 0.8811013767209012\n",
            "Epoch 1 of 4\n",
            "100% 1598/1598 [01:14<00:00, 21.50it/s]\n",
            "Train loss at epoch 1: 0.32393462097596315\n",
            "Training accuracy - epoch 1: 0.9080882352941176\n",
            "Epoch 2 of 4\n",
            "100% 1598/1598 [01:14<00:00, 21.39it/s]\n",
            "Train loss at epoch 2: 0.2794700614450609\n",
            "Training accuracy - epoch 2: 0.9219336670838548\n",
            "Epoch 3 of 4\n",
            "100% 1598/1598 [01:14<00:00, 21.54it/s]\n",
            "Train loss at epoch 3: 0.25272074153644497\n",
            "Training accuracy - epoch 3: 0.9259230287859824\n",
            "Saving to /content/drive/MyDrive/storage/other/saved_models/victims/victim_electra-base-emotion_43\n",
            "Available device:  cuda\n",
            "100% 1598/1598 [00:18<00:00, 87.66it/s]\n",
            "100% 3125/3125 [00:35<00:00, 88.37it/s]\n",
            "100% 34/34 [00:00<00:00, 88.98it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:34<00:00, 88.80it/s]\n",
            "Loading model: imdb_electra-base-emotion_FT_DEF.ckpt\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 34/34 [00:00<00:00, 87.65it/s]\n",
            "Available device:  cuda\n",
            "100% 3092/3092 [00:34<00:00, 89.21it/s]\n",
            "Eval stats: {'train': 0.9258998435054773, 'test': 0.9, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (280,), 'base_def': 1.0, 'collateral_dmg': -0.0015770957175785805}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python attack_nlp.py --poison_rate 2 --n_clusters 100 --no_setup --n_start 16 --n_attack 14\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l46iSUKeQnCy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Evals"
      ],
      "metadata": {
        "id": "4GGKlYeA_eqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "eval_dir = \"/content/drive/MyDrive/storage/results/electra\"\n",
        "eval_dir_base = \"/content/drive/MyDrive/storage/results/electra\"\n",
        "eval_base = \"eval-stats_clus100_pois0.5_FT\""
      ],
      "metadata": {
        "id": "R7hsSdBy_fMA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "suffix_lst = []\n",
        "\n",
        "for i in range(0, 30):\n",
        "  suffix_lst.append(str(i))\n",
        "\n",
        "print(suffix_lst)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh2KHXCb_oNt",
        "outputId": "1071d0da-81bf-481f-a9ef-da5ae0b546fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_evals = {}\n",
        "\n",
        "for suffix in suffix_lst:\n",
        "  file_path = \"{}/{}-{}.npy\".format(eval_dir, eval_base, suffix)\n",
        "  if os.path.exists(file_path):\n",
        "    eval_res = np.load(file_path, allow_pickle=True).item()\n",
        "    for k in eval_res.keys():\n",
        "      print(k, eval_res[k])\n",
        "      all_evals[k] = eval_res[k]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivgmVuTq_q6Z",
        "outputId": "d8666c7a-28a7-4e99-9c4a-94a3e7ea8b44"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 {'train': 0.9442322991249006, 'test': 0.90104, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (70,), 'base_def': 1.0, 'collateral_dmg': -0.0026284928626308934}\n",
            "71 {'train': 0.9408218308741869, 'test': 0.90044, 'pois': 0.9859484777517564, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (106,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.0020347535913400883}\n",
            "90 {'train': 0.9409992069785884, 'test': 0.90208, 'pois': 1.0, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (110,), 'base_def': 1.0, 'collateral_dmg': -0.0037059661983303016}\n",
            "71 {'train': 0.9408218308741869, 'test': 0.90044, 'pois': 0.9859484777517564, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (106,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.0020347535913400883}\n",
            "8 {'train': 0.9474143401015228, 'test': 0.90208, 'pois': 0.9914529914529915, 'train_clus_size': (227,), 'test_clus_size': (468,), 'pois_clus_size': (108,), 'base_def': 0.9914529914529915, 'collateral_dmg': -0.0037094407304745225}\n",
            "90 {'train': 0.9409992069785884, 'test': 0.90208, 'pois': 1.0, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (110,), 'base_def': 1.0, 'collateral_dmg': -0.0037059661983303016}\n",
            "43 {'train': 0.9442322991249006, 'test': 0.90104, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (70,), 'base_def': 1.0, 'collateral_dmg': -0.0026284928626308934}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"{}/{}.npy\".format(eval_dir_base, eval_base)\n",
        "print(save_path)\n",
        "np.save(save_path, all_evals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DUj_ZPGAJpW",
        "outputId": "4b87e224-8684-4f63-9f43-c331b9fd4ea8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/storage/results/electra/eval-stats_clus100_pois0.5_FT.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"{}/{}.npy\".format(eval_dir_base, eval_base)\n",
        "eval_res = np.load(file_path, allow_pickle=True).item()\n",
        "print(all_evals)\n",
        "print(all_evals.keys())\n",
        "print(len(all_evals.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw9Tb6J6AWV1",
        "outputId": "936e3705-d89b-477a-9208-c86505bc6340"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{43: {'train': 0.9442322991249006, 'test': 0.90104, 'pois': 1.0, 'train_clus_size': (124,), 'test_clus_size': (271,), 'pois_clus_size': (70,), 'base_def': 1.0, 'collateral_dmg': -0.0026284928626308934}, 71: {'train': 0.9408218308741869, 'test': 0.90044, 'pois': 0.9859484777517564, 'train_clus_size': (213,), 'test_clus_size': (427,), 'pois_clus_size': (106,), 'base_def': 0.9859484777517564, 'collateral_dmg': -0.0020347535913400883}, 90: {'train': 0.9409992069785884, 'test': 0.90208, 'pois': 1.0, 'train_clus_size': (235,), 'test_clus_size': (445,), 'pois_clus_size': (110,), 'base_def': 1.0, 'collateral_dmg': -0.0037059661983303016}, 8: {'train': 0.9474143401015228, 'test': 0.90208, 'pois': 0.9914529914529915, 'train_clus_size': (227,), 'test_clus_size': (468,), 'pois_clus_size': (108,), 'base_def': 0.9914529914529915, 'collateral_dmg': -0.0037094407304745225}}\n",
            "dict_keys([43, 71, 90, 8])\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Results"
      ],
      "metadata": {
        "id": "gt0OZ30HzAW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQeLDsw_zB-T",
        "outputId": "dde5e46f-1d03-458b-cf55-8f2927e476d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "print(\"\\n################################################################################\\n\")\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "NxbUxPaizXvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5868ae-5a79-42e7-a79f-3f10fe62a48c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  8 04:24:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "################################################################################\n",
            "\n",
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!git clone https://github.com/YunZhi246/subpopulation-data-poisoning-attacks.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqxmGvhKzuDB",
        "outputId": "745edc92-b554-43ab-8067-1b5b8acccf8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "Cloning into 'subpopulation-data-poisoning-attacks'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 137 (delta 77), reused 98 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (137/137), 1.61 MiB | 10.80 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/subpopulation-data-poisoning-attacks"
      ],
      "metadata": {
        "id": "o8o1MAFczvAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f3ff17-f8f6-4410-864f-cd8ff4e7f3a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/subpopulation-data-poisoning-attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-4HgNOk-mCl",
        "outputId": "567268e0-fb77-4332-8754-044953298509"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n",
            "Collecting pandas==1.0.1\n",
            "  Downloading pandas-1.0.1-cp38-cp38-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 4.9 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 77.8 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 627 kB/s \n",
            "\u001b[?25hCollecting seaborn==0.10.0\n",
            "  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 94.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n",
            "Collecting transformers==4.20.0\n",
            "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 75.8 MB/s \n",
            "\u001b[?25hCollecting tables==3.6.1\n",
            "  Downloading tables-3.6.1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 79.1 MB/s \n",
            "\u001b[?25hCollecting datasets==2.7.1\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 88.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2022.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from seaborn==0.10.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 68.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 88.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.0->-r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.8/dist-packages (from tables==3.6.1->-r requirements.txt (line 9)) (2.8.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 94.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (2022.11.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 89.6 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 10)) (0.3.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.5.0->-r requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 10)) (6.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.0->-r requirements.txt (line 8)) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 91.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, xxhash, tokenizers, scipy, responses, pandas, multiprocess, huggingface-hub, transformers, tables, seaborn, scikit-learn, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: tables\n",
            "    Found existing installation: tables 3.7.0\n",
            "    Uninstalling tables-3.7.0:\n",
            "      Successfully uninstalled tables-3.7.0\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.1 which is incompatible.\n",
            "xarray-einstats 0.3.0 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n",
            "plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.1 which is incompatible.\u001b[0m\n",
            "Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 pandas-1.0.1 responses-0.18.0 scikit-learn-0.22.1 scipy-1.4.1 seaborn-0.10.0 tables-3.6.1 tokenizers-0.12.1 transformers-4.20.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "Kf8-c2x5-nPs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "u_Rtd8U0-qef"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import ElectraForSequenceClassification"
      ],
      "metadata": {
        "id": "EE2Y0Rfn-suo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from attack_nlp import init_cluster_attack\n",
        "\n",
        "from subclass_avail import common\n",
        "from subclass_avail.target_nlp import bert_utils"
      ],
      "metadata": {
        "id": "8aFWPUge-xoj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_dir = '/content/drive/MyDrive/storage/results/electra'\n",
        "fname = 'eval-stats_clus{}_pois{}_{}.npy'\n",
        "\n",
        "n_clus = 100\n",
        "seed = 42\n",
        "\n",
        "pois_rates = ['0.5', '1.0', '2.0']\n",
        "# m_types = ['LL', 'FT']\n",
        "m_types = ['FT']"
      ],
      "metadata": {
        "id": "adOFAT_W-0Ky"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to the same used during the attack\n",
        "device = bert_utils.get_device()\n",
        "bert_utils.set_seed(device=device, seed=seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppv6ECGp-4xq",
        "outputId": "142fb83a-3418-4d17-8d94-bbe9be755196"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accumulate all results in a single DataFrame\n",
        "res_df = pd.DataFrame(columns=['type', 'p_rate', 'index', 't_dmg', 'p_acc', 'base_def', 'coll_dmg', 'csize', 'exp'], dtype=object)\n",
        "\n",
        "for ps in pois_rates:\n",
        "    for t in m_types:\n",
        "        exp_name = fname.format(n_clus, ps, t)\n",
        "        print('Experiment {}\\n'.format(exp_name))\n",
        "\n",
        "        res_arr = np.load(os.path.join(common.results_dir_xlnet, exp_name), allow_pickle=True).item()\n",
        "        \n",
        "        for clus_id, results in res_arr.items():\n",
        "            if len(results['train_clus_size']) > 1:\n",
        "                train_clus_size = len(results['train_clus_size'])\n",
        "            else:\n",
        "                train_clus_size = results['train_clus_size'][0]\n",
        "            \n",
        "            to_add = {\n",
        "                'type': t,\n",
        "                'p_rate': ps,\n",
        "                'index': clus_id,\n",
        "                't_dmg': results['base_def'] - results['pois'],\n",
        "                'p_acc': results['pois'],\n",
        "                'base_def': results['base_def'],\n",
        "                'coll_dmg': results['collateral_dmg'],\n",
        "                'csize': train_clus_size,\n",
        "                'exp': exp_name\n",
        "            }\n",
        "            \n",
        "            res_df = res_df.append(to_add, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJvBLcHc_GgB",
        "outputId": "115376a8-2002-4275-b81d-b484214f9ad6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment eval-stats_clus100_pois0.5_FT.npy\n",
            "\n",
            "Experiment eval-stats_clus100_pois1.0_FT.npy\n",
            "\n",
            "Experiment eval-stats_clus100_pois2.0_FT.npy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting by target damage\n",
        "for ps in pois_rates:\n",
        "    for t in m_types:\n",
        "        exp_name = fname.format(n_clus, ps, t)\n",
        "        print('Experiment {}\\n'.format(exp_name))\n",
        "        \n",
        "        sub_df = res_df[res_df['exp'] == exp_name]\n",
        "        sub_df = sub_df.sort_values(by='t_dmg')\n",
        "        \n",
        "        top5_df = sub_df.tail(5)\n",
        "        top10_df = sub_df.tail(10)\n",
        "        \n",
        "        print('Best target damage:')\n",
        "        print(sub_df[-1:])\n",
        "        print()\n",
        "        \n",
        "        print('Top 5 target damage averages:')\n",
        "        print(top5_df.mean())\n",
        "        print()\n",
        "\n",
        "        print('Top 10 target damage averages:')\n",
        "        print(top10_df.mean())\n",
        "        print()\n",
        "        \n",
        "        print('-'*80)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohH3U5_7_JbL",
        "outputId": "bb1dc922-6bba-4c24-c317-09cb1628f919"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment eval-stats_clus100_pois0.5_FT.npy\n",
            "\n",
            "Best target damage:\n",
            "  type p_rate index  t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
            "3   FT    0.5     8    0.0  0.991453  0.991453 -0.003709   227   \n",
            "\n",
            "                                 exp  \n",
            "3  eval-stats_clus100_pois0.5_FT.npy  \n",
            "\n",
            "Top 5 target damage averages:\n",
            "index        53.00000\n",
            "t_dmg         0.00000\n",
            "p_acc         0.99435\n",
            "base_def      0.99435\n",
            "coll_dmg     -0.00302\n",
            "csize       199.75000\n",
            "dtype: float64\n",
            "\n",
            "Top 10 target damage averages:\n",
            "index        53.00000\n",
            "t_dmg         0.00000\n",
            "p_acc         0.99435\n",
            "base_def      0.99435\n",
            "coll_dmg     -0.00302\n",
            "csize       199.75000\n",
            "dtype: float64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Experiment eval-stats_clus100_pois1.0_FT.npy\n",
            "\n",
            "Best target damage:\n",
            "  type p_rate index  t_dmg  p_acc  base_def  coll_dmg csize  \\\n",
            "9   FT    1.0    43    0.0    1.0       1.0 -0.004529   124   \n",
            "\n",
            "                                 exp  \n",
            "9  eval-stats_clus100_pois1.0_FT.npy  \n",
            "\n",
            "Top 5 target damage averages:\n",
            "index        52.600000\n",
            "t_dmg         0.000000\n",
            "p_acc         0.994036\n",
            "base_def      0.994036\n",
            "coll_dmg     -0.003255\n",
            "csize       215.200000\n",
            "dtype: float64\n",
            "\n",
            "Top 10 target damage averages:\n",
            "index        54.666667\n",
            "t_dmg         0.000000\n",
            "p_acc         0.993772\n",
            "base_def      0.993772\n",
            "coll_dmg     -0.003076\n",
            "csize       203.166667\n",
            "dtype: float64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Experiment eval-stats_clus100_pois2.0_FT.npy\n",
            "\n",
            "Best target damage:\n",
            "   type p_rate index     t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
            "17   FT    2.0    49  0.527638  0.464824  0.992462  0.004471   188   \n",
            "\n",
            "                                  exp  \n",
            "17  eval-stats_clus100_pois2.0_FT.npy  \n",
            "\n",
            "Top 5 target damage averages:\n",
            "index        49.400000\n",
            "t_dmg         0.124001\n",
            "p_acc         0.827956\n",
            "base_def      0.951957\n",
            "coll_dmg      0.001035\n",
            "csize       158.000000\n",
            "dtype: float64\n",
            "\n",
            "Top 10 target damage averages:\n",
            "index        48.500000\n",
            "t_dmg         0.062612\n",
            "p_acc         0.909630\n",
            "base_def      0.972242\n",
            "coll_dmg     -0.000618\n",
            "csize       177.400000\n",
            "dtype: float64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting by collateral damage\n",
        "for ps in pois_rates:\n",
        "    for t in m_types:\n",
        "        exp_name = fname.format(n_clus, ps, t)\n",
        "        print('Experiment {}\\n'.format(exp_name))\n",
        "        \n",
        "        sub_df = res_df[res_df['exp'] == exp_name]\n",
        "        sub_df = sub_df.sort_values(by='coll_dmg')\n",
        "        \n",
        "        print('Worst collateral damage:')\n",
        "        print(sub_df[-1:])\n",
        "        print(sub_df[-1:]['coll_dmg'] * 100)\n",
        "        print()\n",
        "        \n",
        "        print('-'*80)\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh3NAUTDA-sq",
        "outputId": "8cc8457b-3a19-4036-d688-85c9dcf6004c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment eval-stats_clus100_pois0.5_FT.npy\n",
            "\n",
            "Worst collateral damage:\n",
            "  type p_rate index  t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
            "1   FT    0.5    71    0.0  0.985948  0.985948 -0.002035   213   \n",
            "\n",
            "                                 exp  \n",
            "1  eval-stats_clus100_pois0.5_FT.npy  \n",
            "1   -0.203475\n",
            "Name: coll_dmg, dtype: float64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Experiment eval-stats_clus100_pois1.0_FT.npy\n",
            "\n",
            "Worst collateral damage:\n",
            "  type p_rate index  t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
            "6   FT    1.0    71    0.0  0.985948  0.985948 -0.001831   213   \n",
            "\n",
            "                                 exp  \n",
            "6  eval-stats_clus100_pois1.0_FT.npy  \n",
            "6   -0.183128\n",
            "Name: coll_dmg, dtype: float64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Experiment eval-stats_clus100_pois2.0_FT.npy\n",
            "\n",
            "Worst collateral damage:\n",
            "   type p_rate index     t_dmg     p_acc  base_def  coll_dmg csize  \\\n",
            "13   FT    2.0    13 -0.011765  0.958824  0.947059   0.00733    92   \n",
            "\n",
            "                                  exp  \n",
            "13  eval-stats_clus100_pois2.0_FT.npy  \n",
            "13    0.732984\n",
            "Name: coll_dmg, dtype: float64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jQjTGicBDT0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}